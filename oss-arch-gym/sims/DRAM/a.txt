ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34419440.88 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [1, 0, 4, 4, 7, 2, 6]
[Action Encoded] [1, 0, 4, 4, 7, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(2.33208931), array(2.33208931), array(2.33208931), array(2.33208931), array(2.33208931), array(2.33208931), array(2.33208931)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 2, 2, 2, 16, 1, 1]
[Action Encoded] [0, 2, 2, 2, 16, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 4, 1, 4]
[Action Encoded] [0, 1, 2, 1, 4, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 2, 2, 3, 13, 3, 7]
[Action Encoded] [1, 2, 2, 3, 13, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(14.9596829), array(14.9596829), array(14.9596829), array(14.9596829), array(14.9596829), array(14.9596829), array(14.9596829)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 2, 4, 1, 12, 3, 1]
[Action Encoded] [1, 2, 4, 1, 12, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 31, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 31, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(14.07059898), array(14.07059898), array(14.07059898), array(14.07059898), array(14.07059898), array(14.07059898), array(14.07059898)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 18, 2, 5]
[Action Encoded] [0, 1, 4, 1, 18, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 4, 0, 3]
[Action Encoded] [1, 0, 3, 2, 4, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 23, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 23, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(2.4026155), array(2.4026155), array(2.4026155), array(2.4026155), array(2.4026155), array(2.4026155), array(2.4026155)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 19, 0, 1]
[Action Encoded] [1, 2, 4, 4, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(13.85842406), array(13.85842406), array(13.85842406), array(13.85842406), array(13.85842406), array(13.85842406), array(13.85842406)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 1, 0, 3, 6, 3, 7]
[Action Encoded] [1, 1, 0, 3, 6, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(14.98007612), array(14.98007612), array(14.98007612), array(14.98007612), array(14.98007612), array(14.98007612), array(14.98007612)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 12, 2, 6]
[Action Encoded] [1, 3, 4, 4, 12, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(7.90953431), array(7.90953431), array(7.90953431), array(7.90953431), array(7.90953431), array(7.90953431), array(7.90953431)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 11, 2, 2]
[Action Encoded] [1, 1, 4, 1, 11, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(14.54777263), array(14.54777263), array(14.54777263), array(14.54777263), array(14.54777263), array(14.54777263), array(14.54777263)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 1, 4, 0, 12, 2, 5]
[Action Encoded] [0, 1, 4, 0, 12, 2, 5]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 31, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 31, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873), array(15.93610873)]
Episode 12 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 1, 2, 7]
[Action Encoded] [1, 2, 1, 1, 1, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(14.78069987), array(14.78069987), array(14.78069987), array(14.78069987), array(14.78069987), array(14.78069987), array(14.78069987)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 1, 1, 4, 1, 2, 0]
[Action Encoded] [1, 1, 1, 4, 1, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(7.99623114), array(7.99623114), array(7.99623114), array(7.99623114), array(7.99623114), array(7.99623114), array(7.99623114)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 2, 2, 0, 15, 2, 2]
[Action Encoded] [1, 2, 2, 0, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(14.53240503), array(14.53240503), array(14.53240503), array(14.53240503), array(14.53240503), array(14.53240503), array(14.53240503)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 18, 2, 7]
[Action Encoded] [1, 3, 4, 3, 18, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 37, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 37, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(7.98938206), array(7.98938206), array(7.98938206), array(7.98938206), array(7.98938206), array(7.98938206), array(7.98938206)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 7, 3, 4]
[Action Encoded] [0, 2, 1, 2, 7, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 4, 1, 4, 12, 2, 9]
[Action Encoded] [0, 4, 1, 4, 12, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(1.87932755), array(1.87932755), array(1.87932755), array(1.87932755), array(1.87932755), array(1.87932755), array(1.87932755)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 2, 4, 1, 8, 0, 5]
[Action Encoded] [1, 2, 4, 1, 8, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(14.64282218), array(14.64282218), array(14.64282218), array(14.64282218), array(14.64282218), array(14.64282218), array(14.64282218)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 6, 2, 8]
[Action Encoded] [0, 2, 1, 1, 6, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 25, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 25, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 1, 1, 2, 16, 3, 8]
[Action Encoded] [1, 1, 1, 2, 16, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 35, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 35, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(15.68134065), array(15.68134065), array(15.68134065), array(15.68134065), array(15.68134065), array(15.68134065), array(15.68134065)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 3, 3, 2, 20, 3, 1]
[Action Encoded] [0, 3, 3, 2, 20, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(8.15396422), array(8.15396422), array(8.15396422), array(8.15396422), array(8.15396422), array(8.15396422), array(8.15396422)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 0, 1, 2, 9, 0, 8]
[Action Encoded] [0, 0, 1, 2, 9, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.45447496), array(2.45447496), array(2.45447496), array(2.45447496), array(2.45447496), array(2.45447496), array(2.45447496)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 1, 3, 2, 18, 0, 5]
[Action Encoded] [1, 1, 3, 2, 18, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(14.68919564), array(14.68919564), array(14.68919564), array(14.68919564), array(14.68919564), array(14.68919564), array(14.68919564)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 1, 3, 2, 10, 0, 9]
[Action Encoded] [1, 1, 3, 2, 10, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(14.80829866), array(14.80829866), array(14.80829866), array(14.80829866), array(14.80829866), array(14.80829866), array(14.80829866)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 2, 0, 2, 10, 2, 4]
[Action Encoded] [1, 2, 0, 2, 10, 2, 4]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
{'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(14.82598354), array(14.82598354), array(14.82598354), array(14.82598354), array(14.82598354), array(14.82598354), array(14.82598354)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 2, 4, 1, 3, 1, 6]
[Action Encoded] [1, 2, 4, 1, 3, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(14.58771211), array(14.58771211), array(14.58771211), array(14.58771211), array(14.58771211), array(14.58771211), array(14.58771211)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 0, 1, 2, 6, 3, 4]
[Action Encoded] [0, 0, 1, 2, 6, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(2.44945894), array(2.44945894), array(2.44945894), array(2.44945894), array(2.44945894), array(2.44945894), array(2.44945894)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 17, 2, 6]
[Action Encoded] [0, 0, 3, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 2, 1, 5]
[Action Encoded] [1, 3, 4, 3, 2, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(8.13246192), array(8.13246192), array(8.13246192), array(8.13246192), array(8.13246192), array(8.13246192), array(8.13246192)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 2, 2, 1, 15, 1, 6]
[Action Encoded] [0, 2, 2, 1, 15, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(16.02270491), array(16.02270491), array(16.02270491), array(16.02270491), array(16.02270491), array(16.02270491), array(16.02270491)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 0, 1, 0, 2, 3, 5]
[Action Encoded] [1, 0, 1, 0, 2, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 21, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 21, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(2.50389971), array(2.50389971), array(2.50389971), array(2.50389971), array(2.50389971), array(2.50389971), array(2.50389971)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 0, 0, 0]
[Action Encoded] [0, 2, 0, 4, 0, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 19, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 19, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(8.2953627), array(8.2953627), array(8.2953627), array(8.2953627), array(8.2953627), array(8.2953627), array(8.2953627)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 8, 3, 4]
[Action Encoded] [1, 2, 3, 4, 8, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(14.88833089), array(14.88833089), array(14.88833089), array(14.88833089), array(14.88833089), array(14.88833089), array(14.88833089)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 12, 1, 9]
[Action Encoded] [1, 3, 3, 3, 12, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(9.0606136), array(9.0606136), array(9.0606136), array(9.0606136), array(9.0606136), array(9.0606136), array(9.0606136)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 3, 1, 5]
[Action Encoded] [1, 1, 4, 1, 3, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(14.73432901), array(14.73432901), array(14.73432901), array(14.73432901), array(14.73432901), array(14.73432901), array(14.73432901)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 9, 0, 3]
[Action Encoded] [0, 3, 0, 4, 9, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 28, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 28, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(8.45737215), array(8.45737215), array(8.45737215), array(8.45737215), array(8.45737215), array(8.45737215), array(8.45737215)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 8, 2, 1]
[Action Encoded] [1, 0, 2, 1, 8, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 27, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 27, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(2.39985405), array(2.39985405), array(2.39985405), array(2.39985405), array(2.39985405), array(2.39985405), array(2.39985405)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 5, 0, 5]
[Action Encoded] [1, 3, 3, 4, 5, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 24, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 24, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(8.17365019), array(8.17365019), array(8.17365019), array(8.17365019), array(8.17365019), array(8.17365019), array(8.17365019)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 17, 1, 6]
[Action Encoded] [1, 0, 3, 0, 17, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 4, 'refi': 285480}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 38687326.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(2.45253975), array(2.45253975), array(2.45253975), array(2.45253975), array(2.45253975), array(2.45253975), array(2.45253975)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 2, 4, 3, 7, 2, 9]
[Action Encoded] [0, 2, 4, 3, 7, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(16.00921805), array(16.00921805), array(16.00921805), array(16.00921805), array(16.00921805), array(16.00921805), array(16.00921805)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 2, 3, 3, 12, 1, 0]
[Action Encoded] [0, 2, 3, 3, 12, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(8.27940526), array(8.27940526), array(8.27940526), array(8.27940526), array(8.27940526), array(8.27940526), array(8.27940526)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 13, 2, 2]
[Action Encoded] [0, 3, 3, 1, 13, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(8.40291334), array(8.40291334), array(8.40291334), array(8.40291334), array(8.40291334), array(8.40291334), array(8.40291334)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 0, 5]
[Action Encoded] [0, 0, 2, 4, 16, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(2.37995376), array(2.37995376), array(2.37995376), array(2.37995376), array(2.37995376), array(2.37995376), array(2.37995376)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 1, 1, 0, 16, 2, 0]
[Action Encoded] [1, 1, 1, 0, 16, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 35, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 35, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(7.89800686), array(7.89800686), array(7.89800686), array(7.89800686), array(7.89800686), array(7.89800686), array(7.89800686)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 4, 1, 2, 7, 1, 5]
[Action Encoded] [1, 4, 1, 2, 7, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(1.91748063), array(1.91748063), array(1.91748063), array(1.91748063), array(1.91748063), array(1.91748063), array(1.91748063)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 3, 0, 3, 6, 0, 0]
[Action Encoded] [1, 3, 0, 3, 6, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(5.18061488), array(5.18061488), array(5.18061488), array(5.18061488), array(5.18061488), array(5.18061488), array(5.18061488)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 12, 3, 4]
[Action Encoded] [1, 0, 3, 4, 12, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 31, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 31, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(2.35669917), array(2.35669917), array(2.35669917), array(2.35669917), array(2.35669917), array(2.35669917), array(2.35669917)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 2, 2, 2, 7, 3, 4]
[Action Encoded] [1, 2, 2, 2, 7, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(14.81416702), array(14.81416702), array(14.81416702), array(14.81416702), array(14.81416702), array(14.81416702), array(14.81416702)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 2, 4, 2, 15, 0, 2]
[Action Encoded] [1, 2, 4, 2, 15, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(14.56287675), array(14.56287675), array(14.56287675), array(14.56287675), array(14.56287675), array(14.56287675), array(14.56287675)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 19, 0, 1]
[Action Encoded] [0, 0, 3, 4, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(2.30511398), array(2.30511398), array(2.30511398), array(2.30511398), array(2.30511398), array(2.30511398), array(2.30511398)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 14, 2, 9]
[Action Encoded] [0, 2, 3, 2, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 8, 3, 3]
[Action Encoded] [0, 1, 3, 3, 8, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 27, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 27, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(15.94450634), array(15.94450634), array(15.94450634), array(15.94450634), array(15.94450634), array(15.94450634), array(15.94450634)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 11, 2, 2]
[Action Encoded] [1, 3, 2, 3, 11, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(8.73890431), array(8.73890431), array(8.73890431), array(8.73890431), array(8.73890431), array(8.73890431), array(8.73890431)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 0, 1, 2, 3, 2, 6]
[Action Encoded] [1, 0, 1, 2, 3, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(2.45303095), array(2.45303095), array(2.45303095), array(2.45303095), array(2.45303095), array(2.45303095), array(2.45303095)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 15, 2, 0]
[Action Encoded] [1, 3, 4, 1, 15, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(5.08223059), array(5.08223059), array(5.08223059), array(5.08223059), array(5.08223059), array(5.08223059), array(5.08223059)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 15, 2, 2]
[Action Encoded] [0, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(8.36663467), array(8.36663467), array(8.36663467), array(8.36663467), array(8.36663467), array(8.36663467), array(8.36663467)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 2, 11, 2, 0]
[Action Encoded] [1, 3, 2, 2, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(5.14601538), array(5.14601538), array(5.14601538), array(5.14601538), array(5.14601538), array(5.14601538), array(5.14601538)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 3, 2, 1, 19, 2, 5]
[Action Encoded] [1, 3, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(8.33737986), array(8.33737986), array(8.33737986), array(8.33737986), array(8.33737986), array(8.33737986), array(8.33737986)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 9, 0, 2]
[Action Encoded] [1, 1, 2, 4, 9, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(14.75912935), array(14.75912935), array(14.75912935), array(14.75912935), array(14.75912935), array(14.75912935), array(14.75912935)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 1, 1, 9]
[Action Encoded] [1, 1, 2, 2, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(15.48969299), array(15.48969299), array(15.48969299), array(15.48969299), array(15.48969299), array(15.48969299), array(15.48969299)]
Episode 62 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 6, 3, 2]
[Action Encoded] [1, 0, 4, 4, 6, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.31992133), array(2.31992133), array(2.31992133), array(2.31992133), array(2.31992133), array(2.31992133), array(2.31992133)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 5, 3, 7]
[Action Encoded] [0, 2, 3, 1, 5, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 0, 1, 3, 13, 2, 7]
[Action Encoded] [1, 0, 1, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.42929704), array(2.42929704), array(2.42929704), array(2.42929704), array(2.42929704), array(2.42929704), array(2.42929704)]
Episode 66 finished after 1 steps.
[Env][Action] [1, 0, 2, 2, 7, 3, 9]
[Action Encoded] [1, 0, 2, 2, 7, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(2.43394352), array(2.43394352), array(2.43394352), array(2.43394352), array(2.43394352), array(2.43394352), array(2.43394352)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 3, 3, 10, 2, 2]
[Action Encoded] [0, 0, 3, 3, 10, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.36636293), array(2.36636293), array(2.36636293), array(2.36636293), array(2.36636293), array(2.36636293), array(2.36636293)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 3, 0, 8, 3, 6]
[Action Encoded] [0, 2, 3, 0, 8, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276)]
Episode 69 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 20, 3, 2]
[Action Encoded] [1, 3, 4, 4, 20, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(7.83848228), array(7.83848228), array(7.83848228), array(7.83848228), array(7.83848228), array(7.83848228), array(7.83848228)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 6, 2, 6]
[Action Encoded] [1, 3, 4, 0, 6, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 25, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 25, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(8.54246123), array(8.54246123), array(8.54246123), array(8.54246123), array(8.54246123), array(8.54246123), array(8.54246123)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 2, 15, 2, 6]
[Action Encoded] [0, 1, 2, 2, 15, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.01829052), array(16.01829052), array(16.01829052), array(16.01829052), array(16.01829052), array(16.01829052), array(16.01829052)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 7, 2, 0]
[Action Encoded] [1, 2, 3, 2, 7, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(7.89743579), array(7.89743579), array(7.89743579), array(7.89743579), array(7.89743579), array(7.89743579), array(7.89743579)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 6, 2, 0]
[Action Encoded] [0, 3, 2, 3, 6, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(5.11696192), array(5.11696192), array(5.11696192), array(5.11696192), array(5.11696192), array(5.11696192), array(5.11696192)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 1, 4, 4, 2, 9]
[Action Encoded] [1, 3, 1, 4, 4, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(8.83248483), array(8.83248483), array(8.83248483), array(8.83248483), array(8.83248483), array(8.83248483), array(8.83248483)]
Episode 75 finished after 1 steps.
[Env][Action] [1, 2, 3, 3, 10, 1, 8]
[Action Encoded] [1, 2, 3, 3, 10, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(15.03780278), array(15.03780278), array(15.03780278), array(15.03780278), array(15.03780278), array(15.03780278), array(15.03780278)]
Episode 76 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 20, 2, 2]
[Action Encoded] [1, 2, 3, 2, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(14.48293367), array(14.48293367), array(14.48293367), array(14.48293367), array(14.48293367), array(14.48293367), array(14.48293367)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 2, 2, 0, 14, 2, 4]
[Action Encoded] [1, 2, 2, 0, 14, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(14.75989287), array(14.75989287), array(14.75989287), array(14.75989287), array(14.75989287), array(14.75989287), array(14.75989287)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 7, 2, 6]
[Action Encoded] [0, 4, 2, 2, 7, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(1.89513784), array(1.89513784), array(1.89513784), array(1.89513784), array(1.89513784), array(1.89513784), array(1.89513784)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 2, 2, 2, 8, 0, 2]
[Action Encoded] [1, 2, 2, 2, 8, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 27, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 27, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(14.62999765), array(14.62999765), array(14.62999765), array(14.62999765), array(14.62999765), array(14.62999765), array(14.62999765)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 3, 0, 2, 2, 2, 0]
[Action Encoded] [1, 3, 0, 2, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(5.1145729), array(5.1145729), array(5.1145729), array(5.1145729), array(5.1145729), array(5.1145729), array(5.1145729)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 19, 2, 9]
[Action Encoded] [1, 3, 1, 3, 19, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 38, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 38, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(8.14382783), array(8.14382783), array(8.14382783), array(8.14382783), array(8.14382783), array(8.14382783), array(8.14382783)]
Episode 82 finished after 1 steps.
[Env][Action] [1, 0, 2, 4, 18, 2, 2]
[Action Encoded] [1, 0, 2, 4, 18, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(2.36868158), array(2.36868158), array(2.36868158), array(2.36868158), array(2.36868158), array(2.36868158), array(2.36868158)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 10, 3, 6]
[Action Encoded] [1, 3, 1, 3, 10, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(8.87259354), array(8.87259354), array(8.87259354), array(8.87259354), array(8.87259354), array(8.87259354), array(8.87259354)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 2, 1, 2, 1, 2, 9]
[Action Encoded] [1, 2, 1, 2, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(15.53040076), array(15.53040076), array(15.53040076), array(15.53040076), array(15.53040076), array(15.53040076), array(15.53040076)]
Episode 85 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 11, 2, 4]
[Action Encoded] [1, 2, 3, 2, 11, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(14.70125659), array(14.70125659), array(14.70125659), array(14.70125659), array(14.70125659), array(14.70125659), array(14.70125659)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 17, 2, 2]
[Action Encoded] [1, 2, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(14.55374789), array(14.55374789), array(14.55374789), array(14.55374789), array(14.55374789), array(14.55374789), array(14.55374789)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 17, 2, 2]
[Action Encoded] [1, 2, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(14.49636892), array(14.49636892), array(14.49636892), array(14.49636892), array(14.49636892), array(14.49636892), array(14.49636892)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 8, 2, 6]
[Action Encoded] [1, 3, 2, 3, 8, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 27, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 27, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(7.97158489), array(7.97158489), array(7.97158489), array(7.97158489), array(7.97158489), array(7.97158489), array(7.97158489)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 6, 2, 2]
[Action Encoded] [1, 2, 3, 2, 6, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(14.30849887), array(14.30849887), array(14.30849887), array(14.30849887), array(14.30849887), array(14.30849887), array(14.30849887)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 3, 2, 2]
[Action Encoded] [1, 3, 2, 3, 3, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(8.39569703), array(8.39569703), array(8.39569703), array(8.39569703), array(8.39569703), array(8.39569703), array(8.39569703)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 2, 3, 6, 2, 9]
[Action Encoded] [0, 2, 2, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 2, 1, 16, 2, 9]
[Action Encoded] [0, 2, 2, 1, 16, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 4, 2, 15, 1, 9]
[Action Encoded] [0, 2, 4, 2, 15, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.01454735), array(16.01454735), array(16.01454735), array(16.01454735), array(16.01454735), array(16.01454735), array(16.01454735)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 4, 2, 12, 3, 9]
[Action Encoded] [0, 2, 4, 2, 12, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 31, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 31, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.01517456), array(16.01517456), array(16.01517456), array(16.01517456), array(16.01517456), array(16.01517456), array(16.01517456)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.33723169), array(1.33723169), array(1.33723169), array(1.33723169), array(1.33723169), array(1.33723169), array(1.33723169)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 3, 2, 2, 15, 3, 3]
[Action Encoded] [0, 3, 2, 2, 15, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(8.47643231), array(8.47643231), array(8.47643231), array(8.47643231), array(8.47643231), array(8.47643231), array(8.47643231)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 15, 2, 2]
[Action Encoded] [1, 0, 3, 2, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(2.39193047), array(2.39193047), array(2.39193047), array(2.39193047), array(2.39193047), array(2.39193047), array(2.39193047)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 2, 2, 3, 15, 2, 3]
[Action Encoded] [1, 2, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(14.86416639), array(14.86416639), array(14.86416639), array(14.86416639), array(14.86416639), array(14.86416639), array(14.86416639)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 8, 2, 2]
[Action Encoded] [1, 1, 4, 2, 8, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 27, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 27, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(14.52753929), array(14.52753929), array(14.52753929), array(14.52753929), array(14.52753929), array(14.52753929), array(14.52753929)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:33:00 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [1, 2, 3, 3, 6, 1, 4]
[Action Encoded] [1, 2, 3, 3, 6, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 25, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 25, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(10.73804205), array(10.73804205), array(10.73804205), array(10.73804205), array(10.73804205), array(10.73804205), array(10.73804205)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 17, 3, 8]
[Action Encoded] [0, 2, 3, 2, 17, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 10, 0, 1]
[Action Encoded] [0, 0, 4, 4, 10, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 1, 0, 1]
[Action Encoded] [1, 2, 3, 1, 1, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 4  Rewards: [10.263875794061725, 10.263875794061725, 10.263875794061725, 10.263875794061725, 10.263875794061725, 10.263875794061725, 10.263875794061725]
Episode 4 finished after 1 steps.
[Env][Action] [1, 1, 4, 4, 18, 3, 5]
[Action Encoded] [1, 1, 4, 4, 18, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 1, 1, 1, 15, 1, 1]
[Action Encoded] [0, 1, 1, 1, 15, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(11.62102872), array(11.62102872), array(11.62102872), array(11.62102872), array(11.62102872), array(11.62102872), array(11.62102872)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 0, 3, 1, 14, 2, 5]
[Action Encoded] [1, 0, 3, 1, 14, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 33, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 33, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 3, 0, 1, 20, 3, 9]
[Action Encoded] [1, 3, 0, 1, 20, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 39, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 39, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(6.37472924), array(6.37472924), array(6.37472924), array(6.37472924), array(6.37472924), array(6.37472924), array(6.37472924)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 2, 0, 3, 20, 3, 4]
[Action Encoded] [0, 2, 0, 3, 20, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 1, 1, 4, 1, 0, 5]
[Action Encoded] [0, 1, 1, 4, 1, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 3, 1, 1, 16, 0, 3]
[Action Encoded] [0, 3, 1, 1, 16, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(6.4638863), array(6.4638863), array(6.4638863), array(6.4638863), array(6.4638863), array(6.4638863), array(6.4638863)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 5, 0, 7]
[Action Encoded] [0, 3, 3, 1, 5, 0, 7]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [6.356463544917054, 6.356463544917054, 6.356463544917054, 6.356463544917054, 6.356463544917054, 6.356463544917054, 6.356463544917054]
Episode 12 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 2, 0, 4]
[Action Encoded] [0, 4, 3, 3, 2, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 21, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 21, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 4, 3, 1, 5, 0, 5]
[Action Encoded] [0, 4, 3, 1, 5, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 7, 2, 1]
[Action Encoded] [0, 2, 1, 2, 7, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 4, 0, 2, 12, 1, 8]
[Action Encoded] [0, 4, 0, 2, 12, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 31, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 31, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 16 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 7, 0, 5]
[Action Encoded] [1, 1, 1, 3, 7, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(11.31844036), array(11.31844036), array(11.31844036), array(11.31844036), array(11.31844036), array(11.31844036), array(11.31844036)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 1, 2, 3, 11, 1, 9]
[Action Encoded] [1, 1, 2, 3, 11, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 0, 1, 4, 5, 3, 8]
[Action Encoded] [1, 0, 1, 4, 5, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 4, 1, 4, 4, 2, 8]
[Action Encoded] [1, 4, 1, 4, 4, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 17, 3, 5]
[Action Encoded] [0, 3, 3, 3, 17, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(6.27022549), array(6.27022549), array(6.27022549), array(6.27022549), array(6.27022549), array(6.27022549), array(6.27022549)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 2, 2, 1, 1, 3, 1]
[Action Encoded] [1, 2, 2, 1, 1, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 3, 1, 2, 2, 1, 2]
[Action Encoded] [1, 3, 1, 2, 2, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 21, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 21, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(5.36105794), array(5.36105794), array(5.36105794), array(5.36105794), array(5.36105794), array(5.36105794), array(5.36105794)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 4, 0, 4, 19, 0, 8]
[Action Encoded] [0, 4, 0, 4, 19, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 2, 0, 0, 1, 3, 8]
[Action Encoded] [1, 2, 0, 0, 1, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 20, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 20, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 25  Rewards: [10.940206494466953, 10.940206494466953, 10.940206494466953, 10.940206494466953, 10.940206494466953, 10.940206494466953, 10.940206494466953]
Episode 25 finished after 1 steps.
[Env][Action] [0, 0, 0, 1, 2, 1, 1]
[Action Encoded] [0, 0, 0, 1, 2, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 21, 'rrd': 4, 'refi': 51480}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 990468.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 21, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(3.27505261), array(3.27505261), array(3.27505261), array(3.27505261), array(3.27505261), array(3.27505261), array(3.27505261)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 10, 3, 7]
[Action Encoded] [1, 4, 4, 3, 10, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(2.27552163), array(2.27552163), array(2.27552163), array(2.27552163), array(2.27552163), array(2.27552163), array(2.27552163)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 2, 3, 2]
[Action Encoded] [1, 3, 3, 4, 2, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(5.68239185), array(5.68239185), array(5.68239185), array(5.68239185), array(5.68239185), array(5.68239185), array(5.68239185)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 2, 4, 0, 17, 2, 0]
[Action Encoded] [1, 2, 4, 0, 17, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 36, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 36, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(7.27678318), array(7.27678318), array(7.27678318), array(7.27678318), array(7.27678318), array(7.27678318), array(7.27678318)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 1, 3, 9]
[Action Encoded] [1, 4, 3, 4, 1, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(2.30211061), array(2.30211061), array(2.30211061), array(2.30211061), array(2.30211061), array(2.30211061), array(2.30211061)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 6, 0, 2]
[Action Encoded] [1, 4, 0, 3, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 3, 2, 2, 10, 0, 9]
[Action Encoded] [0, 3, 2, 2, 10, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(6.26668299), array(6.26668299), array(6.26668299), array(6.26668299), array(6.26668299), array(6.26668299), array(6.26668299)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 20, 3, 4]
[Action Encoded] [0, 4, 3, 4, 20, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 3, 2, 1, 6, 3, 1]
[Action Encoded] [1, 3, 2, 1, 6, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(5.61621716), array(5.61621716), array(5.61621716), array(5.61621716), array(5.61621716), array(5.61621716), array(5.61621716)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 3, 4, 3, 12, 3, 3]
[Action Encoded] [0, 3, 4, 3, 12, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(6.16909282), array(6.16909282), array(6.16909282), array(6.16909282), array(6.16909282), array(6.16909282), array(6.16909282)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 11, 2, 0]
[Action Encoded] [1, 3, 3, 0, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(4.40006507), array(4.40006507), array(4.40006507), array(4.40006507), array(4.40006507), array(4.40006507), array(4.40006507)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 0, 4, 3, 2, 1, 0]
[Action Encoded] [1, 0, 4, 3, 2, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(2.54806592), array(2.54806592), array(2.54806592), array(2.54806592), array(2.54806592), array(2.54806592), array(2.54806592)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 11, 2, 6]
[Action Encoded] [1, 1, 2, 4, 11, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(11.43106166), array(11.43106166), array(11.43106166), array(11.43106166), array(11.43106166), array(11.43106166), array(11.43106166)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 18, 0, 4]
[Action Encoded] [0, 3, 4, 1, 18, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(6.39310022), array(6.39310022), array(6.39310022), array(6.39310022), array(6.39310022), array(6.39310022), array(6.39310022)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 9, 3, 2]
[Action Encoded] [0, 3, 4, 0, 9, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 28, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 28, 'rrd': 6, 'refi': 98280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(6.18284776), array(6.18284776), array(6.18284776), array(6.18284776), array(6.18284776), array(6.18284776), array(6.18284776)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 4, 1, 0, 11, 0, 6]
[Action Encoded] [1, 4, 1, 0, 11, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 3, 2, 1, 19, 0, 5]
[Action Encoded] [0, 3, 2, 1, 19, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(6.52088706), array(6.52088706), array(6.52088706), array(6.52088706), array(6.52088706), array(6.52088706), array(6.52088706)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 14, 0, 5]
[Action Encoded] [0, 1, 0, 1, 14, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 0, 3, 0]
[Action Encoded] [0, 4, 2, 4, 0, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(1.73764145), array(1.73764145), array(1.73764145), array(1.73764145), array(1.73764145), array(1.73764145), array(1.73764145)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 1, 0, 0, 5, 1, 0]
[Action Encoded] [1, 1, 0, 0, 5, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(6.80078704), array(6.80078704), array(6.80078704), array(6.80078704), array(6.80078704), array(6.80078704), array(6.80078704)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 0, 0, 3, 8, 1, 7]
[Action Encoded] [1, 0, 0, 3, 8, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 27, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 27, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 4, 1, 4, 11, 2, 7]
[Action Encoded] [0, 4, 1, 4, 11, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(2.1868268), array(2.1868268), array(2.1868268), array(2.1868268), array(2.1868268), array(2.1868268), array(2.1868268)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 5, 2, 6]
[Action Encoded] [0, 1, 3, 4, 5, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [11.471828637227953, 11.471828637227953, 11.471828637227953, 11.471828637227953, 11.471828637227953, 11.471828637227953, 11.471828637227953]
Episode 48 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 14, 1, 0]
[Action Encoded] [0, 4, 2, 0, 14, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(1.81266011), array(1.81266011), array(1.81266011), array(1.81266011), array(1.81266011), array(1.81266011), array(1.81266011)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 2, 2, 1]
[Action Encoded] [1, 3, 3, 4, 2, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 11, 0, 1]
[Action Encoded] [0, 0, 3, 4, 11, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 14, 2, 9]
[Action Encoded] [1, 4, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 3, 1, 3]
[Action Encoded] [0, 1, 4, 4, 3, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.17686154), array(11.17686154), array(11.17686154), array(11.17686154), array(11.17686154), array(11.17686154), array(11.17686154)]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 11, 0, 2]
[Action Encoded] [1, 4, 2, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 3, 2, 4]
[Action Encoded] [1, 4, 2, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 4, 0, 0]
[Action Encoded] [1, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 15, 2, 2]
[Action Encoded] [1, 3, 4, 0, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 11, 1, 0]
[Action Encoded] [1, 3, 2, 0, 11, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.34702858), array(4.34702858), array(4.34702858), array(4.34702858), array(4.34702858), array(4.34702858), array(4.34702858)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 3]
[Action Encoded] [1, 4, 2, 4, 9, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 6, 0, 2]
[Action Encoded] [1, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 6, 1, 9]
[Action Encoded] [1, 1, 0, 1, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 7, 0, 9]
[Action Encoded] [1, 0, 2, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 6]
[Action Encoded] [0, 0, 0, 3, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 12, 0, 6]
[Action Encoded] [0, 0, 3, 0, 12, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
Episode: 69  Rewards: [3.2042754454904934, 3.2042754454904934, 3.2042754454904934, 3.2042754454904934, 3.2042754454904934, 3.2042754454904934, 3.2042754454904934]
Episode 69 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 20, 1, 2]
[Action Encoded] [1, 3, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(6.18974826), array(6.18974826), array(6.18974826), array(6.18974826), array(6.18974826), array(6.18974826), array(6.18974826)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 1, 1, 9]
[Action Encoded] [1, 4, 3, 3, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592)]
Episode 76 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 20, 0, 2]
[Action Encoded] [1, 0, 3, 4, 20, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 14, 0, 4]
[Action Encoded] [1, 4, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 17, 2, 6]
[Action Encoded] [0, 4, 3, 0, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 0, 2, 2, 0]
[Action Encoded] [1, 1, 0, 0, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 5, 2, 9]
[Action Encoded] [1, 3, 2, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 2]
[Action Encoded] [0, 0, 2, 4, 16, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 10, 1, 6]
[Action Encoded] [1, 3, 4, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.56828759), array(5.56828759), array(5.56828759), array(5.56828759), array(5.56828759), array(5.56828759), array(5.56828759)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 1, 2, 9]
[Action Encoded] [1, 3, 3, 0, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 85 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 16, 1, 4]
[Action Encoded] [1, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [2.287194122445763, 2.287194122445763, 2.287194122445763, 2.287194122445763, 2.287194122445763, 2.287194122445763, 2.287194122445763]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 2, 2, 4]
[Action Encoded] [1, 3, 3, 1, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 4, 3, 6, 2, 9]
[Action Encoded] [0, 0, 4, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 16, 1, 9]
[Action Encoded] [0, 0, 2, 1, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 4, 1, 1]
[Action Encoded] [0, 3, 4, 0, 4, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007)]
Episode 94 finished after 1 steps.
[Env][Action] [1, 1, 4, 4, 12, 1, 4]
[Action Encoded] [1, 1, 4, 4, 12, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242)]
Episode 95 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 4, 2, 4]
[Action Encoded] [1, 4, 2, 3, 4, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 14, 2, 3]
[Action Encoded] [1, 3, 2, 3, 14, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(6.38941756), array(6.38941756), array(6.38941756), array(6.38941756), array(6.38941756), array(6.38941756), array(6.38941756)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 10, 2, 2]
[Action Encoded] [1, 4, 4, 1, 10, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:33:38 UTC 2024
Total Execution Time: 38 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34419440.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 9
)
[Env][Action] [0, 2, 0, 1, 7, 2, 3]
[Action Encoded] [0, 2, 0, 1, 7, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 26, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 26, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(15.98876364), array(15.98876364), array(15.98876364), array(15.98876364), array(15.98876364), array(15.98876364), array(15.98876364)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 20, 0, 7]
[Action Encoded] [0, 4, 2, 4, 20, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(1.8565882), array(1.8565882), array(1.8565882), array(1.8565882), array(1.8565882), array(1.8565882), array(1.8565882)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 18, 0, 6]
[Action Encoded] [0, 3, 2, 4, 18, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 37, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 37, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(8.49967615), array(8.49967615), array(8.49967615), array(8.49967615), array(8.49967615), array(8.49967615), array(8.49967615)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 4, 1, 4, 4, 2, 5]
[Action Encoded] [1, 4, 1, 4, 4, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(1.87718973), array(1.87718973), array(1.87718973), array(1.87718973), array(1.87718973), array(1.87718973), array(1.87718973)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 2, 1, 7]
[Action Encoded] [1, 1, 0, 4, 2, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(15.62218945), array(15.62218945), array(15.62218945), array(15.62218945), array(15.62218945), array(15.62218945), array(15.62218945)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 1, 3, 0, 17, 0, 2]
[Action Encoded] [1, 1, 3, 0, 17, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(14.77920907), array(14.77920907), array(14.77920907), array(14.77920907), array(14.77920907), array(14.77920907), array(14.77920907)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 19, 0, 4]
[Action Encoded] [1, 1, 3, 4, 19, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(14.76324326), array(14.76324326), array(14.76324326), array(14.76324326), array(14.76324326), array(14.76324326), array(14.76324326)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 4, 1, 0, 14, 1, 3]
[Action Encoded] [0, 4, 1, 0, 14, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(1.96611654), array(1.96611654), array(1.96611654), array(1.96611654), array(1.96611654), array(1.96611654), array(1.96611654)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 8, 2, 8]
[Action Encoded] [1, 4, 2, 0, 8, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(1.94015207), array(1.94015207), array(1.94015207), array(1.94015207), array(1.94015207), array(1.94015207), array(1.94015207)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 2, 3, 0, 18, 0, 5]
[Action Encoded] [0, 2, 3, 0, 18, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 37, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 37, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(15.94025853), array(15.94025853), array(15.94025853), array(15.94025853), array(15.94025853), array(15.94025853), array(15.94025853)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 7, 2, 0]
[Action Encoded] [0, 2, 3, 2, 7, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(8.2858948), array(8.2858948), array(8.2858948), array(8.2858948), array(8.2858948), array(8.2858948), array(8.2858948)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 6, 3, 5]
[Action Encoded] [1, 0, 0, 4, 6, 3, 5]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(2.42870995), array(2.42870995), array(2.42870995), array(2.42870995), array(2.42870995), array(2.42870995), array(2.42870995)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 14, 1, 8]
[Action Encoded] [0, 0, 4, 2, 14, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 33, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 33, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(2.38448577), array(2.38448577), array(2.38448577), array(2.38448577), array(2.38448577), array(2.38448577), array(2.38448577)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 3, 0, 2, 7, 3, 3]
[Action Encoded] [1, 3, 0, 2, 7, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 26, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(8.72220088), array(8.72220088), array(8.72220088), array(8.72220088), array(8.72220088), array(8.72220088), array(8.72220088)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 1, 2, 3, 4, 1, 7]
[Action Encoded] [0, 1, 2, 3, 4, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 3, 2, 2, 10, 3, 4]
[Action Encoded] [1, 3, 2, 2, 10, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(8.55289159), array(8.55289159), array(8.55289159), array(8.55289159), array(8.55289159), array(8.55289159), array(8.55289159)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 0, 4, 0, 7, 1, 7]
[Action Encoded] [0, 0, 4, 0, 7, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(2.42759677), array(2.42759677), array(2.42759677), array(2.42759677), array(2.42759677), array(2.42759677), array(2.42759677)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 2, 3, 0, 12, 2, 4]
[Action Encoded] [1, 2, 3, 0, 12, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(14.9255558), array(14.9255558), array(14.9255558), array(14.9255558), array(14.9255558), array(14.9255558), array(14.9255558)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 0, 3, 9]
[Action Encoded] [1, 1, 4, 1, 0, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(15.46602943), array(15.46602943), array(15.46602943), array(15.46602943), array(15.46602943), array(15.46602943), array(15.46602943)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 0, 4, 3, 20, 3, 8]
[Action Encoded] [1, 0, 4, 3, 20, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(2.36019032), array(2.36019032), array(2.36019032), array(2.36019032), array(2.36019032), array(2.36019032), array(2.36019032)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 15, 3, 9]
[Action Encoded] [1, 3, 1, 3, 15, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 34, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 34, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(8.89260466), array(8.89260466), array(8.89260466), array(8.89260466), array(8.89260466), array(8.89260466), array(8.89260466)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 2, 3, 4]
[Action Encoded] [1, 3, 4, 0, 2, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 21, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 21, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(8.65781642), array(8.65781642), array(8.65781642), array(8.65781642), array(8.65781642), array(8.65781642), array(8.65781642)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 15, 2, 4]
[Action Encoded] [0, 2, 3, 2, 15, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(15.90924998), array(15.90924998), array(15.90924998), array(15.90924998), array(15.90924998), array(15.90924998), array(15.90924998)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 4, 2, 2, 19, 1, 9]
[Action Encoded] [1, 4, 2, 2, 19, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 38, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 38, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(1.90192746), array(1.90192746), array(1.90192746), array(1.90192746), array(1.90192746), array(1.90192746), array(1.90192746)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 17, 0, 4]
[Action Encoded] [1, 0, 0, 0, 17, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.53036222), array(2.53036222), array(2.53036222), array(2.53036222), array(2.53036222), array(2.53036222), array(2.53036222)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 4, 1, 0, 3, 2, 0]
[Action Encoded] [0, 4, 1, 0, 3, 2, 0]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(1.39637355), array(1.39637355), array(1.39637355), array(1.39637355), array(1.39637355), array(1.39637355), array(1.39637355)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 3, 2, 1, 19, 1, 2]
[Action Encoded] [0, 3, 2, 1, 19, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(8.41511229), array(8.41511229), array(8.41511229), array(8.41511229), array(8.41511229), array(8.41511229), array(8.41511229)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 4, 2, 2, 15, 1, 1]
[Action Encoded] [1, 4, 2, 2, 15, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(1.87191919), array(1.87191919), array(1.87191919), array(1.87191919), array(1.87191919), array(1.87191919), array(1.87191919)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 13, 2, 0]
[Action Encoded] [0, 2, 0, 0, 13, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 11, 0, 7]
[Action Encoded] [0, 2, 1, 3, 11, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(16.02050783), array(16.02050783), array(16.02050783), array(16.02050783), array(16.02050783), array(16.02050783), array(16.02050783)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 2, 2, 2, 17, 2, 3]
[Action Encoded] [0, 2, 2, 2, 17, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(15.97972498), array(15.97972498), array(15.97972498), array(15.97972498), array(15.97972498), array(15.97972498), array(15.97972498)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 2, 3, 0, 1, 1, 2]
[Action Encoded] [1, 2, 3, 0, 1, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(14.64977932), array(14.64977932), array(14.64977932), array(14.64977932), array(14.64977932), array(14.64977932), array(14.64977932)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 4, 1, 2, 5, 0, 7]
[Action Encoded] [0, 4, 1, 2, 5, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(1.91847956), array(1.91847956), array(1.91847956), array(1.91847956), array(1.91847956), array(1.91847956), array(1.91847956)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 4, 4, 2, 9, 2, 9]
[Action Encoded] [0, 4, 4, 2, 9, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 28, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 28, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(1.85960804), array(1.85960804), array(1.85960804), array(1.85960804), array(1.85960804), array(1.85960804), array(1.85960804)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 0, 4, 2, 11, 2, 5]
[Action Encoded] [1, 0, 4, 2, 11, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(2.37641835), array(2.37641835), array(2.37641835), array(2.37641835), array(2.37641835), array(2.37641835), array(2.37641835)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 15, 2, 7]
[Action Encoded] [1, 0, 0, 0, 15, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(2.52990489), array(2.52990489), array(2.52990489), array(2.52990489), array(2.52990489), array(2.52990489), array(2.52990489)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 0, 3, 1, 6, 1, 6]
[Action Encoded] [1, 0, 3, 1, 6, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(2.42898088), array(2.42898088), array(2.42898088), array(2.42898088), array(2.42898088), array(2.42898088), array(2.42898088)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 16, 1, 8]
[Action Encoded] [1, 1, 2, 0, 16, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 35, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 35, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(14.87923404), array(14.87923404), array(14.87923404), array(14.87923404), array(14.87923404), array(14.87923404), array(14.87923404)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 17, 0, 0]
[Action Encoded] [0, 4, 3, 0, 17, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(1.37378669), array(1.37378669), array(1.37378669), array(1.37378669), array(1.37378669), array(1.37378669), array(1.37378669)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 9, 3, 0]
[Action Encoded] [1, 3, 3, 1, 9, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 6, 'refi': 4680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 38687326.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(5.04867561), array(5.04867561), array(5.04867561), array(5.04867561), array(5.04867561), array(5.04867561), array(5.04867561)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 13, 1, 1]
[Action Encoded] [0, 3, 4, 4, 13, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 32, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 32, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(8.09146018), array(8.09146018), array(8.09146018), array(8.09146018), array(8.09146018), array(8.09146018), array(8.09146018)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 0, 4, 0, 3, 3, 4]
[Action Encoded] [0, 0, 4, 0, 3, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(2.4269053), array(2.4269053), array(2.4269053), array(2.4269053), array(2.4269053), array(2.4269053), array(2.4269053)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 3, 1, 1, 16, 0, 8]
[Action Encoded] [1, 3, 1, 1, 16, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(9.08938063), array(9.08938063), array(9.08938063), array(9.08938063), array(9.08938063), array(9.08938063), array(9.08938063)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 14, 2, 9]
[Action Encoded] [1, 4, 3, 2, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(1.88094423), array(1.88094423), array(1.88094423), array(1.88094423), array(1.88094423), array(1.88094423), array(1.88094423)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 10, 2, 5]
[Action Encoded] [1, 3, 4, 1, 10, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(8.08920149), array(8.08920149), array(8.08920149), array(8.08920149), array(8.08920149), array(8.08920149), array(8.08920149)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 1, 3, 2, 13, 1, 6]
[Action Encoded] [0, 1, 3, 2, 13, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 32, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 32, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 16, 1, 9]
[Action Encoded] [1, 0, 2, 1, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(2.45815412), array(2.45815412), array(2.45815412), array(2.45815412), array(2.45815412), array(2.45815412), array(2.45815412)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 1, 2, 7]
[Action Encoded] [0, 1, 2, 1, 1, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(16.02079411), array(16.02079411), array(16.02079411), array(16.02079411), array(16.02079411), array(16.02079411), array(16.02079411)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 0, 1, 8]
[Action Encoded] [0, 2, 1, 1, 0, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(16.03495685), array(16.03495685), array(16.03495685), array(16.03495685), array(16.03495685), array(16.03495685), array(16.03495685)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 1, 3, 2, 3, 1, 7]
[Action Encoded] [0, 1, 3, 2, 3, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936), array(16.01484936)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:34:49 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent0', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 12
)
[Env][Action] [1, 1, 1, 1, 1, 2, 4]
[Action Encoded] [1, 1, 1, 1, 1, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(10.75100518), array(10.75100518), array(10.75100518), array(10.75100518), array(10.75100518), array(10.75100518), array(10.75100518)]
Episode 1 finished after 1 steps.
[Env][Action] [1, 1, 3, 3, 17, 0, 3]
[Action Encoded] [1, 1, 3, 3, 17, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 7, 2, 6]
[Action Encoded] [0, 0, 4, 2, 7, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(3.12847098), array(3.12847098), array(3.12847098), array(3.12847098), array(3.12847098), array(3.12847098), array(3.12847098)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 9, 2, 3]
[Action Encoded] [0, 4, 0, 0, 9, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 0, 3, 4]
[Action Encoded] [1, 2, 3, 1, 0, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(10.49925307), array(10.49925307), array(10.49925307), array(10.49925307), array(10.49925307), array(10.49925307), array(10.49925307)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 12, 2, 3]
[Action Encoded] [1, 3, 2, 3, 12, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 31, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 31, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 9, 3, 3]
[Action Encoded] [1, 0, 0, 0, 9, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 1, 2, 2, 2, 2, 4]
[Action Encoded] [0, 1, 2, 2, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 8  Rewards: [11.579196363854273, 11.579196363854273, 11.579196363854273, 11.579196363854273, 11.579196363854273, 11.579196363854273, 11.579196363854273]
Episode 8 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 10, 2, 7]
[Action Encoded] [1, 3, 4, 1, 10, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(5.72639591), array(5.72639591), array(5.72639591), array(5.72639591), array(5.72639591), array(5.72639591), array(5.72639591)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 3, 3, 2, 18, 0, 9]
[Action Encoded] [1, 3, 3, 2, 18, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(6.29871033), array(6.29871033), array(6.29871033), array(6.29871033), array(6.29871033), array(6.29871033), array(6.29871033)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 20, 0, 4]
[Action Encoded] [1, 0, 2, 3, 20, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 39, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 39, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 0, 3, 1, 1, 2, 0]
[Action Encoded] [1, 0, 3, 1, 1, 2, 0]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 990468.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 5]
[Action Encoded] [0, 4, 3, 3, 14, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 13  Rewards: [2.2241446651454724, 2.2241446651454724, 2.2241446651454724, 2.2241446651454724, 2.2241446651454724, 2.2241446651454724, 2.2241446651454724]
Episode 13 finished after 1 steps.
[Env][Action] [0, 3, 4, 2, 14, 0, 6]
[Action Encoded] [0, 3, 4, 2, 14, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 33, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 33, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 14  Rewards: [6.273771994276163, 6.273771994276163, 6.273771994276163, 6.273771994276163, 6.273771994276163, 6.273771994276163, 6.273771994276163]
Episode 14 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 3, 0, 5]
[Action Encoded] [0, 2, 1, 3, 3, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 22, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 22, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(11.10913615), array(11.10913615), array(11.10913615), array(11.10913615), array(11.10913615), array(11.10913615), array(11.10913615)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 2, 0, 2, 16, 3, 0]
[Action Encoded] [0, 2, 0, 2, 16, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 35, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 35, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(7.58672024), array(7.58672024), array(7.58672024), array(7.58672024), array(7.58672024), array(7.58672024), array(7.58672024)]
Episode 16 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 5, 3, 8]
[Action Encoded] [1, 3, 4, 1, 5, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 4, 3, 1]
[Action Encoded] [0, 0, 3, 0, 4, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 14, 3, 4]
[Action Encoded] [1, 0, 0, 2, 14, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 33, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 33, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 2, 4, 2, 5, 1, 2]
[Action Encoded] [0, 2, 4, 2, 5, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 24, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 24, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 17, 0, 1]
[Action Encoded] [0, 2, 0, 0, 17, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(12.0003377), array(12.0003377), array(12.0003377), array(12.0003377), array(12.0003377), array(12.0003377), array(12.0003377)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 3, 1, 2, 13, 3, 9]
[Action Encoded] [1, 3, 1, 2, 13, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 2, 2, 4, 15, 3, 9]
[Action Encoded] [1, 2, 2, 4, 15, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(11.35118345), array(11.35118345), array(11.35118345), array(11.35118345), array(11.35118345), array(11.35118345), array(11.35118345)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 2, 1, 3]
[Action Encoded] [1, 2, 4, 4, 2, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(10.95607336), array(10.95607336), array(10.95607336), array(10.95607336), array(10.95607336), array(10.95607336), array(10.95607336)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 2, 4, 0, 11, 2, 2]
[Action Encoded] [0, 2, 4, 0, 11, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(11.69382753), array(11.69382753), array(11.69382753), array(11.69382753), array(11.69382753), array(11.69382753), array(11.69382753)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 4, 3, 2]
[Action Encoded] [0, 1, 0, 1, 4, 3, 2]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 0, 1, 4, 6, 1, 7]
[Action Encoded] [1, 0, 1, 4, 6, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 4, 3, 2]
[Action Encoded] [0, 0, 0, 2, 4, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 23, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 23, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 4, 1, 3, 17, 0, 2]
[Action Encoded] [0, 4, 1, 3, 17, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 2, 3, 3, 16, 1, 0]
[Action Encoded] [0, 2, 3, 3, 16, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(7.2681767), array(7.2681767), array(7.2681767), array(7.2681767), array(7.2681767), array(7.2681767), array(7.2681767)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 20, 2, 2]
[Action Encoded] [0, 4, 2, 2, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 14, 1, 6]
[Action Encoded] [0, 0, 0, 2, 14, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 33, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 33, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 15, 2, 2]
[Action Encoded] [0, 1, 3, 0, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 1, 0, 20, 0, 5]
[Action Encoded] [1, 0, 1, 0, 20, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(3.28715392), array(3.28715392), array(3.28715392), array(3.28715392), array(3.28715392), array(3.28715392), array(3.28715392)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 6, 1, 4]
[Action Encoded] [0, 3, 4, 0, 6, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 3, 1, 4, 15, 3, 9]
[Action Encoded] [1, 3, 1, 4, 15, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(6.3346824), array(6.3346824), array(6.3346824), array(6.3346824), array(6.3346824), array(6.3346824), array(6.3346824)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 1, 0, 0]
[Action Encoded] [0, 3, 2, 4, 1, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 20, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 20, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(4.51639333), array(4.51639333), array(4.51639333), array(4.51639333), array(4.51639333), array(4.51639333), array(4.51639333)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 4, 1, 1, 15, 0, 3]
[Action Encoded] [1, 4, 1, 1, 15, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 14, 0, 4]
[Action Encoded] [1, 3, 4, 4, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(6.18629609), array(6.18629609), array(6.18629609), array(6.18629609), array(6.18629609), array(6.18629609), array(6.18629609)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 8, 1, 5]
[Action Encoded] [0, 3, 4, 1, 8, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 0, 3, 2, 3, 3, 5]
[Action Encoded] [0, 0, 3, 2, 3, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 4, 1, 4]
[Action Encoded] [1, 2, 3, 4, 4, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 42  Rewards: [10.745679351962204, 10.745679351962204, 10.745679351962204, 10.745679351962204, 10.745679351962204, 10.745679351962204, 10.745679351962204]
Episode 42 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 8, 3, 4]
[Action Encoded] [0, 1, 0, 1, 8, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 9, 3, 6]
[Action Encoded] [0, 4, 0, 1, 9, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 28, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 28, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 2, 4, 3, 19, 1, 2]
[Action Encoded] [0, 2, 4, 3, 19, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 38, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 38, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 2, 0, 2, 17, 0, 3]
[Action Encoded] [0, 2, 0, 2, 17, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(11.93398513), array(11.93398513), array(11.93398513), array(11.93398513), array(11.93398513), array(11.93398513), array(11.93398513)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 3, 0, 4]
[Action Encoded] [0, 3, 2, 4, 3, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(6.20012794), array(6.20012794), array(6.20012794), array(6.20012794), array(6.20012794), array(6.20012794), array(6.20012794)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 0, 4, 0, 3, 3, 6]
[Action Encoded] [0, 0, 4, 0, 3, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 1, 4, 3, 18, 3, 7]
[Action Encoded] [1, 1, 4, 3, 18, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 37, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 37, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(11.22365928), array(11.22365928), array(11.22365928), array(11.22365928), array(11.22365928), array(11.22365928), array(11.22365928)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 1, 3, 1, 4, 0, 5]
[Action Encoded] [1, 1, 3, 1, 4, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(10.98599983), array(10.98599983), array(10.98599983), array(10.98599983), array(10.98599983), array(10.98599983), array(10.98599983)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 19, 0, 1]
[Action Encoded] [0, 0, 3, 4, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 14, 2, 9]
[Action Encoded] [1, 4, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412), array(2.28719412)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 3, 1, 3]
[Action Encoded] [0, 1, 3, 4, 3, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 11, 0, 2]
[Action Encoded] [1, 4, 2, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 3, 2, 4]
[Action Encoded] [1, 4, 2, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816), array(2.40333816)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 1, 0, 0]
[Action Encoded] [1, 1, 4, 1, 1, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 15, 2, 2]
[Action Encoded] [1, 3, 4, 0, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 11, 2, 0]
[Action Encoded] [1, 3, 2, 0, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 3]
[Action Encoded] [1, 4, 2, 4, 9, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 6, 0, 2]
[Action Encoded] [1, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 6, 1, 9]
[Action Encoded] [1, 1, 0, 1, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 7, 0, 9]
[Action Encoded] [1, 0, 2, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 6]
[Action Encoded] [0, 0, 0, 3, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 4, 0, 6]
[Action Encoded] [0, 0, 3, 0, 4, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 69 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 1, 1, 2]
[Action Encoded] [1, 3, 4, 4, 1, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 20, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 20, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(4.82052537), array(4.82052537), array(4.82052537), array(4.82052537), array(4.82052537), array(4.82052537), array(4.82052537)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 1, 1, 9]
[Action Encoded] [0, 4, 3, 3, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 2]
[Action Encoded] [0, 0, 3, 4, 20, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 14, 0, 4]
[Action Encoded] [1, 4, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 17, 2, 6]
[Action Encoded] [0, 4, 3, 0, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 0, 2, 2, 0]
[Action Encoded] [1, 1, 0, 0, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972), array(6.87907972)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 5, 2, 9]
[Action Encoded] [1, 3, 2, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 0, 14, 1, 2]
[Action Encoded] [0, 0, 2, 0, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 98280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 1, 2, 9]
[Action Encoded] [1, 3, 3, 0, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 16, 1, 4]
[Action Encoded] [0, 4, 3, 0, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 2, 2, 4]
[Action Encoded] [1, 3, 3, 1, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 16, 1, 9]
[Action Encoded] [0, 0, 2, 1, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 4, 1, 1]
[Action Encoded] [0, 3, 4, 0, 4, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007), array(6.04141007)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 1, 4]
[Action Encoded] [0, 1, 4, 4, 12, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 4, 2, 4]
[Action Encoded] [1, 4, 2, 3, 4, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 14, 2, 3]
[Action Encoded] [1, 0, 2, 3, 14, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 20, 2, 2]
[Action Encoded] [1, 4, 4, 1, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:35:29 UTC 2024
Total Execution Time: 40 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34377147.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent1', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 12
)
[Env][Action] [0, 2, 0, 2, 10, 0, 7]
[Action Encoded] [0, 2, 0, 2, 10, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 1, 1, 0, 9, 2, 1]
[Action Encoded] [0, 1, 1, 0, 9, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(15.12764045), array(15.12764045), array(15.12764045), array(15.12764045), array(15.12764045), array(15.12764045), array(15.12764045)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 2, 0, 3, 14, 1, 3]
[Action Encoded] [0, 2, 0, 3, 14, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(15.9840872), array(15.9840872), array(15.9840872), array(15.9840872), array(15.9840872), array(15.9840872), array(15.9840872)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 3, 0, 0, 9, 0, 1]
[Action Encoded] [0, 3, 0, 0, 9, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(8.23748781), array(8.23748781), array(8.23748781), array(8.23748781), array(8.23748781), array(8.23748781), array(8.23748781)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 12, 3, 4]
[Action Encoded] [1, 3, 3, 3, 12, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(9.00731734), array(9.00731734), array(9.00731734), array(9.00731734), array(9.00731734), array(9.00731734), array(9.00731734)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 2, 0, 3, 4, 0, 7]
[Action Encoded] [0, 2, 0, 3, 4, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(16.02396066), array(16.02396066), array(16.02396066), array(16.02396066), array(16.02396066), array(16.02396066), array(16.02396066)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 17, 1, 7]
[Action Encoded] [1, 2, 3, 4, 17, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(14.84347431), array(14.84347431), array(14.84347431), array(14.84347431), array(14.84347431), array(14.84347431), array(14.84347431)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 18, 2, 6]
[Action Encoded] [1, 1, 2, 2, 18, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 37, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 37, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(14.77627841), array(14.77627841), array(14.77627841), array(14.77627841), array(14.77627841), array(14.77627841), array(14.77627841)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 0, 3, 3, 13, 3, 0]
[Action Encoded] [0, 0, 3, 3, 13, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(1.65489785), array(1.65489785), array(1.65489785), array(1.65489785), array(1.65489785), array(1.65489785), array(1.65489785)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 3, 1, 1, 12, 0, 7]
[Action Encoded] [0, 3, 1, 1, 12, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(8.53780908), array(8.53780908), array(8.53780908), array(8.53780908), array(8.53780908), array(8.53780908), array(8.53780908)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 4, 2, 6]
[Action Encoded] [1, 0, 0, 2, 4, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 23, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 23, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(2.4787999), array(2.4787999), array(2.4787999), array(2.4787999), array(2.4787999), array(2.4787999), array(2.4787999)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 11, 0, 4]
[Action Encoded] [0, 1, 3, 3, 11, 0, 4]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(15.93548935), array(15.93548935), array(15.93548935), array(15.93548935), array(15.93548935), array(15.93548935), array(15.93548935)]
Episode 12 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 0, 3, 0]
[Action Encoded] [1, 0, 3, 2, 0, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(1.6756103), array(1.6756103), array(1.6756103), array(1.6756103), array(1.6756103), array(1.6756103), array(1.6756103)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 0, 3, 3, 13, 0, 5]
[Action Encoded] [1, 0, 3, 3, 13, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 32, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 32, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(2.38082118), array(2.38082118), array(2.38082118), array(2.38082118), array(2.38082118), array(2.38082118), array(2.38082118)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 14, 3, 8]
[Action Encoded] [1, 3, 4, 0, 14, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 33, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 33, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(8.70739106), array(8.70739106), array(8.70739106), array(8.70739106), array(8.70739106), array(8.70739106), array(8.70739106)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 1, 4, 3, 20, 0, 6]
[Action Encoded] [1, 1, 4, 3, 20, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(14.85982072), array(14.85982072), array(14.85982072), array(14.85982072), array(14.85982072), array(14.85982072), array(14.85982072)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 1, 4, 0, 3, 1, 0]
[Action Encoded] [0, 1, 4, 0, 3, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(8.30064949), array(8.30064949), array(8.30064949), array(8.30064949), array(8.30064949), array(8.30064949), array(8.30064949)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 13, 0, 1]
[Action Encoded] [1, 2, 3, 2, 13, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(14.35450017), array(14.35450017), array(14.35450017), array(14.35450017), array(14.35450017), array(14.35450017), array(14.35450017)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 2, 1, 2, 0, 1, 7]
[Action Encoded] [1, 2, 1, 2, 0, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(15.54752489), array(15.54752489), array(15.54752489), array(15.54752489), array(15.54752489), array(15.54752489), array(15.54752489)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 0, 2, 2]
[Action Encoded] [0, 0, 2, 4, 0, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(2.36822321), array(2.36822321), array(2.36822321), array(2.36822321), array(2.36822321), array(2.36822321), array(2.36822321)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 4, 1, 20, 1, 9]
[Action Encoded] [1, 0, 4, 1, 20, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(2.40551592), array(2.40551592), array(2.40551592), array(2.40551592), array(2.40551592), array(2.40551592), array(2.40551592)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 2, 1, 2, 20, 2, 6]
[Action Encoded] [1, 2, 1, 2, 20, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(15.57832497), array(15.57832497), array(15.57832497), array(15.57832497), array(15.57832497), array(15.57832497), array(15.57832497)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 2, 2, 4]
[Action Encoded] [1, 4, 3, 0, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(1.91459483), array(1.91459483), array(1.91459483), array(1.91459483), array(1.91459483), array(1.91459483), array(1.91459483)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 6, 0, 7]
[Action Encoded] [1, 3, 4, 3, 6, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(7.90402746), array(7.90402746), array(7.90402746), array(7.90402746), array(7.90402746), array(7.90402746), array(7.90402746)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 12, 0, 0]
[Action Encoded] [1, 1, 4, 1, 12, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 31, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 31, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(7.89366979), array(7.89366979), array(7.89366979), array(7.89366979), array(7.89366979), array(7.89366979), array(7.89366979)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 4, 1, 1, 3, 0, 9]
[Action Encoded] [0, 4, 1, 1, 3, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 425880}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(1.94325579), array(1.94325579), array(1.94325579), array(1.94325579), array(1.94325579), array(1.94325579), array(1.94325579)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 14, 1, 5]
[Action Encoded] [1, 0, 2, 1, 14, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 33, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 33, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(2.4533534), array(2.4533534), array(2.4533534), array(2.4533534), array(2.4533534), array(2.4533534), array(2.4533534)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 4, 1, 0, 7, 0, 1]
[Action Encoded] [0, 4, 1, 0, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(1.93458361), array(1.93458361), array(1.93458361), array(1.93458361), array(1.93458361), array(1.93458361), array(1.93458361)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 4, 4, 0, 15, 2, 6]
[Action Encoded] [0, 4, 4, 0, 15, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(1.89715214), array(1.89715214), array(1.89715214), array(1.89715214), array(1.89715214), array(1.89715214), array(1.89715214)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 5, 3, 6]
[Action Encoded] [0, 1, 4, 3, 5, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 0, 2, 2, 8, 3, 1]
[Action Encoded] [0, 0, 2, 2, 8, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(2.37448096), array(2.37448096), array(2.37448096), array(2.37448096), array(2.37448096), array(2.37448096), array(2.37448096)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 2, 3, 4, 15, 2, 7]
[Action Encoded] [0, 2, 3, 4, 15, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954), array(16.01297954)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 20, 2, 6]
[Action Encoded] [1, 0, 4, 4, 20, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(2.33214482), array(2.33214482), array(2.33214482), array(2.33214482), array(2.33214482), array(2.33214482), array(2.33214482)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 4, 0, 1, 3, 9]
[Action Encoded] [1, 0, 4, 0, 1, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 20, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 20, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 34 finished after 1 steps.
[Env][Action] [1, 4, 1, 3, 6, 3, 5]
[Action Encoded] [1, 4, 1, 3, 6, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 25, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 25, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(1.8981712), array(1.8981712), array(1.8981712), array(1.8981712), array(1.8981712), array(1.8981712), array(1.8981712)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 10, 1, 4]
[Action Encoded] [0, 4, 3, 3, 10, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 11, 3, 0]
[Action Encoded] [1, 1, 2, 2, 11, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(8.03732098), array(8.03732098), array(8.03732098), array(8.03732098), array(8.03732098), array(8.03732098), array(8.03732098)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 15, 1, 3]
[Action Encoded] [1, 3, 0, 0, 15, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(9.16449847), array(9.16449847), array(9.16449847), array(9.16449847), array(9.16449847), array(9.16449847), array(9.16449847)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 19, 2, 5]
[Action Encoded] [1, 1, 0, 4, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(15.01601074), array(15.01601074), array(15.01601074), array(15.01601074), array(15.01601074), array(15.01601074), array(15.01601074)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 2, 4, 3, 17, 1, 3]
[Action Encoded] [0, 2, 4, 3, 17, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 36, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 36, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 40  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
[array(15.97163004), array(15.97163004), array(15.97163004), array(15.97163004), array(15.97163004), array(15.97163004), array(15.97163004)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 1, 2, 0, 14, 2, 7]
[Action Encoded] [0, 1, 2, 0, 14, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 33, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 1, 0, 0, 4, 3, 4]
[Action Encoded] [1, 1, 0, 0, 4, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 23, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 23, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(15.5711666), array(15.5711666), array(15.5711666), array(15.5711666), array(15.5711666), array(15.5711666), array(15.5711666)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 20, 2, 7]
[Action Encoded] [1, 1, 3, 4, 20, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(14.86413041), array(14.86413041), array(14.86413041), array(14.86413041), array(14.86413041), array(14.86413041), array(14.86413041)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 2, 3, 6]
[Action Encoded] [0, 1, 4, 3, 2, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763), array(16.01234763)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 2, 4, 0, 10, 2, 2]
[Action Encoded] [0, 2, 4, 0, 10, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(15.72691478), array(15.72691478), array(15.72691478), array(15.72691478), array(15.72691478), array(15.72691478), array(15.72691478)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 13, 1, 5]
[Action Encoded] [0, 2, 1, 3, 13, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(15.938084), array(15.938084), array(15.938084), array(15.938084), array(15.938084), array(15.938084), array(15.938084)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 9, 2, 3]
[Action Encoded] [1, 1, 3, 4, 9, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 28, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 28, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(14.70633118), array(14.70633118), array(14.70633118), array(14.70633118), array(14.70633118), array(14.70633118), array(14.70633118)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 3, 1, 1]
[Action Encoded] [1, 3, 4, 1, 3, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(7.85590523), array(7.85590523), array(7.85590523), array(7.85590523), array(7.85590523), array(7.85590523), array(7.85590523)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 0, 4, 3, 7, 3, 0]
[Action Encoded] [0, 0, 4, 3, 7, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 26, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 26, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(1.64826431), array(1.64826431), array(1.64826431), array(1.64826431), array(1.64826431), array(1.64826431), array(1.64826431)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 15, 2, 0]
[Action Encoded] [0, 4, 0, 1, 15, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(1.39806952), array(1.39806952), array(1.39806952), array(1.39806952), array(1.39806952), array(1.39806952), array(1.39806952)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:36:38 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent1', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 10
)
[Env][Action] [0, 4, 3, 2, 10, 3, 3]
[Action Encoded] [0, 4, 3, 2, 10, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(2.26821072), array(2.26821072), array(2.26821072), array(2.26821072), array(2.26821072), array(2.26821072), array(2.26821072)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 8, 3, 4]
[Action Encoded] [0, 2, 1, 1, 8, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 3, 1, 4, 3, 3, 5]
[Action Encoded] [1, 3, 1, 4, 3, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 22, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 22, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(5.41867557), array(5.41867557), array(5.41867557), array(5.41867557), array(5.41867557), array(5.41867557), array(5.41867557)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 4, 4, 2, 18, 1, 6]
[Action Encoded] [0, 4, 4, 2, 18, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 37, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 37, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(2.17839214), array(2.17839214), array(2.17839214), array(2.17839214), array(2.17839214), array(2.17839214), array(2.17839214)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 1, 0, 4]
[Action Encoded] [1, 0, 0, 4, 1, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 20, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 20, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(3.24035007), array(3.24035007), array(3.24035007), array(3.24035007), array(3.24035007), array(3.24035007), array(3.24035007)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 2, 4, 1, 3, 1, 2]
[Action Encoded] [1, 2, 4, 1, 3, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 0, 4, 3, 16, 0, 8]
[Action Encoded] [0, 0, 4, 3, 16, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 35, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 35, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304), array(3.09973304)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 3, 3, 3]
[Action Encoded] [1, 1, 2, 2, 3, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(10.49837059), array(10.49837059), array(10.49837059), array(10.49837059), array(10.49837059), array(10.49837059), array(10.49837059)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 2, 3, 1]
[Action Encoded] [0, 1, 4, 4, 2, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.34238628), array(11.34238628), array(11.34238628), array(11.34238628), array(11.34238628), array(11.34238628), array(11.34238628)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 3, 1, 1, 17, 1, 6]
[Action Encoded] [1, 3, 1, 1, 17, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 36, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 36, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 4, 1, 7]
[Action Encoded] [0, 2, 0, 4, 4, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 2, 1, 4, 13, 1, 5]
[Action Encoded] [0, 2, 1, 4, 13, 1, 5]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 32, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 32, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 12  Rewards: [11.559621399279923, 11.559621399279923, 11.559621399279923, 11.559621399279923, 11.559621399279923, 11.559621399279923, 11.559621399279923]
Episode 12 finished after 1 steps.
[Env][Action] [1, 1, 2, 3, 19, 0, 3]
[Action Encoded] [1, 1, 2, 3, 19, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(11.29459533), array(11.29459533), array(11.29459533), array(11.29459533), array(11.29459533), array(11.29459533), array(11.29459533)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 4, 0, 2, 9, 3, 7]
[Action Encoded] [0, 4, 0, 2, 9, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 3, 4, 2, 12, 3, 7]
[Action Encoded] [1, 3, 4, 2, 12, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 31, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 31, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(6.05129781), array(6.05129781), array(6.05129781), array(6.05129781), array(6.05129781), array(6.05129781), array(6.05129781)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 14, 1, 5]
[Action Encoded] [1, 0, 3, 2, 14, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 33, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 33, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 19, 1, 3]
[Action Encoded] [0, 4, 2, 4, 19, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 13, 3, 7]
[Action Encoded] [1, 3, 4, 0, 13, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(5.82870672), array(5.82870672), array(5.82870672), array(5.82870672), array(5.82870672), array(5.82870672), array(5.82870672)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 3, 0, 0, 20, 3, 3]
[Action Encoded] [0, 3, 0, 0, 20, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(6.5750023), array(6.5750023), array(6.5750023), array(6.5750023), array(6.5750023), array(6.5750023), array(6.5750023)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 1, 3, 0, 3, 0, 4]
[Action Encoded] [1, 1, 3, 0, 3, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(10.74382348), array(10.74382348), array(10.74382348), array(10.74382348), array(10.74382348), array(10.74382348), array(10.74382348)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 12, 2, 5]
[Action Encoded] [1, 0, 0, 4, 12, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 14, 2, 7]
[Action Encoded] [0, 1, 3, 0, 14, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 33, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 33, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 4, 2, 4]
[Action Encoded] [0, 0, 4, 4, 4, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 8, 1, 0]
[Action Encoded] [0, 2, 1, 2, 8, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 27, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 27, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(7.39499807), array(7.39499807), array(7.39499807), array(7.39499807), array(7.39499807), array(7.39499807), array(7.39499807)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 4, 1, 0, 20, 3, 9]
[Action Encoded] [1, 4, 1, 0, 20, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 0, 4, 2, 17, 2, 8]
[Action Encoded] [1, 0, 4, 2, 17, 2, 8]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(3.14354552), array(3.14354552), array(3.14354552), array(3.14354552), array(3.14354552), array(3.14354552), array(3.14354552)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 17, 0, 3]
[Action Encoded] [0, 1, 0, 1, 17, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 36, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 36, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353), array(11.64627353)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 19, 0, 1]
[Action Encoded] [0, 1, 3, 3, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 3, 4, 3, 3, 2, 2]
[Action Encoded] [0, 3, 4, 3, 3, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [6.186296088053687, 6.186296088053687, 6.186296088053687, 6.186296088053687, 6.186296088053687, 6.186296088053687, 6.186296088053687]
Episode 29 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 20, 0, 0]
[Action Encoded] [1, 3, 4, 0, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 11, 3, 0]
[Action Encoded] [1, 4, 2, 3, 11, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(1.84366553), array(1.84366553), array(1.84366553), array(1.84366553), array(1.84366553), array(1.84366553), array(1.84366553)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 3, 1, 3, 12, 3, 0]
[Action Encoded] [0, 3, 1, 3, 12, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(4.60176938), array(4.60176938), array(4.60176938), array(4.60176938), array(4.60176938), array(4.60176938), array(4.60176938)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 13, 2, 3]
[Action Encoded] [1, 2, 3, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(11.0119717), array(11.0119717), array(11.0119717), array(11.0119717), array(11.0119717), array(11.0119717), array(11.0119717)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 11, 2, 3]
[Action Encoded] [0, 4, 0, 1, 11, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 3, 1, 0, 3, 3, 5]
[Action Encoded] [1, 3, 1, 0, 3, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(5.33783873), array(5.33783873), array(5.33783873), array(5.33783873), array(5.33783873), array(5.33783873), array(5.33783873)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 3, 2, 7]
[Action Encoded] [0, 2, 0, 0, 3, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 3, 3, 2, 20, 3, 3]
[Action Encoded] [0, 3, 3, 2, 20, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 1, 1, 0, 5, 1, 9]
[Action Encoded] [0, 1, 1, 0, 5, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 38  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 38 finished after 1 steps.
[Env][Action] [1, 3, 0, 1, 14, 0, 8]
[Action Encoded] [1, 3, 0, 1, 14, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(6.38206495), array(6.38206495), array(6.38206495), array(6.38206495), array(6.38206495), array(6.38206495), array(6.38206495)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 17, 1, 3]
[Action Encoded] [1, 0, 0, 2, 17, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 15, 1, 8]
[Action Encoded] [1, 2, 1, 1, 15, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 2, 0, 0, 12, 3, 1]
[Action Encoded] [1, 2, 0, 0, 12, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(11.87769274), array(11.87769274), array(11.87769274), array(11.87769274), array(11.87769274), array(11.87769274), array(11.87769274)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 15, 2, 7]
[Action Encoded] [0, 4, 2, 2, 15, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 6, 0, 8]
[Action Encoded] [0, 1, 2, 4, 6, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 0, 3, 3, 15, 1, 7]
[Action Encoded] [0, 0, 3, 3, 15, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(3.13548773), array(3.13548773), array(3.13548773), array(3.13548773), array(3.13548773), array(3.13548773), array(3.13548773)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 9, 3, 7]
[Action Encoded] [1, 4, 3, 4, 9, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.3014852), array(2.3014852), array(2.3014852), array(2.3014852), array(2.3014852), array(2.3014852), array(2.3014852)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 7, 0, 2]
[Action Encoded] [0, 3, 4, 1, 7, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 26, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 26, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 3, 4, 2, 16, 3, 2]
[Action Encoded] [1, 3, 4, 2, 16, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(6.08115619), array(6.08115619), array(6.08115619), array(6.08115619), array(6.08115619), array(6.08115619), array(6.08115619)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 12, 3, 2]
[Action Encoded] [1, 3, 1, 3, 12, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(6.27377199), array(6.27377199), array(6.27377199), array(6.27377199), array(6.27377199), array(6.27377199), array(6.27377199)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 4, 1, 2, 8, 3, 9]
[Action Encoded] [0, 4, 1, 2, 8, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(2.27919479), array(2.27919479), array(2.27919479), array(2.27919479), array(2.27919479), array(2.27919479), array(2.27919479)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 11, 0, 1]
[Action Encoded] [0, 0, 3, 4, 11, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 3]
[Action Encoded] [0, 1, 3, 4, 8, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 11, 0, 2]
[Action Encoded] [1, 4, 2, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 3, 2, 4]
[Action Encoded] [1, 0, 2, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(3.27395691), array(3.27395691), array(3.27395691), array(3.27395691), array(3.27395691), array(3.27395691), array(3.27395691)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 1, 0, 0]
[Action Encoded] [1, 1, 4, 1, 1, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458), array(6.22439458)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 15, 2, 2]
[Action Encoded] [1, 3, 4, 0, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831), array(6.36010831)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 11, 2, 0]
[Action Encoded] [1, 3, 2, 4, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 2]
[Action Encoded] [1, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 2]
[Action Encoded] [0, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 6, 1, 9]
[Action Encoded] [1, 1, 0, 1, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 2, 0, 7, 0, 9]
[Action Encoded] [0, 0, 2, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 12, 0, 9]
[Action Encoded] [0, 0, 3, 0, 12, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 69  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 2]
[Action Encoded] [0, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 9]
[Action Encoded] [0, 4, 3, 3, 14, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 2]
[Action Encoded] [0, 0, 3, 4, 20, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 14, 0, 4]
[Action Encoded] [1, 3, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 17, 2, 6]
[Action Encoded] [0, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 2, 2, 0]
[Action Encoded] [1, 1, 0, 4, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 5, 2, 9]
[Action Encoded] [1, 3, 2, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 14, 1, 2]
[Action Encoded] [0, 0, 2, 4, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 1, 2, 9]
[Action Encoded] [1, 3, 3, 4, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 16, 1, 4]
[Action Encoded] [0, 0, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 2, 2, 4]
[Action Encoded] [1, 3, 3, 1, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 2, 9]
[Action Encoded] [0, 0, 2, 4, 16, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 4, 1, 9]
[Action Encoded] [0, 3, 4, 4, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 1, 9]
[Action Encoded] [0, 1, 4, 4, 12, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 2, 3]
[Action Encoded] [1, 0, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 20, 2, 2]
[Action Encoded] [1, 4, 4, 1, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:37:20 UTC 2024
Total Execution Time: 42 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent5', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 6
)
[Env][Action] [0, 1, 1, 1, 19, 0, 3]
[Action Encoded] [0, 1, 1, 1, 19, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(15.95318784), array(15.95318784), array(15.95318784), array(15.95318784), array(15.95318784), array(15.95318784), array(15.95318784)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 7, 0, 8]
[Action Encoded] [0, 4, 2, 3, 7, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(1.87728038), array(1.87728038), array(1.87728038), array(1.87728038), array(1.87728038), array(1.87728038), array(1.87728038)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 2, 1, 2, 6, 3, 4]
[Action Encoded] [1, 2, 1, 2, 6, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(15.3886707), array(15.3886707), array(15.3886707), array(15.3886707), array(15.3886707), array(15.3886707), array(15.3886707)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 16, 3, 2]
[Action Encoded] [1, 0, 0, 4, 16, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 35, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 35, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(2.41564027), array(2.41564027), array(2.41564027), array(2.41564027), array(2.41564027), array(2.41564027), array(2.41564027)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 1, 3, 2, 11, 2, 9]
[Action Encoded] [1, 1, 3, 2, 11, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(14.87626484), array(14.87626484), array(14.87626484), array(14.87626484), array(14.87626484), array(14.87626484), array(14.87626484)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 16, 2, 4]
[Action Encoded] [0, 1, 4, 1, 16, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 0, 2, 2, 3, 0, 0]
[Action Encoded] [1, 0, 2, 2, 3, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(1.69458227), array(1.69458227), array(1.69458227), array(1.69458227), array(1.69458227), array(1.69458227), array(1.69458227)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 2, 3, 7]
[Action Encoded] [1, 2, 4, 4, 2, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(14.13709428), array(14.13709428), array(14.13709428), array(14.13709428), array(14.13709428), array(14.13709428), array(14.13709428)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 11, 0, 4]
[Action Encoded] [0, 4, 3, 0, 11, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(1.91441672), array(1.91441672), array(1.91441672), array(1.91441672), array(1.91441672), array(1.91441672), array(1.91441672)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 3, 1, 1, 2, 0, 9]
[Action Encoded] [1, 3, 1, 1, 2, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 21, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 21, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(9.00436113), array(9.00436113), array(9.00436113), array(9.00436113), array(9.00436113), array(9.00436113), array(9.00436113)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 4, 4, 1, 8, 1, 4]
[Action Encoded] [0, 4, 4, 1, 8, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(1.87307905), array(1.87307905), array(1.87307905), array(1.87307905), array(1.87307905), array(1.87307905), array(1.87307905)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 4, 2, 2, 0, 3, 8]
[Action Encoded] [1, 4, 2, 2, 0, 3, 8]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(1.89775932), array(1.89775932), array(1.89775932), array(1.89775932), array(1.89775932), array(1.89775932), array(1.89775932)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 11, 0, 9]
[Action Encoded] [0, 0, 0, 3, 11, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 13  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 13 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 4, 3, 6]
[Action Encoded] [1, 1, 0, 1, 4, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(15.11983676), array(15.11983676), array(15.11983676), array(15.11983676), array(15.11983676), array(15.11983676), array(15.11983676)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 0, 3, 3, 4, 3, 6]
[Action Encoded] [0, 0, 3, 3, 4, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(2.37881262), array(2.37881262), array(2.37881262), array(2.37881262), array(2.37881262), array(2.37881262), array(2.37881262)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 12, 0, 3]
[Action Encoded] [0, 1, 3, 4, 12, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(15.94388659), array(15.94388659), array(15.94388659), array(15.94388659), array(15.94388659), array(15.94388659), array(15.94388659)]
Episode 16 finished after 1 steps.
[Env][Action] [1, 3, 1, 2, 7, 1, 1]
[Action Encoded] [1, 3, 1, 2, 7, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(8.15767708), array(8.15767708), array(8.15767708), array(8.15767708), array(8.15767708), array(8.15767708), array(8.15767708)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 8, 2, 9]
[Action Encoded] [1, 3, 1, 3, 8, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 27, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 27, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(8.12884758), array(8.12884758), array(8.12884758), array(8.12884758), array(8.12884758), array(8.12884758), array(8.12884758)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 5, 3, 1]
[Action Encoded] [0, 2, 3, 1, 5, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(15.20937506), array(15.20937506), array(15.20937506), array(15.20937506), array(15.20937506), array(15.20937506), array(15.20937506)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 7, 2, 2]
[Action Encoded] [0, 3, 3, 3, 7, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(8.36204178), array(8.36204178), array(8.36204178), array(8.36204178), array(8.36204178), array(8.36204178), array(8.36204178)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 1, 4, 4, 3, 1, 5]
[Action Encoded] [1, 1, 4, 4, 3, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(14.5826178), array(14.5826178), array(14.5826178), array(14.5826178), array(14.5826178), array(14.5826178), array(14.5826178)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 15, 1, 9]
[Action Encoded] [0, 4, 2, 2, 15, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 0, 1, 0, 20, 3, 3]
[Action Encoded] [0, 0, 1, 0, 20, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.50128683), array(2.50128683), array(2.50128683), array(2.50128683), array(2.50128683), array(2.50128683), array(2.50128683)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 5, 2, 1]
[Action Encoded] [0, 2, 1, 1, 5, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877), array(15.21227877)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 4, 1, 1, 3, 3, 4]
[Action Encoded] [0, 4, 1, 1, 3, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 13, 1, 0]
[Action Encoded] [1, 1, 1, 3, 13, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(8.02674218), array(8.02674218), array(8.02674218), array(8.02674218), array(8.02674218), array(8.02674218), array(8.02674218)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 0, 1, 2, 16, 1, 0]
[Action Encoded] [0, 0, 1, 2, 16, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(1.71756841), array(1.71756841), array(1.71756841), array(1.71756841), array(1.71756841), array(1.71756841), array(1.71756841)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 0, 1, 0, 15, 2, 4]
[Action Encoded] [0, 0, 1, 0, 15, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(2.50281244), array(2.50281244), array(2.50281244), array(2.50281244), array(2.50281244), array(2.50281244), array(2.50281244)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 0, 3, 8]
[Action Encoded] [1, 1, 0, 1, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 2, 3, 0, 18, 1, 7]
[Action Encoded] [1, 2, 3, 0, 18, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 37, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 37, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(15.07716948), array(15.07716948), array(15.07716948), array(15.07716948), array(15.07716948), array(15.07716948), array(15.07716948)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 0, 1, 2]
[Action Encoded] [0, 2, 1, 1, 0, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(15.7424534), array(15.7424534), array(15.7424534), array(15.7424534), array(15.7424534), array(15.7424534), array(15.7424534)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 4, 3, 1, 19, 0, 6]
[Action Encoded] [0, 4, 3, 1, 19, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(1.89739908), array(1.89739908), array(1.89739908), array(1.89739908), array(1.89739908), array(1.89739908), array(1.89739908)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 17, 1, 8]
[Action Encoded] [1, 4, 0, 3, 17, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 36, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 36, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(1.91945847), array(1.91945847), array(1.91945847), array(1.91945847), array(1.91945847), array(1.91945847), array(1.91945847)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 2, 1, 2, 11, 0, 4]
[Action Encoded] [1, 2, 1, 2, 11, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(15.43455761), array(15.43455761), array(15.43455761), array(15.43455761), array(15.43455761), array(15.43455761), array(15.43455761)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 3, 2, 1, 19, 3, 7]
[Action Encoded] [0, 3, 2, 1, 19, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(8.53736628), array(8.53736628), array(8.53736628), array(8.53736628), array(8.53736628), array(8.53736628), array(8.53736628)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 4, 1, 0, 8, 3, 0]
[Action Encoded] [1, 4, 1, 0, 8, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(1.39711712), array(1.39711712), array(1.39711712), array(1.39711712), array(1.39711712), array(1.39711712), array(1.39711712)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 4, 3, 1, 20, 1, 9]
[Action Encoded] [0, 4, 3, 1, 20, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(1.90120395), array(1.90120395), array(1.90120395), array(1.90120395), array(1.90120395), array(1.90120395), array(1.90120395)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 5, 0, 5]
[Action Encoded] [1, 4, 2, 3, 5, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(1.87712929), array(1.87712929), array(1.87712929), array(1.87712929), array(1.87712929), array(1.87712929), array(1.87712929)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 19, 3, 0]
[Action Encoded] [0, 4, 2, 2, 19, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 38, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 38, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(1.35355259), array(1.35355259), array(1.35355259), array(1.35355259), array(1.35355259), array(1.35355259), array(1.35355259)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 7, 0, 5]
[Action Encoded] [1, 4, 3, 3, 7, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 238680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(1.8578502), array(1.8578502), array(1.8578502), array(1.8578502), array(1.8578502), array(1.8578502), array(1.8578502)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 1, 0, 8]
[Action Encoded] [1, 3, 3, 1, 1, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(8.68167438), array(8.68167438), array(8.68167438), array(8.68167438), array(8.68167438), array(8.68167438), array(8.68167438)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 17, 3, 5]
[Action Encoded] [0, 1, 3, 0, 17, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 0, 0, 4, 4, 1, 4]
[Action Encoded] [0, 0, 0, 4, 4, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(2.42361872), array(2.42361872), array(2.42361872), array(2.42361872), array(2.42361872), array(2.42361872), array(2.42361872)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 4, 3, 9]
[Action Encoded] [1, 3, 4, 3, 4, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 23, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 23, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(7.97989325), array(7.97989325), array(7.97989325), array(7.97989325), array(7.97989325), array(7.97989325), array(7.97989325)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 3, 0, 3, 14, 2, 4]
[Action Encoded] [0, 3, 0, 3, 14, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(8.48030024), array(8.48030024), array(8.48030024), array(8.48030024), array(8.48030024), array(8.48030024), array(8.48030024)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 17, 1, 0]
[Action Encoded] [1, 2, 3, 1, 17, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 36, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 36, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(8.08825144), array(8.08825144), array(8.08825144), array(8.08825144), array(8.08825144), array(8.08825144), array(8.08825144)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 3, 0, 2, 8, 3, 6]
[Action Encoded] [1, 3, 0, 2, 8, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(8.93689991), array(8.93689991), array(8.93689991), array(8.93689991), array(8.93689991), array(8.93689991), array(8.93689991)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 0, 4, 3, 20, 2, 1]
[Action Encoded] [0, 0, 4, 3, 20, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(2.3066604), array(2.3066604), array(2.3066604), array(2.3066604), array(2.3066604), array(2.3066604), array(2.3066604)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 0, 3, 1, 10, 1, 2]
[Action Encoded] [0, 0, 3, 1, 10, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(2.41239636), array(2.41239636), array(2.41239636), array(2.41239636), array(2.41239636), array(2.41239636), array(2.41239636)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 1, 1, 4, 17, 0, 7]
[Action Encoded] [0, 1, 1, 4, 17, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 36, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 36, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(16.01672617), array(16.01672617), array(16.01672617), array(16.01672617), array(16.01672617), array(16.01672617), array(16.01672617)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:38:36 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent1', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 10
)
[Env][Action] [1, 1, 4, 3, 2, 2, 7]
[Action Encoded] [1, 1, 4, 3, 2, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(10.39657644), array(10.39657644), array(10.39657644), array(10.39657644), array(10.39657644), array(10.39657644), array(10.39657644)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 1, 3, 1, 10, 0, 3]
[Action Encoded] [0, 1, 3, 1, 10, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [11.562547627170085, 11.562547627170085, 11.562547627170085, 11.562547627170085, 11.562547627170085, 11.562547627170085, 11.562547627170085]
Episode 2 finished after 1 steps.
[Env][Action] [0, 3, 2, 0, 16, 3, 4]
[Action Encoded] [0, 3, 2, 0, 16, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 35, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 35, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 20, 1, 9]
[Action Encoded] [0, 0, 1, 1, 20, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 9, 2, 6]
[Action Encoded] [0, 3, 3, 1, 9, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 11, 3, 1]
[Action Encoded] [1, 0, 3, 4, 11, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127), array(3.11057127)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 14, 1, 3]
[Action Encoded] [0, 1, 2, 4, 14, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 4, 0, 2, 1, 2, 6]
[Action Encoded] [0, 4, 0, 2, 1, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 1, 3, 2, 17, 2, 2]
[Action Encoded] [1, 1, 3, 2, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412), array(11.5542412)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 1, 0, 0, 19, 1, 7]
[Action Encoded] [0, 1, 0, 0, 19, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 38, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 38, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 0, 0, 4, 8, 3, 0]
[Action Encoded] [0, 0, 0, 4, 8, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(2.48674496), array(2.48674496), array(2.48674496), array(2.48674496), array(2.48674496), array(2.48674496), array(2.48674496)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 2, 2, 3, 1, 2, 8]
[Action Encoded] [1, 2, 2, 3, 1, 2, 8]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
{'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 20, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 20, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(10.49196192), array(10.49196192), array(10.49196192), array(10.49196192), array(10.49196192), array(10.49196192), array(10.49196192)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 2, 4, 0, 7, 3, 6]
[Action Encoded] [0, 2, 4, 0, 7, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319), array(11.60401319)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 12, 2, 0]
[Action Encoded] [0, 1, 4, 3, 12, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(7.85769357), array(7.85769357), array(7.85769357), array(7.85769357), array(7.85769357), array(7.85769357), array(7.85769357)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 15, 2, 3]
[Action Encoded] [0, 1, 0, 4, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 0, 1, 0, 7, 1, 2]
[Action Encoded] [1, 0, 1, 0, 7, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 3, 4, 2, 17, 1, 6]
[Action Encoded] [0, 3, 4, 2, 17, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(6.21750498), array(6.21750498), array(6.21750498), array(6.21750498), array(6.21750498), array(6.21750498), array(6.21750498)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 4, 2, 7]
[Action Encoded] [0, 1, 3, 0, 4, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 3, 0, 2, 0, 0, 9]
[Action Encoded] [1, 3, 0, 2, 0, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 19  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 19 finished after 1 steps.
[Env][Action] [0, 1, 1, 2, 3, 2, 9]
[Action Encoded] [0, 1, 1, 2, 3, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 7, 1, 7]
[Action Encoded] [0, 3, 3, 0, 7, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(6.0479983), array(6.0479983), array(6.0479983), array(6.0479983), array(6.0479983), array(6.0479983), array(6.0479983)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 1, 3, 1, 4, 2, 5]
[Action Encoded] [1, 1, 3, 1, 4, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 0, 1, 0, 20, 0, 8]
[Action Encoded] [0, 0, 1, 0, 20, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 1, 4, 3, 12, 1, 7]
[Action Encoded] [1, 1, 4, 3, 12, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(11.20801655), array(11.20801655), array(11.20801655), array(11.20801655), array(11.20801655), array(11.20801655), array(11.20801655)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 1, 3, 1, 1, 1, 3]
[Action Encoded] [0, 1, 3, 1, 1, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 20, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 2, 3, 3, 2, 3, 5]
[Action Encoded] [1, 2, 3, 3, 2, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(10.70760111), array(10.70760111), array(10.70760111), array(10.70760111), array(10.70760111), array(10.70760111), array(10.70760111)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 15, 3, 1]
[Action Encoded] [1, 0, 0, 0, 15, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 2, 1, 3, 2, 2, 6]
[Action Encoded] [1, 2, 1, 3, 2, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 21, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 21, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(10.58012967), array(10.58012967), array(10.58012967), array(10.58012967), array(10.58012967), array(10.58012967), array(10.58012967)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 11, 0, 7]
[Action Encoded] [1, 0, 3, 0, 11, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 0, 4, 2, 9, 0, 4]
[Action Encoded] [1, 0, 4, 2, 9, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(3.16591951), array(3.16591951), array(3.16591951), array(3.16591951), array(3.16591951), array(3.16591951), array(3.16591951)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 1, 3, 3, 14, 2, 6]
[Action Encoded] [1, 1, 3, 3, 14, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(11.23149703), array(11.23149703), array(11.23149703), array(11.23149703), array(11.23149703), array(11.23149703), array(11.23149703)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 2, 0, 1, 5, 0, 0]
[Action Encoded] [0, 2, 0, 1, 5, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 32  Rewards: [7.610208539573, 7.610208539573, 7.610208539573, 7.610208539573, 7.610208539573, 7.610208539573, 7.610208539573]
Episode 32 finished after 1 steps.
[Env][Action] [0, 2, 2, 2, 3, 3, 1]
[Action Encoded] [0, 2, 2, 2, 3, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(11.82192893), array(11.82192893), array(11.82192893), array(11.82192893), array(11.82192893), array(11.82192893), array(11.82192893)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 4, 4, 0, 7, 0, 2]
[Action Encoded] [0, 4, 4, 0, 7, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(2.27125121), array(2.27125121), array(2.27125121), array(2.27125121), array(2.27125121), array(2.27125121), array(2.27125121)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 6, 3, 5]
[Action Encoded] [0, 1, 4, 3, 6, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 9, 1, 7]
[Action Encoded] [1, 3, 0, 0, 9, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(5.83790994), array(5.83790994), array(5.83790994), array(5.83790994), array(5.83790994), array(5.83790994), array(5.83790994)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 20, 3, 3]
[Action Encoded] [0, 2, 0, 4, 20, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 39, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 39, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(11.81268582), array(11.81268582), array(11.81268582), array(11.81268582), array(11.81268582), array(11.81268582), array(11.81268582)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 0, 0, 2]
[Action Encoded] [0, 0, 3, 0, 0, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 19, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 19, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 15, 0, 7]
[Action Encoded] [0, 2, 0, 4, 15, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(11.59510757), array(11.59510757), array(11.59510757), array(11.59510757), array(11.59510757), array(11.59510757), array(11.59510757)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 14, 2, 5]
[Action Encoded] [0, 0, 4, 4, 14, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 238680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 2, 0, 3, 5, 1, 7]
[Action Encoded] [0, 2, 0, 3, 5, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 24, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 24, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 4, 2, 2, 10, 1, 5]
[Action Encoded] [1, 4, 2, 2, 10, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(2.35326862), array(2.35326862), array(2.35326862), array(2.35326862), array(2.35326862), array(2.35326862), array(2.35326862)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 13, 0, 3]
[Action Encoded] [0, 1, 4, 4, 13, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 32, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 32, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 5, 3, 3]
[Action Encoded] [0, 1, 4, 3, 5, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 0, 2, 3, 13, 0, 4]
[Action Encoded] [0, 0, 2, 3, 13, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 3, 0, 0]
[Action Encoded] [1, 4, 3, 2, 3, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(1.83756689), array(1.83756689), array(1.83756689), array(1.83756689), array(1.83756689), array(1.83756689), array(1.83756689)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 8, 2, 7]
[Action Encoded] [0, 4, 2, 0, 8, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(2.31090208), array(2.31090208), array(2.31090208), array(2.31090208), array(2.31090208), array(2.31090208), array(2.31090208)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 2, 1, 0]
[Action Encoded] [0, 1, 2, 1, 2, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 21, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 21, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 8, 1, 9]
[Action Encoded] [1, 3, 3, 0, 8, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 49  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 49 finished after 1 steps.
[Env][Action] [1, 4, 1, 2, 17, 2, 1]
[Action Encoded] [1, 4, 1, 2, 17, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367)]
Episode 50 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 3, 0, 1]
[Action Encoded] [1, 0, 3, 4, 3, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 3]
[Action Encoded] [0, 1, 3, 4, 8, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 11, 0, 2]
[Action Encoded] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[1, 4, 2, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 3, 2, 4]
[Action Encoded] [1, 0, 0, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 4, 0, 0]
[Action Encoded] [1, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 15, 2, 2]
[Action Encoded] [1, 3, 4, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 11, 2, 0]
[Action Encoded] [1, 3, 2, 4, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 2]
[Action Encoded] [1, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 6, 0, 2]
[Action Encoded] [1, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 6, 1, 9]
[Action Encoded] [1, 1, 0, 4, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 7, 0, 9]
[Action Encoded] [1, 0, 2, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 8, 0, 6]
[Action Encoded] [1, 0, 3, 0, 8, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 69  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[array(3.24142339), array(3.24142339), array(3.24142339), array(3.24142339), array(3.24142339), array(3.24142339), array(3.24142339)]
Episode 69 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 20, 1, 2]
[Action Encoded] [1, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(3.08313082), array(3.08313082), array(3.08313082), array(3.08313082), array(3.08313082), array(3.08313082), array(3.08313082)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 17, 2, 6]
[Action Encoded] [1, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.91370648), array(11.91370648), array(11.91370648), array(11.91370648), array(11.91370648), array(11.91370648), array(11.91370648)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 19, 0, 0]
[Action Encoded] [1, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 9]
[Action Encoded] [0, 4, 3, 3, 14, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 14, 0, 4]
[Action Encoded] [1, 3, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354)]
Episode 78 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 17, 2, 6]
[Action Encoded] [1, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 2, 2, 0]
[Action Encoded] [1, 1, 0, 4, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 5, 2, 9]
[Action Encoded] [1, 3, 2, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 14, 1, 2]
[Action Encoded] [0, 0, 2, 4, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 1, 2, 9]
[Action Encoded] [1, 3, 3, 4, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 2, 2, 4]
[Action Encoded] [1, 3, 3, 4, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 9]
[Action Encoded] [0, 0, 2, 4, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 4, 1, 9]
[Action Encoded] [0, 3, 4, 4, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 1, 9]
[Action Encoded] [0, 1, 4, 4, 12, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 2, 3]
[Action Encoded] [1, 0, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 20, 2, 2]
[Action Encoded] [1, 4, 4, 1, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:39:21 UTC 2024
Total Execution Time: 45 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent1', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 10
)
[Env][Action] [0, 4, 3, 1, 4, 3, 8]
[Action Encoded] [0, 4, 3, 1, 4, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(1.89732705), array(1.89732705), array(1.89732705), array(1.89732705), array(1.89732705), array(1.89732705), array(1.89732705)]
Episode 1 finished after 1 steps.
[Env][Action] [1, 0, 1, 2, 5, 2, 2]
[Action Encoded] [1, 0, 1, 2, 5, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(2.43949045), array(2.43949045), array(2.43949045), array(2.43949045), array(2.43949045), array(2.43949045), array(2.43949045)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 0, 1, 4, 20, 1, 4]
[Action Encoded] [1, 0, 1, 4, 20, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(2.40432064), array(2.40432064), array(2.40432064), array(2.40432064), array(2.40432064), array(2.40432064), array(2.40432064)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 10, 1, 2]
[Action Encoded] [0, 2, 1, 1, 10, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(15.73087269), array(15.73087269), array(15.73087269), array(15.73087269), array(15.73087269), array(15.73087269), array(15.73087269)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 4, 1, 2, 13, 0, 5]
[Action Encoded] [0, 4, 1, 2, 13, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(1.91766982), array(1.91766982), array(1.91766982), array(1.91766982), array(1.91766982), array(1.91766982), array(1.91766982)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 0, 4]
[Action Encoded] [0, 4, 3, 0, 5, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(1.91438529), array(1.91438529), array(1.91438529), array(1.91438529), array(1.91438529), array(1.91438529), array(1.91438529)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 7, 2, 9]
[Action Encoded] [1, 0, 3, 2, 7, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 2, 2, 3, 15, 3, 9]
[Action Encoded] [0, 2, 2, 3, 15, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(16.01172552), array(16.01172552), array(16.01172552), array(16.01172552), array(16.01172552), array(16.01172552), array(16.01172552)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 16, 2, 5]
[Action Encoded] [0, 1, 3, 0, 16, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649), array(15.93889649)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 0, 4, 3, 4, 0, 9]
[Action Encoded] [1, 0, 4, 3, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(2.36222449), array(2.36222449), array(2.36222449), array(2.36222449), array(2.36222449), array(2.36222449), array(2.36222449)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 2, 3, 3, 5, 2, 8]
[Action Encoded] [0, 2, 3, 3, 5, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 24, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 24, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(16.01360663), array(16.01360663), array(16.01360663), array(16.01360663), array(16.01360663), array(16.01360663), array(16.01360663)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 7, 2, 7]
[Action Encoded] [0, 2, 1, 1, 7, 2, 7]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
{'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 26, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 26, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 0, 1, 3, 7, 0, 6]
[Action Encoded] [0, 0, 1, 3, 7, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(2.42658976), array(2.42658976), array(2.42658976), array(2.42658976), array(2.42658976), array(2.42658976), array(2.42658976)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 20, 3, 5]
[Action Encoded] [0, 1, 4, 3, 20, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(15.92898886), array(15.92898886), array(15.92898886), array(15.92898886), array(15.92898886), array(15.92898886), array(15.92898886)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 1, 0, 2, 7, 1, 8]
[Action Encoded] [1, 1, 0, 2, 7, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(14.88274464), array(14.88274464), array(14.88274464), array(14.88274464), array(14.88274464), array(14.88274464), array(14.88274464)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 5, 0, 7]
[Action Encoded] [1, 2, 3, 1, 5, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(14.96105123), array(14.96105123), array(14.96105123), array(14.96105123), array(14.96105123), array(14.96105123), array(14.96105123)]
Episode 16 finished after 1 steps.
[Env][Action] [1, 3, 2, 2, 7, 1, 2]
[Action Encoded] [1, 3, 2, 2, 7, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 26, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(8.77649125), array(8.77649125), array(8.77649125), array(8.77649125), array(8.77649125), array(8.77649125), array(8.77649125)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 3, 2, 1, 15, 2, 9]
[Action Encoded] [1, 3, 2, 1, 15, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 19, 3, 6]
[Action Encoded] [0, 4, 2, 0, 19, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 38, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 38, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(1.9394852), array(1.9394852), array(1.9394852), array(1.9394852), array(1.9394852), array(1.9394852), array(1.9394852)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 4, 3, 1, 12, 0, 7]
[Action Encoded] [1, 4, 3, 1, 12, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 31, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 31, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(1.89826389), array(1.89826389), array(1.89826389), array(1.89826389), array(1.89826389), array(1.89826389), array(1.89826389)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 4, 1, 4, 14, 2, 5]
[Action Encoded] [1, 4, 1, 4, 14, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(1.87737105), array(1.87737105), array(1.87737105), array(1.87737105), array(1.87737105), array(1.87737105), array(1.87737105)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 0, 1, 3, 0, 1, 0]
[Action Encoded] [1, 0, 1, 3, 0, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 19, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 19, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(1.69327388), array(1.69327388), array(1.69327388), array(1.69327388), array(1.69327388), array(1.69327388), array(1.69327388)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 0, 2, 0, 0, 5]
[Action Encoded] [1, 4, 0, 2, 0, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(1.93897998), array(1.93897998), array(1.93897998), array(1.93897998), array(1.93897998), array(1.93897998), array(1.93897998)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 4, 0, 1, 15, 2, 6]
[Action Encoded] [1, 4, 0, 1, 15, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(1.96299147), array(1.96299147), array(1.96299147), array(1.96299147), array(1.96299147), array(1.96299147), array(1.96299147)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 15, 2, 2]
[Action Encoded] [1, 0, 0, 2, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.46533629), array(2.46533629), array(2.46533629), array(2.46533629), array(2.46533629), array(2.46533629), array(2.46533629)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 3, 0, 4, 6, 2, 5]
[Action Encoded] [1, 3, 0, 4, 6, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 238680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(8.93023357), array(8.93023357), array(8.93023357), array(8.93023357), array(8.93023357), array(8.93023357), array(8.93023357)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 13, 1, 0]
[Action Encoded] [0, 1, 2, 1, 13, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 32, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 32, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(8.3078455), array(8.3078455), array(8.3078455), array(8.3078455), array(8.3078455), array(8.3078455), array(8.3078455)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 1, 1, 1, 3, 3, 4]
[Action Encoded] [1, 1, 1, 1, 3, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(14.9041139), array(14.9041139), array(14.9041139), array(14.9041139), array(14.9041139), array(14.9041139), array(14.9041139)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 7, 1, 0]
[Action Encoded] [0, 0, 1, 1, 7, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 26, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 26, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(1.73850126), array(1.73850126), array(1.73850126), array(1.73850126), array(1.73850126), array(1.73850126), array(1.73850126)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 2, 1, 0, 14, 0, 2]
[Action Encoded] [1, 2, 1, 0, 14, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(15.06002853), array(15.06002853), array(15.06002853), array(15.06002853), array(15.06002853), array(15.06002853), array(15.06002853)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 3, 1, 2, 1, 1, 1]
[Action Encoded] [1, 3, 1, 2, 1, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(8.13124521), array(8.13124521), array(8.13124521), array(8.13124521), array(8.13124521), array(8.13124521), array(8.13124521)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 0, 1, 0, 17, 3, 6]
[Action Encoded] [0, 0, 1, 0, 17, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(2.50319608), array(2.50319608), array(2.50319608), array(2.50319608), array(2.50319608), array(2.50319608), array(2.50319608)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 1, 3, 3, 15, 3, 4]
[Action Encoded] [1, 1, 3, 3, 15, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(14.94649217), array(14.94649217), array(14.94649217), array(14.94649217), array(14.94649217), array(14.94649217), array(14.94649217)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 1, 3, 1, 5, 2, 7]
[Action Encoded] [0, 1, 3, 1, 5, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 34  Rewards: [16.01985517449301, 16.01985517449301, 16.01985517449301, 16.01985517449301, 16.01985517449301, 16.01985517449301, 16.01985517449301]
Episode 34 finished after 1 steps.
[Env][Action] [0, 4, 1, 2, 11, 1, 7]
[Action Encoded] [0, 4, 1, 2, 11, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(1.91824814), array(1.91824814), array(1.91824814), array(1.91824814), array(1.91824814), array(1.91824814), array(1.91824814)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 3, 0, 1, 15, 1, 4]
[Action Encoded] [1, 3, 0, 1, 15, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(9.08499126), array(9.08499126), array(9.08499126), array(9.08499126), array(9.08499126), array(9.08499126), array(9.08499126)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 2, 4, 1, 10, 2, 0]
[Action Encoded] [0, 2, 4, 1, 10, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(8.28623664), array(8.28623664), array(8.28623664), array(8.28623664), array(8.28623664), array(8.28623664), array(8.28623664)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 6, 2, 5]
[Action Encoded] [1, 3, 4, 4, 6, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(8.13718548), array(8.13718548), array(8.13718548), array(8.13718548), array(8.13718548), array(8.13718548), array(8.13718548)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 2, 2, 3, 0, 1, 8]
[Action Encoded] [0, 2, 2, 3, 0, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 19, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 19, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 7, 3, 7]
[Action Encoded] [0, 4, 2, 4, 7, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 26, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 26, 'rrd': 6, 'refi': 332280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 38687326.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(1.85573141), array(1.85573141), array(1.85573141), array(1.85573141), array(1.85573141), array(1.85573141), array(1.85573141)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 0, 2, 8]
[Action Encoded] [1, 0, 3, 2, 0, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 19, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 19, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284), array(2.40958284)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 1, 1, 0, 11, 0, 5]
[Action Encoded] [1, 1, 1, 0, 11, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(14.80001348), array(14.80001348), array(14.80001348), array(14.80001348), array(14.80001348), array(14.80001348), array(14.80001348)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 18, 2, 8]
[Action Encoded] [1, 2, 4, 4, 18, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(14.80076199), array(14.80076199), array(14.80076199), array(14.80076199), array(14.80076199), array(14.80076199), array(14.80076199)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 10, 0, 3]
[Action Encoded] [1, 3, 3, 0, 10, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 29, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 29, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(8.75363662), array(8.75363662), array(8.75363662), array(8.75363662), array(8.75363662), array(8.75363662), array(8.75363662)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 16, 0, 5]
[Action Encoded] [0, 0, 3, 4, 16, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916), array(2.35492916)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 1, 0, 1]
[Action Encoded] [1, 0, 1, 1, 1, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.42530585), array(2.42530585), array(2.42530585), array(2.42530585), array(2.42530585), array(2.42530585), array(2.42530585)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 9, 0, 0]
[Action Encoded] [1, 3, 2, 0, 9, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(4.92540719), array(4.92540719), array(4.92540719), array(4.92540719), array(4.92540719), array(4.92540719), array(4.92540719)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 4, 0, 8]
[Action Encoded] [0, 4, 0, 1, 4, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(1.96139568), array(1.96139568), array(1.96139568), array(1.96139568), array(1.96139568), array(1.96139568), array(1.96139568)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 2, 1, 4, 7, 2, 2]
[Action Encoded] [0, 2, 1, 4, 7, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(15.72539303), array(15.72539303), array(15.72539303), array(15.72539303), array(15.72539303), array(15.72539303), array(15.72539303)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 16, 2, 8]
[Action Encoded] [1, 2, 1, 1, 16, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(14.78043274), array(14.78043274), array(14.78043274), array(14.78043274), array(14.78043274), array(14.78043274), array(14.78043274)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:40:28 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 990468.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [1, 2, 0, 0, 8, 3, 9]
[Action Encoded] [1, 2, 0, 0, 8, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 1  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 1 finished after 1 steps.
[Env][Action] [0, 3, 1, 4, 1, 2, 4]
[Action Encoded] [0, 3, 1, 4, 1, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 2, 2, 4, 12, 0, 2]
[Action Encoded] [1, 2, 2, 4, 12, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(11.29179759), array(11.29179759), array(11.29179759), array(11.29179759), array(11.29179759), array(11.29179759), array(11.29179759)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 4, 0, 1, 1, 2, 3]
[Action Encoded] [1, 4, 0, 1, 1, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(2.43511556), array(2.43511556), array(2.43511556), array(2.43511556), array(2.43511556), array(2.43511556), array(2.43511556)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 10, 3, 0]
[Action Encoded] [1, 2, 3, 1, 10, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(7.21272699), array(7.21272699), array(7.21272699), array(7.21272699), array(7.21272699), array(7.21272699), array(7.21272699)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 4, 2, 9]
[Action Encoded] [1, 4, 3, 3, 4, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592), array(2.32421592)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 3, 2, 2, 17, 2, 5]
[Action Encoded] [0, 3, 2, 2, 17, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(6.41528565), array(6.41528565), array(6.41528565), array(6.41528565), array(6.41528565), array(6.41528565), array(6.41528565)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 8, 1, 6]
[Action Encoded] [0, 1, 3, 3, 8, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 27, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 27, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 13, 1, 6]
[Action Encoded] [1, 1, 3, 4, 13, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 32, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 32, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 10, 0, 6]
[Action Encoded] [1, 0, 0, 2, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 18, 2, 0]
[Action Encoded] [1, 4, 2, 0, 18, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(1.84885762), array(1.84885762), array(1.84885762), array(1.84885762), array(1.84885762), array(1.84885762), array(1.84885762)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 6, 3, 7]
[Action Encoded] [0, 0, 4, 2, 6, 3, 7]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767)]
Episode 12 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 18, 0, 8]
[Action Encoded] [1, 4, 0, 0, 18, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 37, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 37, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 1, 4, 3, 14, 3, 3]
[Action Encoded] [1, 1, 4, 3, 14, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 33, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 33, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 8, 3, 2]
[Action Encoded] [0, 4, 0, 0, 8, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 2, 1, 4, 5, 3, 5]
[Action Encoded] [0, 2, 1, 4, 5, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 3, 2, 2, 14, 2, 5]
[Action Encoded] [0, 3, 2, 2, 14, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 33, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 33, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783), array(6.4004783)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 1, 0, 3, 17, 3, 7]
[Action Encoded] [0, 1, 0, 3, 17, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 36, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 36, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 0, 0, 3]
[Action Encoded] [1, 3, 2, 4, 0, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(5.24693892), array(5.24693892), array(5.24693892), array(5.24693892), array(5.24693892), array(5.24693892), array(5.24693892)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 1, 2, 0, 3, 0, 8]
[Action Encoded] [0, 1, 2, 0, 3, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 20, 1, 3]
[Action Encoded] [1, 0, 1, 1, 20, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 0, 4, 0, 1, 2, 7]
[Action Encoded] [1, 0, 4, 0, 1, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 22  Rewards: [3.2211511555391596, 3.2211511555391596, 3.2211511555391596, 3.2211511555391596, 3.2211511555391596, 3.2211511555391596, 3.2211511555391596]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 4, 0, 9, 1, 1]
[Action Encoded] [1, 4, 4, 0, 9, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 28, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 28, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 11, 0, 8]
[Action Encoded] [0, 1, 3, 4, 11, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 0, 3, 1, 8, 1, 0]
[Action Encoded] [1, 0, 3, 1, 8, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952), array(2.57344952)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 4, 0, 9]
[Action Encoded] [0, 3, 3, 3, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 425880}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 8, 0, 9]
[Action Encoded] [1, 3, 4, 3, 8, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(5.714595), array(5.714595), array(5.714595), array(5.714595), array(5.714595), array(5.714595), array(5.714595)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 12, 1, 4]
[Action Encoded] [1, 0, 2, 3, 12, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 4, 2, 6]
[Action Encoded] [1, 3, 4, 1, 4, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(5.36365033), array(5.36365033), array(5.36365033), array(5.36365033), array(5.36365033), array(5.36365033), array(5.36365033)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 9, 2, 0]
[Action Encoded] [1, 2, 3, 2, 9, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 28, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 28, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(7.31141392), array(7.31141392), array(7.31141392), array(7.31141392), array(7.31141392), array(7.31141392), array(7.31141392)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 13, 0, 4]
[Action Encoded] [0, 0, 4, 2, 13, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(3.10662134), array(3.10662134), array(3.10662134), array(3.10662134), array(3.10662134), array(3.10662134), array(3.10662134)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 3, 1, 1, 0, 1, 7]
[Action Encoded] [1, 3, 1, 1, 0, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 2, 0, 3]
[Action Encoded] [1, 1, 4, 2, 2, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 21, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 21, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(10.67253069), array(10.67253069), array(10.67253069), array(10.67253069), array(10.67253069), array(10.67253069), array(10.67253069)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 13, 3, 2]
[Action Encoded] [1, 0, 0, 4, 13, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 32, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 32, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 17, 0, 0]
[Action Encoded] [0, 0, 0, 2, 17, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(2.59243896), array(2.59243896), array(2.59243896), array(2.59243896), array(2.59243896), array(2.59243896), array(2.59243896)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 0, 2, 4, 8, 3, 1]
[Action Encoded] [1, 0, 2, 4, 8, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 3, 1, 0, 20, 3, 3]
[Action Encoded] [0, 3, 1, 0, 20, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937), array(6.55944937)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 8, 1, 0]
[Action Encoded] [0, 1, 4, 1, 8, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 4, 0, 4, 15, 3, 9]
[Action Encoded] [1, 4, 0, 4, 15, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 39  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 39 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 3, 3, 9]
[Action Encoded] [1, 1, 4, 1, 3, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 40  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[array(10.60217782), array(10.60217782), array(10.60217782), array(10.60217782), array(10.60217782), array(10.60217782), array(10.60217782)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 1, 1, 1, 14, 3, 6]
[Action Encoded] [1, 1, 1, 1, 14, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 33, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 33, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 2, 3, 3, 0, 0, 7]
[Action Encoded] [0, 2, 3, 3, 0, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [11.586215620290538, 11.586215620290538, 11.586215620290538, 11.586215620290538, 11.586215620290538, 11.586215620290538, 11.586215620290538]
Episode 42 finished after 1 steps.
[Env][Action] [0, 4, 1, 4, 0, 2, 2]
[Action Encoded] [0, 4, 1, 4, 0, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 13, 2, 0]
[Action Encoded] [0, 3, 3, 1, 13, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301), array(4.57152301)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 13, 0, 4]
[Action Encoded] [0, 3, 2, 4, 13, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 0, 1, 2, 19, 3, 2]
[Action Encoded] [1, 0, 1, 2, 19, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 38, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 38, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 10, 1, 1]
[Action Encoded] [1, 1, 2, 2, 10, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.01609846), array(11.01609846), array(11.01609846), array(11.01609846), array(11.01609846), array(11.01609846), array(11.01609846)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 1, 0, 3, 1, 2, 9]
[Action Encoded] [0, 1, 0, 3, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 48  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 48 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 18, 1, 9]
[Action Encoded] [1, 4, 4, 3, 18, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 37, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 37, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 2, 0, 2, 2, 1, 3]
[Action Encoded] [1, 2, 0, 2, 2, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 21, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 21, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(10.71519516), array(10.71519516), array(10.71519516), array(10.71519516), array(10.71519516), array(10.71519516), array(10.71519516)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 3, 0, 1]
[Action Encoded] [0, 0, 3, 4, 3, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 3, 1, 3]
[Action Encoded] [0, 1, 3, 4, 3, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 11, 0, 2]
[Action Encoded] [1, 4, 3, 0, 11, 0, 2]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 3, 2, 4]
[Action Encoded] [1, 4, 0, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 4, 0, 0]
[Action Encoded] [1, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 15, 2, 2]
[Action Encoded] [1, 3, 4, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684), array(6.13836684)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 11, 2, 0]
[Action Encoded] [1, 3, 2, 4, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 3]
[Action Encoded] [1, 4, 2, 4, 9, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 2]
[Action Encoded] [0, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 6, 1, 3]
[Action Encoded] [1, 1, 0, 4, 6, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794)]
Episode 64 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 5, 1, 4]
[Action Encoded] [1, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 7, 0, 9]
[Action Encoded] [0, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 12, 0, 6]
[Action Encoded] [1, 0, 3, 0, 12, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 69  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 2]
[Action Encoded] [0, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 9]
[Action Encoded] [0, 4, 3, 3, 14, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 14, 0, 4]
[Action Encoded] [1, 4, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 17, 2, 6]
[Action Encoded] [0, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 2, 2, 0]
[Action Encoded] [1, 1, 0, 4, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 0, 4, 5, 2, 9]
[Action Encoded] [1, 3, 0, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 14, 1, 2]
[Action Encoded] [0, 0, 2, 4, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 1, 2, 9]
[Action Encoded] [1, 3, 3, 4, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 6]
[Action Encoded] [1, 0, 4, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 2, 2, 4]
[Action Encoded] [1, 3, 3, 4, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 2, 9]
[Action Encoded] [0, 0, 2, 4, 16, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 4, 1, 1]
[Action Encoded] [0, 3, 4, 4, 4, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 94  Rewards: [6.118052336392861, 6.118052336392861, 6.118052336392861, 6.118052336392861, 6.118052336392861, 6.118052336392861, 6.118052336392861]
Episode 94 finished after 1 steps.
[Env][Action] [1, 1, 4, 4, 12, 0, 4]
[Action Encoded] [1, 1, 4, 4, 12, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242), array(11.13045242)]
Episode 95 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 4, 2, 4]
[Action Encoded] [1, 4, 2, 3, 4, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012), array(2.34740012)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 2, 3]
[Action Encoded] [1, 0, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 20, 2, 2]
[Action Encoded] [1, 4, 4, 3, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:41:15 UTC 2024
Total Execution Time: 47 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent5', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 6
)
[Env][Action] [1, 3, 0, 2, 9, 1, 0]
[Action Encoded] [1, 3, 0, 2, 9, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 1  Rewards: [5.097499490818519, 5.097499490818519, 5.097499490818519, 5.097499490818519, 5.097499490818519, 5.097499490818519, 5.097499490818519]
Episode 1 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 1, 1, 3]
[Action Encoded] [0, 0, 4, 2, 1, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(2.37790871), array(2.37790871), array(2.37790871), array(2.37790871), array(2.37790871), array(2.37790871), array(2.37790871)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 6, 1, 2]
[Action Encoded] [0, 1, 4, 4, 6, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(15.71600584), array(15.71600584), array(15.71600584), array(15.71600584), array(15.71600584), array(15.71600584), array(15.71600584)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 2, 2, 3, 5, 0, 9]
[Action Encoded] [1, 2, 2, 3, 5, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(14.9244663), array(14.9244663), array(14.9244663), array(14.9244663), array(14.9244663), array(14.9244663), array(14.9244663)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 2, 1, 3, 14, 1, 4]
[Action Encoded] [1, 2, 1, 3, 14, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(14.61403996), array(14.61403996), array(14.61403996), array(14.61403996), array(14.61403996), array(14.61403996), array(14.61403996)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 3, 2, 0, 18, 3, 9]
[Action Encoded] [0, 3, 2, 0, 18, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 6  Rewards: [8.564349880807123, 8.564349880807123, 8.564349880807123, 8.564349880807123, 8.564349880807123, 8.564349880807123, 8.564349880807123]
Episode 6 finished after 1 steps.
[Env][Action] [1, 2, 1, 3, 4, 2, 8]
[Action Encoded] [1, 2, 1, 3, 4, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(14.90461089), array(14.90461089), array(14.90461089), array(14.90461089), array(14.90461089), array(14.90461089), array(14.90461089)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 0, 1, 4]
[Action Encoded] [1, 0, 0, 2, 0, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(2.47814164), array(2.47814164), array(2.47814164), array(2.47814164), array(2.47814164), array(2.47814164), array(2.47814164)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 3, 2, 6]
[Action Encoded] [1, 3, 3, 1, 3, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(8.71776661), array(8.71776661), array(8.71776661), array(8.71776661), array(8.71776661), array(8.71776661), array(8.71776661)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 3, 0, 3, 4, 3, 8]
[Action Encoded] [1, 3, 0, 3, 4, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 23, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 23, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(9.20166735), array(9.20166735), array(9.20166735), array(9.20166735), array(9.20166735), array(9.20166735), array(9.20166735)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 1, 2, 0, 18, 3, 8]
[Action Encoded] [0, 1, 2, 0, 18, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(16.02329849), array(16.02329849), array(16.02329849), array(16.02329849), array(16.02329849), array(16.02329849), array(16.02329849)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 4, 2, 9]
[Action Encoded] [1, 4, 3, 0, 4, 2, 9]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43600486.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34419440.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 12  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 12 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 14, 0, 8]
[Action Encoded] [1, 4, 0, 0, 14, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(1.98423443), array(1.98423443), array(1.98423443), array(1.98423443), array(1.98423443), array(1.98423443), array(1.98423443)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 0, 0, 9]
[Action Encoded] [1, 3, 4, 3, 0, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(7.90677993), array(7.90677993), array(7.90677993), array(7.90677993), array(7.90677993), array(7.90677993), array(7.90677993)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 2, 0, 1, 18, 0, 7]
[Action Encoded] [1, 2, 0, 1, 18, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 37, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 37, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(15.11255274), array(15.11255274), array(15.11255274), array(15.11255274), array(15.11255274), array(15.11255274), array(15.11255274)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 2, 2, 2, 4, 2, 2]
[Action Encoded] [0, 2, 2, 2, 4, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 23, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 23, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(15.72874126), array(15.72874126), array(15.72874126), array(15.72874126), array(15.72874126), array(15.72874126), array(15.72874126)]
Episode 16 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 14, 2, 2]
[Action Encoded] [1, 4, 3, 3, 14, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(1.84750506), array(1.84750506), array(1.84750506), array(1.84750506), array(1.84750506), array(1.84750506), array(1.84750506)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 0, 4, 3, 12, 0, 2]
[Action Encoded] [1, 0, 4, 3, 12, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(2.3439988), array(2.3439988), array(2.3439988), array(2.3439988), array(2.3439988), array(2.3439988), array(2.3439988)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 17, 2, 5]
[Action Encoded] [1, 1, 0, 4, 17, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(15.01051339), array(15.01051339), array(15.01051339), array(15.01051339), array(15.01051339), array(15.01051339), array(15.01051339)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 4, 3, 1, 10, 2, 3]
[Action Encoded] [1, 4, 3, 1, 10, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(1.90391869), array(1.90391869), array(1.90391869), array(1.90391869), array(1.90391869), array(1.90391869), array(1.90391869)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 4, 0, 4, 2, 0, 6]
[Action Encoded] [0, 4, 0, 4, 2, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(1.89717272), array(1.89717272), array(1.89717272), array(1.89717272), array(1.89717272), array(1.89717272), array(1.89717272)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 1, 0, 0, 9, 2, 2]
[Action Encoded] [0, 1, 0, 0, 9, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(15.73938372), array(15.73938372), array(15.73938372), array(15.73938372), array(15.73938372), array(15.73938372), array(15.73938372)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 20, 0, 9]
[Action Encoded] [1, 2, 1, 1, 20, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(14.8018335), array(14.8018335), array(14.8018335), array(14.8018335), array(14.8018335), array(14.8018335), array(14.8018335)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 0, 2, 0, 8, 0, 8]
[Action Encoded] [0, 0, 2, 0, 8, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 0, 2, 2, 12, 2, 4]
[Action Encoded] [0, 0, 2, 2, 12, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 31, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 31, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.42546351), array(2.42546351), array(2.42546351), array(2.42546351), array(2.42546351), array(2.42546351), array(2.42546351)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 3, 0, 1]
[Action Encoded] [0, 2, 1, 3, 3, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 22, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34377147.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
{'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 22, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(15.21140754), array(15.21140754), array(15.21140754), array(15.21140754), array(15.21140754), array(15.21140754), array(15.21140754)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 3, 2, 4]
[Action Encoded] [0, 1, 2, 1, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509), array(15.94230509)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 11, 3, 3]
[Action Encoded] [0, 2, 3, 2, 11, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(15.97505383), array(15.97505383), array(15.97505383), array(15.97505383), array(15.97505383), array(15.97505383), array(15.97505383)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 4, 2, 1, 1, 2, 0]
[Action Encoded] [0, 4, 2, 1, 1, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(1.3729318), array(1.3729318), array(1.3729318), array(1.3729318), array(1.3729318), array(1.3729318), array(1.3729318)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 0, 3, 3, 10, 1, 5]
[Action Encoded] [1, 0, 3, 3, 10, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 30  Rewards: [2.3806187279557336, 2.3806187279557336, 2.3806187279557336, 2.3806187279557336, 2.3806187279557336, 2.3806187279557336, 2.3806187279557336]
Episode 30 finished after 1 steps.
[Env][Action] [1, 0, 0, 3, 13, 1, 9]
[Action Encoded] [1, 0, 0, 3, 13, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 31  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 2, 3, 4, 5, 0, 1]
[Action Encoded] [0, 2, 3, 4, 5, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 24, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 24, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(15.20850416), array(15.20850416), array(15.20850416), array(15.20850416), array(15.20850416), array(15.20850416), array(15.20850416)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 18, 0, 4]
[Action Encoded] [1, 3, 2, 3, 18, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 37, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 37, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(8.05003866), array(8.05003866), array(8.05003866), array(8.05003866), array(8.05003866), array(8.05003866), array(8.05003866)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 0, 1, 2, 20, 2, 8]
[Action Encoded] [0, 0, 1, 2, 20, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 39, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(2.45499769), array(2.45499769), array(2.45499769), array(2.45499769), array(2.45499769), array(2.45499769), array(2.45499769)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 14, 2, 5]
[Action Encoded] [1, 3, 3, 1, 14, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 33, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 33, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(8.66180262), array(8.66180262), array(8.66180262), array(8.66180262), array(8.66180262), array(8.66180262), array(8.66180262)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 19, 3, 5]
[Action Encoded] [0, 1, 0, 1, 19, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(15.94044567), array(15.94044567), array(15.94044567), array(15.94044567), array(15.94044567), array(15.94044567), array(15.94044567)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 3, 1, 3, 12, 3, 1]
[Action Encoded] [0, 3, 1, 3, 12, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(8.13637417), array(8.13637417), array(8.13637417), array(8.13637417), array(8.13637417), array(8.13637417), array(8.13637417)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 11, 1, 1]
[Action Encoded] [0, 1, 2, 1, 11, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 30, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 30, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(15.12592176), array(15.12592176), array(15.12592176), array(15.12592176), array(15.12592176), array(15.12592176), array(15.12592176)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 14, 0, 3]
[Action Encoded] [0, 0, 1, 1, 14, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(2.47364682), array(2.47364682), array(2.47364682), array(2.47364682), array(2.47364682), array(2.47364682), array(2.47364682)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 3, 1, 0, 1, 0, 2]
[Action Encoded] [0, 3, 1, 0, 1, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 20, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 20, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 40  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
[array(8.44788928), array(8.44788928), array(8.44788928), array(8.44788928), array(8.44788928), array(8.44788928), array(8.44788928)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 3, 2, 1]
[Action Encoded] [1, 4, 2, 1, 3, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 22, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 22, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(1.89097351), array(1.89097351), array(1.89097351), array(1.89097351), array(1.89097351), array(1.89097351), array(1.89097351)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 7, 0, 9]
[Action Encoded] [0, 2, 1, 1, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(16.02301883), array(16.02301883), array(16.02301883), array(16.02301883), array(16.02301883), array(16.02301883), array(16.02301883)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 0, 0, 1, 9, 1, 0]
[Action Encoded] [0, 0, 0, 1, 9, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 28, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 28, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(1.73877319), array(1.73877319), array(1.73877319), array(1.73877319), array(1.73877319), array(1.73877319), array(1.73877319)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 3, 1, 1, 1, 2, 9]
[Action Encoded] [1, 3, 1, 1, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(8.33358113), array(8.33358113), array(8.33358113), array(8.33358113), array(8.33358113), array(8.33358113), array(8.33358113)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 0, 4, 0, 19, 0, 4]
[Action Encoded] [1, 0, 4, 0, 19, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(2.4249833), array(2.4249833), array(2.4249833), array(2.4249833), array(2.4249833), array(2.4249833), array(2.4249833)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 4, 1, 2, 8, 2, 3]
[Action Encoded] [0, 4, 1, 2, 8, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 27, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 27, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(1.92335664), array(1.92335664), array(1.92335664), array(1.92335664), array(1.92335664), array(1.92335664), array(1.92335664)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 1, 4, 2, 1, 2, 2]
[Action Encoded] [0, 1, 4, 2, 1, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(15.723285), array(15.723285), array(15.723285), array(15.723285), array(15.723285), array(15.723285), array(15.723285)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 2, 4, 2, 10, 3, 7]
[Action Encoded] [0, 2, 4, 2, 10, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(16.01486095), array(16.01486095), array(16.01486095), array(16.01486095), array(16.01486095), array(16.01486095), array(16.01486095)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 2, 1, 0, 8, 2, 3]
[Action Encoded] [0, 2, 1, 0, 8, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(15.98813996), array(15.98813996), array(15.98813996), array(15.98813996), array(15.98813996), array(15.98813996), array(15.98813996)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 16, 3, 5]
[Action Encoded] [0, 1, 3, 3, 16, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(15.93301235), array(15.93301235), array(15.93301235), array(15.93301235), array(15.93301235), array(15.93301235), array(15.93301235)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:42:22 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent5', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 6
)
[Env][Action] [0, 0, 3, 2, 20, 1, 3]
[Action Encoded] [0, 0, 3, 2, 20, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(3.02686582), array(3.02686582), array(3.02686582), array(3.02686582), array(3.02686582), array(3.02686582), array(3.02686582)]
Episode 1 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 13, 1, 4]
[Action Encoded] [1, 3, 2, 3, 13, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 2  Rewards: [6.367410382250436, 6.367410382250436, 6.367410382250436, 6.367410382250436, 6.367410382250436, 6.367410382250436, 6.367410382250436]
Episode 2 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 6, 2, 3]
[Action Encoded] [1, 3, 2, 3, 6, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(5.47754513), array(5.47754513), array(5.47754513), array(5.47754513), array(5.47754513), array(5.47754513), array(5.47754513)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 4, 0, 2, 3, 2, 5]
[Action Encoded] [0, 4, 0, 2, 3, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628), array(2.31342628)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 2, 0, 2, 1, 2, 3]
[Action Encoded] [0, 2, 0, 2, 1, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 20, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 20, 2, 4]
[Action Encoded] [0, 1, 4, 3, 20, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 6, 3, 6]
[Action Encoded] [0, 3, 4, 1, 6, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(6.09787184), array(6.09787184), array(6.09787184), array(6.09787184), array(6.09787184), array(6.09787184), array(6.09787184)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 3, 4, 3, 0, 2, 0]
[Action Encoded] [0, 3, 4, 3, 0, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 19, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 19, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(4.1791176), array(4.1791176), array(4.1791176), array(4.1791176), array(4.1791176), array(4.1791176), array(4.1791176)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 3, 4, 2, 10, 2, 5]
[Action Encoded] [1, 3, 4, 2, 10, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(5.60769913), array(5.60769913), array(5.60769913), array(5.60769913), array(5.60769913), array(5.60769913), array(5.60769913)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 10, 3, 9]
[Action Encoded] [0, 1, 3, 3, 10, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(11.4964287), array(11.4964287), array(11.4964287), array(11.4964287), array(11.4964287), array(11.4964287), array(11.4964287)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 3, 1, 2]
[Action Encoded] [0, 0, 0, 3, 3, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 22, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 22, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 11  Rewards: [3.2074261588095596, 3.2074261588095596, 3.2074261588095596, 3.2074261588095596, 3.2074261588095596, 3.2074261588095596, 3.2074261588095596]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 9, 3, 3]
[Action Encoded] [1, 3, 4, 3, 9, 3, 3]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 28, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 28, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(5.73527864), array(5.73527864), array(5.73527864), array(5.73527864), array(5.73527864), array(5.73527864), array(5.73527864)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 3, 0, 1, 3, 1, 8]
[Action Encoded] [0, 3, 0, 1, 3, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 3, 0, 7]
[Action Encoded] [0, 4, 0, 0, 3, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 11, 1, 1]
[Action Encoded] [1, 0, 0, 4, 11, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 30, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 30, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 4, 1, 2, 13, 0, 6]
[Action Encoded] [1, 4, 1, 2, 13, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 6, 3, 8]
[Action Encoded] [0, 0, 4, 2, 6, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767), array(3.1324767)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 3, 2, 2, 4, 1, 9]
[Action Encoded] [1, 3, 2, 2, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 2, 2, 4, 12, 1, 8]
[Action Encoded] [0, 2, 2, 4, 12, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 12, 1, 4]
[Action Encoded] [0, 4, 2, 3, 12, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(2.25133325), array(2.25133325), array(2.25133325), array(2.25133325), array(2.25133325), array(2.25133325), array(2.25133325)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 4, 4, 2, 7, 0, 2]
[Action Encoded] [1, 4, 4, 2, 7, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 18, 1, 4]
[Action Encoded] [1, 4, 3, 2, 18, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 17, 2, 1]
[Action Encoded] [0, 3, 2, 3, 17, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 19, 3, 8]
[Action Encoded] [0, 0, 0, 2, 19, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 38, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 38, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556), array(3.23820556)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 10, 1, 6]
[Action Encoded] [0, 2, 3, 1, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 13, 2, 5]
[Action Encoded] [1, 3, 4, 0, 13, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(5.87812872), array(5.87812872), array(5.87812872), array(5.87812872), array(5.87812872), array(5.87812872), array(5.87812872)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 4, 1, 8]
[Action Encoded] [0, 3, 3, 3, 4, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 23, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644), array(6.23848644)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 4, 3, 2, 17, 0, 1]
[Action Encoded] [0, 4, 3, 2, 17, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(2.25492867), array(2.25492867), array(2.25492867), array(2.25492867), array(2.25492867), array(2.25492867), array(2.25492867)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 3, 4, 2, 1, 3, 7]
[Action Encoded] [0, 3, 4, 2, 1, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(5.92206561), array(5.92206561), array(5.92206561), array(5.92206561), array(5.92206561), array(5.92206561), array(5.92206561)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 4, 1, 2, 18, 3, 4]
[Action Encoded] [1, 4, 1, 2, 18, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 37, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 37, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 12, 1, 7]
[Action Encoded] [1, 0, 2, 0, 12, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 31, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 31, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(3.25219582), array(3.25219582), array(3.25219582), array(3.25219582), array(3.25219582), array(3.25219582), array(3.25219582)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 0, 3, 7]
[Action Encoded] [1, 4, 2, 4, 0, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 19, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(2.32868802), array(2.32868802), array(2.32868802), array(2.32868802), array(2.32868802), array(2.32868802), array(2.32868802)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 1, 0, 0]
[Action Encoded] [0, 1, 3, 3, 1, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 20, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 20, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(7.89544826), array(7.89544826), array(7.89544826), array(7.89544826), array(7.89544826), array(7.89544826), array(7.89544826)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 13, 1, 0]
[Action Encoded] [1, 4, 3, 0, 13, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 32, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 32, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(1.85455518), array(1.85455518), array(1.85455518), array(1.85455518), array(1.85455518), array(1.85455518), array(1.85455518)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 0, 0, 0, 10, 2, 1]
[Action Encoded] [0, 0, 0, 0, 10, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(3.3183646), array(3.3183646), array(3.3183646), array(3.3183646), array(3.3183646), array(3.3183646), array(3.3183646)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 0, 5]
[Action Encoded] [1, 4, 2, 1, 19, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 1, 3, 0, 9, 0, 8]
[Action Encoded] [1, 1, 3, 0, 9, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(10.73665137), array(10.73665137), array(10.73665137), array(10.73665137), array(10.73665137), array(10.73665137), array(10.73665137)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 0, 1, 3, 16, 1, 4]
[Action Encoded] [0, 0, 1, 3, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(3.07248264), array(3.07248264), array(3.07248264), array(3.07248264), array(3.07248264), array(3.07248264), array(3.07248264)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 2, 3, 1]
[Action Encoded] [1, 1, 1, 3, 2, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489), array(11.0236489)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 4, 3, 1, 6, 3, 7]
[Action Encoded] [0, 4, 3, 1, 6, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 332280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 1, 0, 1]
[Action Encoded] [0, 4, 2, 2, 1, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 20, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 20, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(2.2724697), array(2.2724697), array(2.2724697), array(2.2724697), array(2.2724697), array(2.2724697), array(2.2724697)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 20, 3, 9]
[Action Encoded] [1, 0, 3, 0, 20, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122), array(3.22009122)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 0, 4, 0, 6, 0, 9]
[Action Encoded] [0, 0, 4, 0, 6, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 25, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 25, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 43  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 43 finished after 1 steps.
[Env][Action] [1, 0, 0, 3, 12, 1, 2]
[Action Encoded] [1, 0, 0, 3, 12, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194), array(3.27286194)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 4, 2, 2, 17, 0, 9]
[Action Encoded] [0, 4, 2, 2, 17, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339), array(2.26034339)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 18, 1, 0]
[Action Encoded] [1, 0, 2, 1, 18, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 37, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 37, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 17, 0, 6]
[Action Encoded] [1, 2, 4, 4, 17, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.14190647), array(11.14190647), array(11.14190647), array(11.14190647), array(11.14190647), array(11.14190647), array(11.14190647)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 0, 3, 3, 0, 0, 9]
[Action Encoded] [1, 0, 3, 3, 0, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 0, 2, 2, 15, 1, 5]
[Action Encoded] [0, 0, 2, 2, 15, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 49  Rewards: [3.071518270724409, 3.071518270724409, 3.071518270724409, 3.071518270724409, 3.071518270724409, 3.071518270724409, 3.071518270724409]
Episode 49 finished after 1 steps.
[Env][Action] [1, 2, 4, 3, 20, 3, 4]
[Action Encoded] [1, 2, 4, 3, 20, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(10.56533229), array(10.56533229), array(10.56533229), array(10.56533229), array(10.56533229), array(10.56533229), array(10.56533229)]
Episode 50 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 3, 0, 1]
[Action Encoded] [1, 0, 3, 4, 3, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 3]
[Action Encoded] [0, 1, 3, 4, 8, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 11, 0, 2]
[Action Encoded] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[1, 4, 3, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 3, 2, 4]
[Action Encoded] [1, 4, 0, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 4, 0, 0]
[Action Encoded] [1, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 15, 2, 2]
[Action Encoded] [1, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 11, 2, 0]
[Action Encoded] [1, 3, 2, 4, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 3]
[Action Encoded] [1, 4, 2, 4, 9, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 6, 0, 2]
[Action Encoded] [1, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 6, 1, 3]
[Action Encoded] [1, 1, 0, 4, 6, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794), array(10.91146794)]
Episode 64 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 5, 1, 4]
[Action Encoded] [1, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 7, 0, 9]
[Action Encoded] [1, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 8, 0, 9]
[Action Encoded] [1, 0, 3, 0, 8, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
Maximum steps per episodes reached!
Episode: 69  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 2]
[Action Encoded] [0, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [1, 3, 2, 3, 19, 0, 0]
[Action Encoded] [1, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573), array(4.62142573)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 9]
[Action Encoded] [0, 4, 3, 3, 14, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 14, 0, 4]
[Action Encoded] [1, 4, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 78 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 17, 2, 6]
[Action Encoded] [1, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869, 2.32485374026869]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 2, 2, 0]
[Action Encoded] [1, 1, 0, 4, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 0, 4, 5, 2, 9]
[Action Encoded] [1, 3, 0, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 14, 1, 2]
[Action Encoded] [0, 0, 2, 4, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 1, 2, 9]
[Action Encoded] [1, 3, 3, 4, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 2, 2, 4]
[Action Encoded] [1, 3, 3, 4, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 9]
[Action Encoded] [0, 0, 2, 4, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 4, 1, 9]
[Action Encoded] [0, 3, 4, 4, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 1, 9]
[Action Encoded] [0, 1, 4, 4, 12, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 0, 3]
[Action Encoded] [1, 0, 2, 3, 15, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 20, 2, 2]
[Action Encoded] [1, 4, 4, 3, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:43:09 UTC 2024
Total Execution Time: 47 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent0', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 12
)
[Env][Action] [0, 2, 1, 4, 7, 2, 0]
[Action Encoded] [0, 2, 1, 4, 7, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(8.28726231), array(8.28726231), array(8.28726231), array(8.28726231), array(8.28726231), array(8.28726231), array(8.28726231)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 17, 1, 7]
[Action Encoded] [0, 2, 3, 2, 17, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 9, 2, 9]
[Action Encoded] [0, 3, 0, 4, 9, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 28, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 28, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 3 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 5, 3, 2]
[Action Encoded] [0, 2, 0, 4, 5, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(15.72995915), array(15.72995915), array(15.72995915), array(15.72995915), array(15.72995915), array(15.72995915), array(15.72995915)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 4, 0, 4, 6, 2, 7]
[Action Encoded] [1, 4, 0, 4, 6, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(1.89821239), array(1.89821239), array(1.89821239), array(1.89821239), array(1.89821239), array(1.89821239), array(1.89821239)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 12, 1, 2]
[Action Encoded] [0, 0, 1, 1, 12, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(2.46310347), array(2.46310347), array(2.46310347), array(2.46310347), array(2.46310347), array(2.46310347), array(2.46310347)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 4, 0, 8]
[Action Encoded] [0, 4, 2, 4, 4, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(1.85603661), array(1.85603661), array(1.85603661), array(1.85603661), array(1.85603661), array(1.85603661), array(1.85603661)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 2, 0, 9]
[Action Encoded] [0, 1, 4, 3, 2, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 21, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 20, 3, 6]
[Action Encoded] [0, 4, 2, 0, 20, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(1.93947445), array(1.93947445), array(1.93947445), array(1.93947445), array(1.93947445), array(1.93947445), array(1.93947445)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 8, 3, 4]
[Action Encoded] [1, 4, 0, 3, 8, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 27, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 27, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(1.91570614), array(1.91570614), array(1.91570614), array(1.91570614), array(1.91570614), array(1.91570614), array(1.91570614)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 19, 3, 7]
[Action Encoded] [0, 0, 2, 1, 19, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(2.45025523), array(2.45025523), array(2.45025523), array(2.45025523), array(2.45025523), array(2.45025523), array(2.45025523)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 1, 0, 2, 9, 1, 2]
[Action Encoded] [0, 1, 0, 2, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 98280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(15.73239343), array(15.73239343), array(15.73239343), array(15.73239343), array(15.73239343), array(15.73239343), array(15.73239343)]
Episode 12 finished after 1 steps.
[Env][Action] [1, 3, 0, 3, 1, 2, 8]
[Action Encoded] [1, 3, 0, 3, 1, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 20, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 20, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(9.19460031), array(9.19460031), array(9.19460031), array(9.19460031), array(9.19460031), array(9.19460031), array(9.19460031)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 18, 0, 5]
[Action Encoded] [1, 0, 4, 4, 18, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(2.33272779), array(2.33272779), array(2.33272779), array(2.33272779), array(2.33272779), array(2.33272779), array(2.33272779)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 3, 1, 2, 11, 1, 4]
[Action Encoded] [0, 3, 1, 2, 11, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(8.48751482), array(8.48751482), array(8.48751482), array(8.48751482), array(8.48751482), array(8.48751482), array(8.48751482)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 11, 3, 9]
[Action Encoded] [0, 1, 3, 3, 11, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(16.0145366), array(16.0145366), array(16.0145366), array(16.0145366), array(16.0145366), array(16.0145366), array(16.0145366)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 3, 2, 2, 17, 2, 1]
[Action Encoded] [0, 3, 2, 2, 17, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(8.28627731), array(8.28627731), array(8.28627731), array(8.28627731), array(8.28627731), array(8.28627731), array(8.28627731)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 15, 3, 0]
[Action Encoded] [1, 4, 2, 4, 15, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(1.32636663), array(1.32636663), array(1.32636663), array(1.32636663), array(1.32636663), array(1.32636663), array(1.32636663)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 18, 1, 3]
[Action Encoded] [0, 3, 0, 4, 18, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(8.4583503), array(8.4583503), array(8.4583503), array(8.4583503), array(8.4583503), array(8.4583503), array(8.4583503)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 2, 4, 3, 10, 3, 5]
[Action Encoded] [0, 2, 4, 3, 10, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(15.92753042), array(15.92753042), array(15.92753042), array(15.92753042), array(15.92753042), array(15.92753042), array(15.92753042)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 9, 2, 0]
[Action Encoded] [0, 1, 2, 1, 9, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 28, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 28, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(8.30773118), array(8.30773118), array(8.30773118), array(8.30773118), array(8.30773118), array(8.30773118), array(8.30773118)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 2, 2, 0, 6, 0, 6]
[Action Encoded] [0, 2, 2, 0, 6, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 25, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 25, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(16.02521661), array(16.02521661), array(16.02521661), array(16.02521661), array(16.02521661), array(16.02521661), array(16.02521661)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 5, 2, 7]
[Action Encoded] [1, 3, 2, 0, 5, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 24, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 24, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(9.00300685), array(9.00300685), array(9.00300685), array(9.00300685), array(9.00300685), array(9.00300685), array(9.00300685)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 0, 4, 3, 10, 3, 2]
[Action Encoded] [1, 0, 4, 3, 10, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(2.34349385), array(2.34349385), array(2.34349385), array(2.34349385), array(2.34349385), array(2.34349385), array(2.34349385)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 1, 1, 0, 20, 2, 4]
[Action Encoded] [0, 1, 1, 0, 20, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(15.94881645), array(15.94881645), array(15.94881645), array(15.94881645), array(15.94881645), array(15.94881645), array(15.94881645)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 1, 1, 4, 9, 2, 8]
[Action Encoded] [1, 1, 1, 4, 9, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 28, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43600486.38 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 28, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(14.82462888), array(14.82462888), array(14.82462888), array(14.82462888), array(14.82462888), array(14.82462888), array(14.82462888)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 2, 3, 6]
[Action Encoded] [1, 2, 3, 4, 2, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(14.95475898), array(14.95475898), array(14.95475898), array(14.95475898), array(14.95475898), array(14.95475898), array(14.95475898)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 0, 4, 1, 15, 2, 1]
[Action Encoded] [0, 0, 4, 1, 15, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(2.34939726), array(2.34939726), array(2.34939726), array(2.34939726), array(2.34939726), array(2.34939726), array(2.34939726)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 20, 0, 1]
[Action Encoded] [1, 3, 3, 1, 20, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(7.96072562), array(7.96072562), array(7.96072562), array(7.96072562), array(7.96072562), array(7.96072562), array(7.96072562)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 1, 2, 2, 13, 1, 7]
[Action Encoded] [0, 1, 2, 2, 13, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 32, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 32, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(16.01891635), array(16.01891635), array(16.01891635), array(16.01891635), array(16.01891635), array(16.01891635), array(16.01891635)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 4, 4, 2, 0, 3, 6]
[Action Encoded] [1, 4, 4, 2, 0, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 2, 4, 0, 18, 0, 7]
[Action Encoded] [1, 2, 4, 0, 18, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 37, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 37, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(14.78978795), array(14.78978795), array(14.78978795), array(14.78978795), array(14.78978795), array(14.78978795), array(14.78978795)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 15, 1, 1]
[Action Encoded] [0, 1, 0, 4, 15, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(15.12363078), array(15.12363078), array(15.12363078), array(15.12363078), array(15.12363078), array(15.12363078), array(15.12363078)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 4, 1, 19, 3, 4]
[Action Encoded] [1, 0, 4, 1, 19, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(2.40066841), array(2.40066841), array(2.40066841), array(2.40066841), array(2.40066841), array(2.40066841), array(2.40066841)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 2, 2, 1]
[Action Encoded] [1, 4, 2, 4, 2, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(1.83187593), array(1.83187593), array(1.83187593), array(1.83187593), array(1.83187593), array(1.83187593), array(1.83187593)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 4, 0, 7]
[Action Encoded] [0, 4, 0, 0, 4, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(1.9846284), array(1.9846284), array(1.9846284), array(1.9846284), array(1.9846284), array(1.9846284), array(1.9846284)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 1, 3, 2, 6, 3, 7]
[Action Encoded] [0, 1, 3, 2, 6, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(16.01578771), array(16.01578771), array(16.01578771), array(16.01578771), array(16.01578771), array(16.01578771), array(16.01578771)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 2, 3, 2]
[Action Encoded] [0, 4, 0, 0, 2, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(1.9781069), array(1.9781069), array(1.9781069), array(1.9781069), array(1.9781069), array(1.9781069), array(1.9781069)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 4, 3, 2, 17, 1, 7]
[Action Encoded] [0, 4, 3, 2, 17, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(1.87705879), array(1.87705879), array(1.87705879), array(1.87705879), array(1.87705879), array(1.87705879), array(1.87705879)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 18, 2, 8]
[Action Encoded] [1, 4, 3, 2, 18, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 37, 'rrd': 5, 'refi': 379080}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(1.87756249), array(1.87756249), array(1.87756249), array(1.87756249), array(1.87756249), array(1.87756249), array(1.87756249)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 3, 2, 3]
[Action Encoded] [0, 4, 3, 3, 3, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(1.86194777), array(1.86194777), array(1.86194777), array(1.86194777), array(1.86194777), array(1.86194777), array(1.86194777)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 2, 4, 0, 8, 1, 7]
[Action Encoded] [0, 2, 4, 0, 8, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 27, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 27, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(16.01611547), array(16.01611547), array(16.01611547), array(16.01611547), array(16.01611547), array(16.01611547), array(16.01611547)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 2, 4, 2, 3, 1, 1]
[Action Encoded] [1, 2, 4, 2, 3, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 22, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 22, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(13.81158153), array(13.81158153), array(13.81158153), array(13.81158153), array(13.81158153), array(13.81158153), array(13.81158153)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 16, 1, 2]
[Action Encoded] [1, 0, 0, 2, 16, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(2.46569329), array(2.46569329), array(2.46569329), array(2.46569329), array(2.46569329), array(2.46569329), array(2.46569329)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 1, 1, 1, 12, 3, 7]
[Action Encoded] [0, 1, 1, 1, 12, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854), array(16.0229854)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 0, 2, 2, 20, 0, 3]
[Action Encoded] [1, 0, 2, 2, 20, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 39, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 39, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.42588995), array(2.42588995), array(2.42588995), array(2.42588995), array(2.42588995), array(2.42588995), array(2.42588995)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 3, 1, 0, 20, 1, 4]
[Action Encoded] [0, 3, 1, 0, 20, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 39, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(8.54767323), array(8.54767323), array(8.54767323), array(8.54767323), array(8.54767323), array(8.54767323), array(8.54767323)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 0, 1, 2, 13, 3, 1]
[Action Encoded] [0, 0, 1, 2, 13, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 32, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(2.39644954), array(2.39644954), array(2.39644954), array(2.39644954), array(2.39644954), array(2.39644954), array(2.39644954)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 2, 2, 3, 15, 1, 2]
[Action Encoded] [0, 2, 2, 3, 15, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(15.72143788), array(15.72143788), array(15.72143788), array(15.72143788), array(15.72143788), array(15.72143788), array(15.72143788)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 0, 2, 2, 5, 0, 6]
[Action Encoded] [0, 0, 2, 2, 5, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 24, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 24, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(2.42595893), array(2.42595893), array(2.42595893), array(2.42595893), array(2.42595893), array(2.42595893), array(2.42595893)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:44:15 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent1', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 10
)
[Env][Action] [1, 2, 3, 0, 6, 3, 0]
[Action Encoded] [1, 2, 3, 0, 6, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 25, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 25, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(6.9477031), array(6.9477031), array(6.9477031), array(6.9477031), array(6.9477031), array(6.9477031), array(6.9477031)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 2, 1, 4, 5, 3, 1]
[Action Encoded] [0, 2, 1, 4, 5, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 24, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214), array(11.5596214)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 13, 0, 7]
[Action Encoded] [1, 4, 3, 2, 13, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 32, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852), array(2.32740852)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 1, 3, 3, 9, 1, 4]
[Action Encoded] [0, 1, 3, 3, 9, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 28, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 28, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696), array(11.48821696)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 5, 3, 1]
[Action Encoded] [1, 3, 4, 1, 5, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221), array(5.50746221)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 19, 0, 1]
[Action Encoded] [1, 0, 0, 2, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 3, 1, 0, 17, 0, 6]
[Action Encoded] [0, 3, 1, 0, 17, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 7  Rewards: [6.540111371391661, 6.540111371391661, 6.540111371391661, 6.540111371391661, 6.540111371391661, 6.540111371391661, 6.540111371391661]
Episode 7 finished after 1 steps.
[Env][Action] [0, 2, 3, 0, 16, 0, 6]
[Action Encoded] [0, 2, 3, 0, 16, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 9, 2, 2]
[Action Encoded] [1, 2, 3, 2, 9, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 28, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 28, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.51556796), array(11.51556796), array(11.51556796), array(11.51556796), array(11.51556796), array(11.51556796), array(11.51556796)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 7, 2, 3]
[Action Encoded] [0, 4, 3, 3, 7, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 4, 0, 4, 1, 3, 5]
[Action Encoded] [0, 4, 0, 4, 1, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 20, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 20, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 20, 0, 6]
[Action Encoded] [0, 4, 0, 0, 20, 0, 6]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 3, 4, 2, 8, 3, 0]
[Action Encoded] [0, 3, 4, 2, 8, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(4.54379095), array(4.54379095), array(4.54379095), array(4.54379095), array(4.54379095), array(4.54379095), array(4.54379095)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 13, 2, 1]
[Action Encoded] [0, 1, 0, 4, 13, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 8, 3, 7]
[Action Encoded] [0, 4, 0, 0, 8, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 19, 2, 9]
[Action Encoded] [0, 3, 3, 1, 19, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(6.43762559), array(6.43762559), array(6.43762559), array(6.43762559), array(6.43762559), array(6.43762559), array(6.43762559)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 0, 3, 1, 4, 1, 2]
[Action Encoded] [0, 0, 3, 1, 4, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 2, 0, 1, 14, 0, 1]
[Action Encoded] [0, 2, 0, 1, 14, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 1, 4, 0, 11, 3, 1]
[Action Encoded] [1, 1, 4, 0, 11, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 30, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 30, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(10.78705818), array(10.78705818), array(10.78705818), array(10.78705818), array(10.78705818), array(10.78705818), array(10.78705818)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 16, 0, 2]
[Action Encoded] [1, 0, 2, 1, 16, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 3, 1, 2, 15, 0, 5]
[Action Encoded] [1, 3, 1, 2, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 34, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(6.47142875), array(6.47142875), array(6.47142875), array(6.47142875), array(6.47142875), array(6.47142875), array(6.47142875)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 11, 0, 2]
[Action Encoded] [0, 3, 3, 1, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 0, 0, 4]
[Action Encoded] [1, 4, 4, 1, 0, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 19, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 19, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 15, 1, 9]
[Action Encoded] [0, 0, 1, 1, 15, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 3, 1, 1, 8, 1, 9]
[Action Encoded] [0, 3, 1, 1, 8, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(6.30587202), array(6.30587202), array(6.30587202), array(6.30587202), array(6.30587202), array(6.30587202), array(6.30587202)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 0, 3, 2, 17, 3, 2]
[Action Encoded] [0, 0, 3, 2, 17, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(3.09189801), array(3.09189801), array(3.09189801), array(3.09189801), array(3.09189801), array(3.09189801), array(3.09189801)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 1, 3, 3, 19, 2, 0]
[Action Encoded] [1, 1, 3, 3, 19, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 38, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 38, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(7.15229671), array(7.15229671), array(7.15229671), array(7.15229671), array(7.15229671), array(7.15229671), array(7.15229671)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 3, 0, 6]
[Action Encoded] [1, 2, 3, 1, 3, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(10.69244527), array(10.69244527), array(10.69244527), array(10.69244527), array(10.69244527), array(10.69244527), array(10.69244527)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 5, 2, 9]
[Action Encoded] [0, 1, 4, 1, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 8, 1, 1]
[Action Encoded] [1, 1, 2, 2, 8, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 27, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 27, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(11.12275501), array(11.12275501), array(11.12275501), array(11.12275501), array(11.12275501), array(11.12275501), array(11.12275501)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 1, 0, 3, 20, 2, 6]
[Action Encoded] [1, 1, 0, 3, 20, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(11.99366424), array(11.99366424), array(11.99366424), array(11.99366424), array(11.99366424), array(11.99366424), array(11.99366424)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 0, 4, 3, 5, 0, 1]
[Action Encoded] [1, 0, 4, 3, 5, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(3.14253603), array(3.14253603), array(3.14253603), array(3.14253603), array(3.14253603), array(3.14253603), array(3.14253603)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 17, 0, 8]
[Action Encoded] [1, 0, 3, 2, 17, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956), array(3.1648956)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 1, 2, 1, 13, 1, 1]
[Action Encoded] [1, 1, 2, 1, 13, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 32, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 32, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(11.14587924), array(11.14587924), array(11.14587924), array(11.14587924), array(11.14587924), array(11.14587924), array(11.14587924)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 10, 3, 5]
[Action Encoded] [1, 1, 1, 3, 10, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 20, 1, 8]
[Action Encoded] [1, 3, 3, 1, 20, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499), array(6.37839499)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 3, 2, 2, 1, 1, 1]
[Action Encoded] [1, 3, 2, 2, 1, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(5.4829604), array(5.4829604), array(5.4829604), array(5.4829604), array(5.4829604), array(5.4829604), array(5.4829604)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 3, 1, 2, 0, 2, 2]
[Action Encoded] [0, 3, 1, 2, 0, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(6.35282296), array(6.35282296), array(6.35282296), array(6.35282296), array(6.35282296), array(6.35282296), array(6.35282296)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 2, 1, 4, 6, 1, 3]
[Action Encoded] [1, 2, 1, 4, 6, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(10.80717108), array(10.80717108), array(10.80717108), array(10.80717108), array(10.80717108), array(10.80717108), array(10.80717108)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 2, 4, 2, 10, 2, 0]
[Action Encoded] [0, 2, 4, 2, 10, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 4680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(7.39945021), array(7.39945021), array(7.39945021), array(7.39945021), array(7.39945021), array(7.39945021), array(7.39945021)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 2, 2, 1, 1, 2, 7]
[Action Encoded] [1, 2, 2, 1, 1, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 12, 1, 2]
[Action Encoded] [1, 0, 4, 4, 12, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 2, 3, 4, 14, 0, 5]
[Action Encoded] [0, 2, 3, 4, 14, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(11.38539952), array(11.38539952), array(11.38539952), array(11.38539952), array(11.38539952), array(11.38539952), array(11.38539952)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 17, 2, 7]
[Action Encoded] [0, 3, 2, 3, 17, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 4, 4, 3, 12, 3, 4]
[Action Encoded] [0, 4, 4, 3, 12, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 11, 2, 7]
[Action Encoded] [0, 0, 2, 1, 11, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 1, 4, 2, 16, 0, 8]
[Action Encoded] [0, 1, 4, 2, 16, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 0, 2, 2, 10, 1, 6]
[Action Encoded] [1, 0, 2, 2, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 3, 0, 1, 14, 3, 1]
[Action Encoded] [1, 3, 0, 1, 14, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(6.32384771), array(6.32384771), array(6.32384771), array(6.32384771), array(6.32384771), array(6.32384771), array(6.32384771)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 2, 3, 3, 16, 0, 3]
[Action Encoded] [0, 2, 3, 3, 16, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(11.41119726), array(11.41119726), array(11.41119726), array(11.41119726), array(11.41119726), array(11.41119726), array(11.41119726)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 3, 0, 1]
[Action Encoded] [0, 0, 3, 4, 3, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521), array(3.10071521)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 3, 1, 3]
[Action Encoded] [0, 1, 3, 4, 3, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
[array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 11, 0, 2]
[Action Encoded] [1, 4, 3, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 3, 2, 4]
[Action Encoded] [1, 0, 0, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966), array(3.33532966)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 4, 0, 0]
[Action Encoded] [0, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 15, 2, 2]
[Action Encoded] [1, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 11, 2, 0]
[Action Encoded] [1, 3, 2, 0, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 2]
[Action Encoded] [1, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 2]
[Action Encoded] [0, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 6, 1, 9]
[Action Encoded] [0, 1, 0, 1, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 7, 0, 9]
[Action Encoded] [0, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 8, 0, 9]
[Action Encoded] [0, 0, 3, 0, 8, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 69  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 2]
[Action Encoded] [0, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 7, 0, 1]
[Action Encoded] [0, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 8]
[Action Encoded] [0, 4, 3, 3, 14, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 14, 0, 4]
[Action Encoded] [1, 3, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 17, 2, 6]
[Action Encoded] [0, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 2]
[Action Encoded] [1, 1, 2, 4, 10, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 2, 2, 0]
[Action Encoded] [1, 1, 0, 1, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 5, 2, 9]
[Action Encoded] [1, 3, 2, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 2]
[Action Encoded] [0, 0, 2, 4, 16, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 1, 2, 9]
[Action Encoded] [1, 3, 3, 0, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 2, 2, 4]
[Action Encoded] [0, 3, 3, 1, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 16, 1, 9]
[Action Encoded] [0, 0, 2, 1, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 4, 1, 9]
[Action Encoded] [0, 3, 4, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 0, 9]
[Action Encoded] [0, 1, 4, 4, 12, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 13, 2, 3]
[Action Encoded] [0, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 2, 3]
[Action Encoded] [1, 0, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 20, 2, 2]
[Action Encoded] [1, 4, 4, 1, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178), array(2.28781178)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:45:01 UTC 2024
Total Execution Time: 46 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent5', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 6
)
[Env][Action] [0, 0, 3, 3, 0, 0, 5]
[Action Encoded] [0, 0, 3, 3, 0, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(2.37797552), array(2.37797552), array(2.37797552), array(2.37797552), array(2.37797552), array(2.37797552), array(2.37797552)]
Episode 1 finished after 1 steps.
[Env][Action] [1, 1, 2, 3, 17, 3, 2]
[Action Encoded] [1, 1, 2, 3, 17, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 36, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 36, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(14.6878215), array(14.6878215), array(14.6878215), array(14.6878215), array(14.6878215), array(14.6878215), array(14.6878215)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 1, 1, 2, 16, 0, 1]
[Action Encoded] [1, 1, 1, 2, 16, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 35, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 35, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(14.68383034), array(14.68383034), array(14.68383034), array(14.68383034), array(14.68383034), array(14.68383034), array(14.68383034)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 1, 3, 2, 20, 0, 3]
[Action Encoded] [1, 1, 3, 2, 20, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 39, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(14.78904485), array(14.78904485), array(14.78904485), array(14.78904485), array(14.78904485), array(14.78904485), array(14.78904485)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 3, 1, 2, 2, 3, 3]
[Action Encoded] [0, 3, 1, 2, 2, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 21, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 21, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(8.44012881), array(8.44012881), array(8.44012881), array(8.44012881), array(8.44012881), array(8.44012881), array(8.44012881)]
Episode 5 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 9, 1, 7]
[Action Encoded] [0, 3, 4, 1, 9, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 28, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 28, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(8.49715337), array(8.49715337), array(8.49715337), array(8.49715337), array(8.49715337), array(8.49715337), array(8.49715337)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 11, 0, 9]
[Action Encoded] [1, 4, 3, 3, 11, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(1.86064652), array(1.86064652), array(1.86064652), array(1.86064652), array(1.86064652), array(1.86064652), array(1.86064652)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 16, 3, 1]
[Action Encoded] [1, 3, 4, 4, 16, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 35, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 35, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(7.92083645), array(7.92083645), array(7.92083645), array(7.92083645), array(7.92083645), array(7.92083645), array(7.92083645)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 0, 0, 4, 8, 1, 2]
[Action Encoded] [0, 0, 0, 4, 8, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(2.4118318), array(2.4118318), array(2.4118318), array(2.4118318), array(2.4118318), array(2.4118318), array(2.4118318)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 5, 1, 3]
[Action Encoded] [1, 3, 4, 3, 5, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 24, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(7.62277143), array(7.62277143), array(7.62277143), array(7.62277143), array(7.62277143), array(7.62277143), array(7.62277143)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 2, 1, 0]
[Action Encoded] [1, 0, 2, 0, 2, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 21, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 21, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(1.73810759), array(1.73810759), array(1.73810759), array(1.73810759), array(1.73810759), array(1.73810759), array(1.73810759)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 2, 1, 0, 3, 1, 4]
[Action Encoded] [0, 2, 1, 0, 3, 1, 4]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 38687326.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43600486.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
{'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 12  Rewards: [15.956430800849596, 15.956430800849596, 15.956430800849596, 15.956430800849596, 15.956430800849596, 15.956430800849596, 15.956430800849596]
Episode 12 finished after 1 steps.
[Env][Action] [1, 1, 1, 1, 3, 1, 7]
[Action Encoded] [1, 1, 1, 1, 3, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(14.78240489), array(14.78240489), array(14.78240489), array(14.78240489), array(14.78240489), array(14.78240489), array(14.78240489)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 4, 4, 0, 0, 3, 9]
[Action Encoded] [1, 4, 4, 0, 0, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 19, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 19, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 14  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 14 finished after 1 steps.
[Env][Action] [1, 1, 1, 2, 19, 2, 8]
[Action Encoded] [1, 1, 1, 2, 19, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 38, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 38, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(15.59871308), array(15.59871308), array(15.59871308), array(15.59871308), array(15.59871308), array(15.59871308), array(15.59871308)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 1, 0, 3, 10, 0, 7]
[Action Encoded] [1, 1, 0, 3, 10, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(14.98774234), array(14.98774234), array(14.98774234), array(14.98774234), array(14.98774234), array(14.98774234), array(14.98774234)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 2, 3, 0, 16, 0, 3]
[Action Encoded] [0, 2, 3, 0, 16, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 35, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(15.98377553), array(15.98377553), array(15.98377553), array(15.98377553), array(15.98377553), array(15.98377553), array(15.98377553)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 17, 0, 0]
[Action Encoded] [0, 3, 4, 1, 17, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 36, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 36, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(5.12972372), array(5.12972372), array(5.12972372), array(5.12972372), array(5.12972372), array(5.12972372), array(5.12972372)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 0, 1, 0, 12, 0, 5]
[Action Encoded] [1, 0, 1, 0, 12, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 31, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(2.50450771), array(2.50450771), array(2.50450771), array(2.50450771), array(2.50450771), array(2.50450771), array(2.50450771)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 4, 0, 2, 11, 3, 6]
[Action Encoded] [1, 4, 0, 2, 11, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(1.93992614), array(1.93992614), array(1.93992614), array(1.93992614), array(1.93992614), array(1.93992614), array(1.93992614)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 13, 0, 5]
[Action Encoded] [1, 0, 1, 1, 13, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 32, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 32, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(2.47803196), array(2.47803196), array(2.47803196), array(2.47803196), array(2.47803196), array(2.47803196), array(2.47803196)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 3, 4, 4, 5, 1, 5]
[Action Encoded] [1, 3, 4, 4, 5, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 24, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 24, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(8.36513088), array(8.36513088), array(8.36513088), array(8.36513088), array(8.36513088), array(8.36513088), array(8.36513088)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 19, 0, 2]
[Action Encoded] [1, 4, 4, 1, 19, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(1.87051103), array(1.87051103), array(1.87051103), array(1.87051103), array(1.87051103), array(1.87051103), array(1.87051103)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 3, 0, 2]
[Action Encoded] [1, 3, 3, 1, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(8.54108275), array(8.54108275), array(8.54108275), array(8.54108275), array(8.54108275), array(8.54108275), array(8.54108275)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 0, 3, 1, 15, 0, 0]
[Action Encoded] [1, 0, 3, 1, 15, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(1.69373648), array(1.69373648), array(1.69373648), array(1.69373648), array(1.69373648), array(1.69373648), array(1.69373648)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 4, 1, 2, 7, 2, 4]
[Action Encoded] [1, 4, 1, 2, 7, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(1.9146577), array(1.9146577), array(1.9146577), array(1.9146577), array(1.9146577), array(1.9146577), array(1.9146577)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 1, 3, 1, 2, 2, 9]
[Action Encoded] [0, 1, 3, 1, 2, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(16.01985517), array(16.01985517), array(16.01985517), array(16.01985517), array(16.01985517), array(16.01985517), array(16.01985517)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 9, 3, 4]
[Action Encoded] [1, 2, 3, 2, 9, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 28, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 28, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(14.73834753), array(14.73834753), array(14.73834753), array(14.73834753), array(14.73834753), array(14.73834753), array(14.73834753)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 16, 2, 8]
[Action Encoded] [0, 2, 0, 4, 16, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276), array(16.02333276)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 3, 1, 4, 14, 3, 2]
[Action Encoded] [1, 3, 1, 4, 14, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 33, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 33, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(7.98954777), array(7.98954777), array(7.98954777), array(7.98954777), array(7.98954777), array(7.98954777), array(7.98954777)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 19, 3, 1]
[Action Encoded] [0, 1, 2, 4, 19, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(15.11962323), array(15.11962323), array(15.11962323), array(15.11962323), array(15.11962323), array(15.11962323), array(15.11962323)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 4, 4, 2, 16, 1, 6]
[Action Encoded] [0, 4, 4, 2, 16, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 3, 2, 2, 9, 1, 7]
[Action Encoded] [0, 3, 2, 2, 9, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(8.48609279), array(8.48609279), array(8.48609279), array(8.48609279), array(8.48609279), array(8.48609279), array(8.48609279)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 10, 3, 7]
[Action Encoded] [0, 2, 0, 0, 10, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 29, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 29, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(16.02992815), array(16.02992815), array(16.02992815), array(16.02992815), array(16.02992815), array(16.02992815), array(16.02992815)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 1, 3, 1, 20, 3, 8]
[Action Encoded] [1, 1, 3, 1, 20, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 13, 'ras': 39, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(15.00200045), array(15.00200045), array(15.00200045), array(15.00200045), array(15.00200045), array(15.00200045), array(15.00200045)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 1, 0, 2, 12, 3, 8]
[Action Encoded] [1, 1, 0, 2, 12, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 31, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 31, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(14.8954506), array(14.8954506), array(14.8954506), array(14.8954506), array(14.8954506), array(14.8954506), array(14.8954506)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 4, 0, 4, 3, 0, 0]
[Action Encoded] [0, 4, 0, 4, 3, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(1.35631365), array(1.35631365), array(1.35631365), array(1.35631365), array(1.35631365), array(1.35631365), array(1.35631365)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 2, 1, 4, 12, 0, 5]
[Action Encoded] [0, 2, 1, 4, 12, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 4, 1, 0, 15, 3, 5]
[Action Encoded] [1, 4, 1, 0, 15, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 34, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 34, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(1.96288134), array(1.96288134), array(1.96288134), array(1.96288134), array(1.96288134), array(1.96288134), array(1.96288134)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 0, 2, 2]
[Action Encoded] [1, 4, 3, 4, 0, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43600486.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(1.82958789), array(1.82958789), array(1.82958789), array(1.82958789), array(1.82958789), array(1.82958789), array(1.82958789)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 0, 2, 0, 5, 1, 8]
[Action Encoded] [0, 0, 2, 0, 5, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345), array(2.48354345)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 0, 3, 8]
[Action Encoded] [1, 1, 0, 1, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227), array(15.00694227)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 7, 2, 1]
[Action Encoded] [1, 4, 3, 0, 7, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(1.89038948), array(1.89038948), array(1.89038948), array(1.89038948), array(1.89038948), array(1.89038948), array(1.89038948)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 7, 2, 2]
[Action Encoded] [0, 3, 3, 4, 7, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(8.33490819), array(8.33490819), array(8.33490819), array(8.33490819), array(8.33490819), array(8.33490819), array(8.33490819)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 4, 1, 4, 0, 0, 5]
[Action Encoded] [0, 4, 1, 4, 0, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 19, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 19, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(1.87644465), array(1.87644465), array(1.87644465), array(1.87644465), array(1.87644465), array(1.87644465), array(1.87644465)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 3, 4, 1, 16, 0, 2]
[Action Encoded] [1, 3, 4, 1, 16, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(8.55647993), array(8.55647993), array(8.55647993), array(8.55647993), array(8.55647993), array(8.55647993), array(8.55647993)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 2, 2, 0, 2, 2, 4]
[Action Encoded] [1, 2, 2, 0, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(14.67145479), array(14.67145479), array(14.67145479), array(14.67145479), array(14.67145479), array(14.67145479), array(14.67145479)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 1, 2, 3, 5, 3, 5]
[Action Encoded] [0, 1, 2, 3, 5, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 24, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 24, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(15.93517969), array(15.93517969), array(15.93517969), array(15.93517969), array(15.93517969), array(15.93517969), array(15.93517969)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 20, 0, 8]
[Action Encoded] [0, 1, 0, 1, 20, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 39, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 39, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(16.02643006), array(16.02643006), array(16.02643006), array(16.02643006), array(16.02643006), array(16.02643006), array(16.02643006)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 19, 0, 0]
[Action Encoded] [0, 0, 2, 1, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(1.72002433), array(1.72002433), array(1.72002433), array(1.72002433), array(1.72002433), array(1.72002433), array(1.72002433)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:46:12 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 990468.56 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent6', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 5
)
[Env][Action] [0, 1, 0, 3, 0, 1, 2]
[Action Encoded] [0, 1, 0, 3, 0, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 19, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 19, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601), array(11.57086601)]
Episode 1 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 10, 2, 7]
[Action Encoded] [1, 1, 1, 3, 10, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357), array(10.96353357)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 2, 0, 1, 3, 3, 5]
[Action Encoded] [1, 2, 0, 1, 3, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 22, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(11.57733729), array(11.57733729), array(11.57733729), array(11.57733729), array(11.57733729), array(11.57733729), array(11.57733729)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 4, 1, 3, 10, 1, 4]
[Action Encoded] [0, 4, 1, 3, 10, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 9, 0, 6]
[Action Encoded] [0, 0, 3, 0, 9, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 28, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 0, 1, 0, 8, 2, 7]
[Action Encoded] [1, 0, 1, 0, 8, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695), array(3.30938695)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 8, 2, 8]
[Action Encoded] [0, 2, 1, 1, 8, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 4, 1, 4, 3, 3, 5]
[Action Encoded] [0, 4, 1, 4, 3, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 22, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 22, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566), array(2.19874566)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 17, 3, 4]
[Action Encoded] [0, 1, 3, 0, 17, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 15, 1, 8]
[Action Encoded] [1, 1, 0, 4, 15, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(11.90488805), array(11.90488805), array(11.90488805), array(11.90488805), array(11.90488805), array(11.90488805), array(11.90488805)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 8, 0, 0]
[Action Encoded] [0, 2, 3, 1, 8, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 27, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 27, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(7.45329702), array(7.45329702), array(7.45329702), array(7.45329702), array(7.45329702), array(7.45329702), array(7.45329702)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 0, 3, 3, 5, 0, 6]
[Action Encoded] [1, 0, 3, 3, 5, 0, 6]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408), array(3.16694408)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 3, 0, 0, 2, 1, 3]
[Action Encoded] [0, 3, 0, 0, 2, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(6.4827755), array(6.4827755), array(6.4827755), array(6.4827755), array(6.4827755), array(6.4827755), array(6.4827755)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 3, 3, 7]
[Action Encoded] [0, 2, 0, 4, 3, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 22, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 22, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(11.15836423), array(11.15836423), array(11.15836423), array(11.15836423), array(11.15836423), array(11.15836423), array(11.15836423)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 11, 2, 5]
[Action Encoded] [0, 0, 1, 1, 11, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 30, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 0, 4, 1, 18, 2, 1]
[Action Encoded] [1, 0, 4, 1, 18, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177)]
Episode 16 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 20, 3, 2]
[Action Encoded] [1, 1, 2, 0, 20, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 39, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066), array(11.3584066)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 15, 3, 3]
[Action Encoded] [0, 2, 1, 1, 15, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 1, 3, 2, 6, 2, 0]
[Action Encoded] [0, 1, 3, 2, 6, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 19  Rewards: [7.909699968218584, 7.909699968218584, 7.909699968218584, 7.909699968218584, 7.909699968218584, 7.909699968218584, 7.909699968218584]
Episode 19 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 16, 0, 6]
[Action Encoded] [0, 2, 1, 1, 16, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(11.90577239), array(11.90577239), array(11.90577239), array(11.90577239), array(11.90577239), array(11.90577239), array(11.90577239)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 18, 0, 1]
[Action Encoded] [0, 2, 1, 3, 18, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 37, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 37, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 2, 2, 2, 5, 3, 2]
[Action Encoded] [1, 2, 2, 2, 5, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 24, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 24, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(10.76865657), array(10.76865657), array(10.76865657), array(10.76865657), array(10.76865657), array(10.76865657), array(10.76865657)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 7, 0, 7]
[Action Encoded] [1, 2, 4, 4, 7, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(10.86937063), array(10.86937063), array(10.86937063), array(10.86937063), array(10.86937063), array(10.86937063), array(10.86937063)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 18, 0, 4]
[Action Encoded] [1, 0, 2, 1, 18, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 37, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 37, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133), array(3.22646133)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 5, 1, 5]
[Action Encoded] [0, 4, 0, 0, 5, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 4, 2, 1, 1, 3, 7]
[Action Encoded] [0, 4, 2, 1, 1, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 20, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 4, 3, 2, 10, 0, 0]
[Action Encoded] [0, 4, 3, 2, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(1.79330466), array(1.79330466), array(1.79330466), array(1.79330466), array(1.79330466), array(1.79330466), array(1.79330466)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 0, 4, 1, 20, 1, 9]
[Action Encoded] [1, 0, 4, 1, 20, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 39, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177), array(3.17002177)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 9, 3, 9]
[Action Encoded] [0, 2, 0, 4, 9, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 29  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 29 finished after 1 steps.
[Env][Action] [1, 0, 2, 4, 18, 0, 4]
[Action Encoded] [1, 0, 2, 4, 18, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 37, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 37, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 6, 3, 3]
[Action Encoded] [0, 3, 0, 4, 6, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 4, 1, 4, 2, 1, 5]
[Action Encoded] [1, 4, 1, 4, 2, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 21, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 16, 'ras': 21, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 6, 2, 5]
[Action Encoded] [1, 3, 3, 3, 6, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 33  Rewards: [5.753127015498061, 5.753127015498061, 5.753127015498061, 5.753127015498061, 5.753127015498061, 5.753127015498061, 5.753127015498061]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 2, 2, 3, 2, 2]
[Action Encoded] [1, 0, 2, 2, 3, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(3.22221179), array(3.22221179), array(3.22221179), array(3.22221179), array(3.22221179), array(3.22221179), array(3.22221179)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 0, 1, 2, 4, 0, 9]
[Action Encoded] [1, 0, 1, 2, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(3.25652486), array(3.25652486), array(3.25652486), array(3.25652486), array(3.25652486), array(3.25652486), array(3.25652486)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 9, 1, 4]
[Action Encoded] [0, 3, 4, 1, 9, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 28, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 28, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797), array(6.06121797)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 2, 3, 4, 1, 1, 1]
[Action Encoded] [1, 2, 3, 4, 1, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [10.506554359428968, 10.506554359428968, 10.506554359428968, 10.506554359428968, 10.506554359428968, 10.506554359428968, 10.506554359428968]
Episode 37 finished after 1 steps.
[Env][Action] [1, 0, 2, 1, 10, 1, 0]
[Action Encoded] [1, 0, 2, 1, 10, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049), array(2.58177049)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 7, 2, 2]
[Action Encoded] [0, 0, 0, 3, 7, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 26, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(3.20742616), array(3.20742616), array(3.20742616), array(3.20742616), array(3.20742616), array(3.20742616), array(3.20742616)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 13, 1, 5]
[Action Encoded] [1, 1, 4, 1, 13, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 32, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 32, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 40  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[array(11.35039079), array(11.35039079), array(11.35039079), array(11.35039079), array(11.35039079), array(11.35039079), array(11.35039079)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 20, 3, 2]
[Action Encoded] [1, 4, 4, 3, 20, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 4, 1, 0, 17, 0, 7]
[Action Encoded] [1, 4, 1, 0, 17, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 36, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 0, 3, 3, 12, 0, 0]
[Action Encoded] [1, 0, 3, 3, 12, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(2.53922614), array(2.53922614), array(2.53922614), array(2.53922614), array(2.53922614), array(2.53922614), array(2.53922614)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 17, 0, 0]
[Action Encoded] [1, 1, 1, 3, 17, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(7.34819528), array(7.34819528), array(7.34819528), array(7.34819528), array(7.34819528), array(7.34819528), array(7.34819528)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 6, 2, 3]
[Action Encoded] [1, 1, 0, 4, 6, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956), array(11.60425956)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 11, 2, 6]
[Action Encoded] [0, 4, 2, 0, 11, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 16, 2, 2]
[Action Encoded] [0, 2, 0, 0, 16, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 35, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 35, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575), array(11.7758575)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 2, 0, 2, 0, 0, 5]
[Action Encoded] [0, 2, 0, 2, 0, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 19, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575), array(11.7119575)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 14, 0, 0]
[Action Encoded] [0, 4, 0, 1, 14, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 13, 2, 2]
[Action Encoded] [0, 2, 3, 1, 13, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291)]
Episode 50 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 3, 0, 1]
[Action Encoded] [1, 0, 3, 4, 3, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 22, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341), array(3.13448341)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 3]
[Action Encoded] [0, 1, 3, 4, 8, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[1, 4, 3, 0, 11, 0, 2]
[Action Encoded] [1, 4, 3, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409)]
Episode 55 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 3, 2, 4]
[Action Encoded] [1, 4, 0, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465), array(2.45558465)]
Episode 56 finished after 1 steps.
[Env][Action] [1, 1, 4, 1, 4, 0, 0]
[Action Encoded] [1, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291), array(7.05253291)]
Episode 57 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 15, 2, 2]
[Action Encoded] [1, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769), array(6.2314769)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 11, 2, 0]
[Action Encoded] [1, 3, 2, 0, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339), array(4.48312339)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 2]
[Action Encoded] [1, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 2]
[Action Encoded] [0, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 6, 1, 9]
[Action Encoded] [1, 1, 0, 1, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 7, 0, 9]
[Action Encoded] [0, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 8, 0, 9]
[Action Encoded] [1, 0, 3, 0, 8, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 69  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 2]
[Action Encoded] [0, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [1, 0, 3, 4, 7, 0, 1]
[Action Encoded] [1, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973), array(3.13347973)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 8]
[Action Encoded] [0, 4, 3, 3, 14, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 14, 0, 4]
[Action Encoded] [1, 4, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 17, 2, 6]
[Action Encoded] [0, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 2]
[Action Encoded] [1, 1, 2, 4, 10, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 2, 2, 0]
[Action Encoded] [1, 1, 0, 1, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343), array(7.10590343)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 5, 2, 9]
[Action Encoded] [1, 3, 2, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721), array(5.64192721)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 2]
[Action Encoded] [0, 0, 2, 4, 16, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: [3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616, 3.10958284414616]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 1, 2, 9]
[Action Encoded] [1, 3, 3, 0, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 2, 2, 4]
[Action Encoded] [1, 3, 3, 1, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444), array(5.54601444)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 16, 2, 9]
[Action Encoded] [0, 0, 2, 1, 16, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 35, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 4, 1, 9]
[Action Encoded] [0, 3, 4, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 0, 9]
[Action Encoded] [0, 1, 4, 4, 12, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 13, 2, 3]
[Action Encoded] [1, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823), array(6.28799823)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 2, 3]
[Action Encoded] [1, 0, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 20, 2, 2]
[Action Encoded] [1, 4, 4, 3, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:46:59 UTC 2024
Total Execution Time: 47 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [0, 4, 1, 0, 12, 3, 4]
[Action Encoded] [0, 4, 1, 0, 12, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(1.96107683), array(1.96107683), array(1.96107683), array(1.96107683), array(1.96107683), array(1.96107683), array(1.96107683)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 4, 2, 1, 19, 0, 3]
[Action Encoded] [0, 4, 2, 1, 19, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(1.92334612), array(1.92334612), array(1.92334612), array(1.92334612), array(1.92334612), array(1.92334612), array(1.92334612)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 4, 2, 1, 4, 2, 9]
[Action Encoded] [0, 4, 2, 1, 4, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(1.92172538), array(1.92172538), array(1.92172538), array(1.92172538), array(1.92172538), array(1.92172538), array(1.92172538)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 3, 2, 1, 15, 2, 7]
[Action Encoded] [1, 3, 2, 1, 15, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068), array(8.7905068)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 2, 4, 3, 8, 0, 7]
[Action Encoded] [0, 2, 4, 3, 8, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(16.00859131), array(16.00859131), array(16.00859131), array(16.00859131), array(16.00859131), array(16.00859131), array(16.00859131)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 3, 0, 4, 18, 1, 7]
[Action Encoded] [1, 3, 0, 4, 18, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(9.18344368), array(9.18344368), array(9.18344368), array(9.18344368), array(9.18344368), array(9.18344368), array(9.18344368)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 1, 1, 0, 2, 2, 4]
[Action Encoded] [1, 1, 1, 0, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(15.14524872), array(15.14524872), array(15.14524872), array(15.14524872), array(15.14524872), array(15.14524872), array(15.14524872)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 0, 0, 3, 11, 2, 8]
[Action Encoded] [1, 0, 0, 3, 11, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 30, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 30, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(2.45864756), array(2.45864756), array(2.45864756), array(2.45864756), array(2.45864756), array(2.45864756), array(2.45864756)]
Episode 8 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 11, 3, 3]
[Action Encoded] [1, 4, 3, 2, 11, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 30, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(1.88309267), array(1.88309267), array(1.88309267), array(1.88309267), array(1.88309267), array(1.88309267), array(1.88309267)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 1, 1, 0, 9, 2, 8]
[Action Encoded] [1, 1, 1, 0, 9, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 28, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(14.96203672), array(14.96203672), array(14.96203672), array(14.96203672), array(14.96203672), array(14.96203672), array(14.96203672)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 19, 0, 4]
[Action Encoded] [0, 2, 3, 1, 19, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 38, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(15.93653112), array(15.93653112), array(15.93653112), array(15.93653112), array(15.93653112), array(15.93653112), array(15.93653112)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 8, 2, 2]
[Action Encoded] [1, 3, 4, 0, 8, 2, 2]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34377147.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(8.62475601), array(8.62475601), array(8.62475601), array(8.62475601), array(8.62475601), array(8.62475601), array(8.62475601)]
Episode 12 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 2, 2, 3]
[Action Encoded] [1, 2, 4, 4, 2, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(14.58203913), array(14.58203913), array(14.58203913), array(14.58203913), array(14.58203913), array(14.58203913), array(14.58203913)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 3, 1, 1, 2, 3, 4]
[Action Encoded] [1, 3, 1, 1, 2, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 21, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 21, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(9.03984008), array(9.03984008), array(9.03984008), array(9.03984008), array(9.03984008), array(9.03984008), array(9.03984008)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 2, 1, 3, 8, 0, 1]
[Action Encoded] [1, 2, 1, 3, 8, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(13.91189786), array(13.91189786), array(13.91189786), array(13.91189786), array(13.91189786), array(13.91189786), array(13.91189786)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 13, 0, 6]
[Action Encoded] [1, 0, 0, 0, 13, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 32, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 32, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(2.53093411), array(2.53093411), array(2.53093411), array(2.53093411), array(2.53093411), array(2.53093411), array(2.53093411)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 12, 1, 6]
[Action Encoded] [0, 1, 4, 3, 12, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(16.01140968), array(16.01140968), array(16.01140968), array(16.01140968), array(16.01140968), array(16.01140968), array(16.01140968)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 1, 4, 2, 15, 1, 5]
[Action Encoded] [0, 1, 4, 2, 15, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(15.93456039), array(15.93456039), array(15.93456039), array(15.93456039), array(15.93456039), array(15.93456039), array(15.93456039)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 14, 3, 0]
[Action Encoded] [0, 1, 0, 4, 14, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 33, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 33, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(8.30042125), array(8.30042125), array(8.30042125), array(8.30042125), array(8.30042125), array(8.30042125), array(8.30042125)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 7, 2, 2]
[Action Encoded] [1, 1, 4, 2, 7, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(14.54465615), array(14.54465615), array(14.54465615), array(14.54465615), array(14.54465615), array(14.54465615), array(14.54465615)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 0, 2, 3]
[Action Encoded] [1, 2, 1, 1, 0, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(15.41857413), array(15.41857413), array(15.41857413), array(15.41857413), array(15.41857413), array(15.41857413), array(15.41857413)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 3, 0, 0]
[Action Encoded] [0, 0, 0, 2, 3, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(1.73723653), array(1.73723653), array(1.73723653), array(1.73723653), array(1.73723653), array(1.73723653), array(1.73723653)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 3, 4, 3, 13, 2, 8]
[Action Encoded] [0, 3, 4, 3, 13, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(8.46612551), array(8.46612551), array(8.46612551), array(8.46612551), array(8.46612551), array(8.46612551), array(8.46612551)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 0, 1, 0, 11, 0, 7]
[Action Encoded] [0, 0, 1, 0, 11, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(2.50348388), array(2.50348388), array(2.50348388), array(2.50348388), array(2.50348388), array(2.50348388), array(2.50348388)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 11, 1, 6]
[Action Encoded] [1, 3, 3, 0, 11, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(8.78405699), array(8.78405699), array(8.78405699), array(8.78405699), array(8.78405699), array(8.78405699), array(8.78405699)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 2, 0, 2, 9, 3, 1]
[Action Encoded] [1, 2, 0, 2, 9, 3, 1]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41895199.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
{'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(14.17296247), array(14.17296247), array(14.17296247), array(14.17296247), array(14.17296247), array(14.17296247), array(14.17296247)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 2, 0, 2, 3, 0, 6]
[Action Encoded] [0, 2, 0, 2, 3, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869), array(16.02615869)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 3, 3, 6]
[Action Encoded] [0, 2, 0, 0, 3, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(16.03904499), array(16.03904499), array(16.03904499), array(16.03904499), array(16.03904499), array(16.03904499), array(16.03904499)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 2, 2, 2, 16, 1, 1]
[Action Encoded] [1, 2, 2, 2, 16, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(14.07134443), array(14.07134443), array(14.07134443), array(14.07134443), array(14.07134443), array(14.07134443), array(14.07134443)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 0, 1, 3, 11, 2, 1]
[Action Encoded] [1, 0, 1, 3, 11, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 30, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 30, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(2.3758313), array(2.3758313), array(2.3758313), array(2.3758313), array(2.3758313), array(2.3758313), array(2.3758313)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 5, 3, 2]
[Action Encoded] [0, 0, 3, 0, 5, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(2.4373497), array(2.4373497), array(2.4373497), array(2.4373497), array(2.4373497), array(2.4373497), array(2.4373497)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 6, 2, 8]
[Action Encoded] [1, 4, 0, 0, 6, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 25, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 25, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(1.98560838), array(1.98560838), array(1.98560838), array(1.98560838), array(1.98560838), array(1.98560838), array(1.98560838)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 4, 0, 1, 4, 0, 6]
[Action Encoded] [1, 4, 0, 1, 4, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(1.96316772), array(1.96316772), array(1.96316772), array(1.96316772), array(1.96316772), array(1.96316772), array(1.96316772)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 3, 1, 4, 15, 0, 4]
[Action Encoded] [1, 3, 1, 4, 15, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 34, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 34, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(8.05249984), array(8.05249984), array(8.05249984), array(8.05249984), array(8.05249984), array(8.05249984), array(8.05249984)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 7, 1, 6]
[Action Encoded] [1, 3, 2, 0, 7, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 26, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(8.9706259), array(8.9706259), array(8.9706259), array(8.9706259), array(8.9706259), array(8.9706259), array(8.9706259)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 8, 2, 2]
[Action Encoded] [0, 0, 2, 4, 8, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 27, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 27, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(2.36611988), array(2.36611988), array(2.36611988), array(2.36611988), array(2.36611988), array(2.36611988), array(2.36611988)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 3, 3, 6]
[Action Encoded] [0, 4, 2, 3, 3, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 22, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 22, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(1.87736098), array(1.87736098), array(1.87736098), array(1.87736098), array(1.87736098), array(1.87736098), array(1.87736098)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 1, 0, 0]
[Action Encoded] [0, 2, 1, 1, 1, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 20, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(8.31172571), array(8.31172571), array(8.31172571), array(8.31172571), array(8.31172571), array(8.31172571), array(8.31172571)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 1, 3, 0, 19, 1, 8]
[Action Encoded] [0, 1, 3, 0, 19, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 38, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 12, 'ras': 38, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(16.02110712), array(16.02110712), array(16.02110712), array(16.02110712), array(16.02110712), array(16.02110712), array(16.02110712)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 9, 3, 4]
[Action Encoded] [1, 3, 3, 3, 9, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 28, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 28, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(9.00830317), array(9.00830317), array(9.00830317), array(9.00830317), array(9.00830317), array(9.00830317), array(9.00830317)]
Episode 40 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 5, 2, 9]
[Action Encoded] [1, 4, 0, 0, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 41  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 7, 1, 0]
[Action Encoded] [0, 2, 1, 3, 7, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(8.29433501), array(8.29433501), array(8.29433501), array(8.29433501), array(8.29433501), array(8.29433501), array(8.29433501)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 1, 1, 4, 18, 1, 2]
[Action Encoded] [0, 1, 1, 4, 18, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(15.7269271), array(15.7269271), array(15.7269271), array(15.7269271), array(15.7269271), array(15.7269271), array(15.7269271)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 17, 2, 5]
[Action Encoded] [1, 3, 4, 3, 17, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(8.50198086), array(8.50198086), array(8.50198086), array(8.50198086), array(8.50198086), array(8.50198086), array(8.50198086)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 12, 0, 8]
[Action Encoded] [1, 4, 3, 3, 12, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606), array(1.85742606)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 6, 1, 1]
[Action Encoded] [1, 0, 0, 0, 6, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.47601659), array(2.47601659), array(2.47601659), array(2.47601659), array(2.47601659), array(2.47601659), array(2.47601659)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 1, 0, 0, 15, 0, 1]
[Action Encoded] [1, 1, 0, 0, 15, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 34, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(14.37622702), array(14.37622702), array(14.37622702), array(14.37622702), array(14.37622702), array(14.37622702), array(14.37622702)]
Episode 47 finished after 1 steps.
[Env][Action] [0, 0, 4, 2, 12, 1, 0]
[Action Encoded] [0, 0, 4, 2, 12, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 31, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 14, 'ras': 31, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(1.65245484), array(1.65245484), array(1.65245484), array(1.65245484), array(1.65245484), array(1.65245484), array(1.65245484)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 7, 1, 1]
[Action Encoded] [0, 4, 0, 1, 7, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 26, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 26, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(1.93452997), array(1.93452997), array(1.93452997), array(1.93452997), array(1.93452997), array(1.93452997), array(1.93452997)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 12, 1, 3]
[Action Encoded] [1, 0, 1, 1, 12, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(2.47537886), array(2.47537886), array(2.47537886), array(2.47537886), array(2.47537886), array(2.47537886), array(2.47537886)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:48:14 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [1, 1, 2, 2, 6, 3, 1]
[Action Encoded] [1, 1, 2, 2, 6, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 25, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(10.43705629), array(10.43705629), array(10.43705629), array(10.43705629), array(10.43705629), array(10.43705629), array(10.43705629)]
Episode 1 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 10, 2, 4]
[Action Encoded] [1, 3, 4, 0, 10, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 2  Rewards: [5.613374942247096, 5.613374942247096, 5.613374942247096, 5.613374942247096, 5.613374942247096, 5.613374942247096, 5.613374942247096]
Episode 2 finished after 1 steps.
[Env][Action] [1, 3, 4, 2, 10, 3, 4]
[Action Encoded] [1, 3, 4, 2, 10, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 20, 1, 0]
[Action Encoded] [0, 4, 3, 4, 20, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(1.73222304), array(1.73222304), array(1.73222304), array(1.73222304), array(1.73222304), array(1.73222304), array(1.73222304)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 3, 2, 1, 19, 2, 8]
[Action Encoded] [0, 3, 2, 1, 19, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 1, 1, 3, 18, 2, 6]
[Action Encoded] [1, 1, 1, 3, 18, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 37, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 15, 'ras': 37, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 0, 2, 9]
[Action Encoded] [1, 1, 0, 1, 0, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 7  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 7 finished after 1 steps.
[Env][Action] [0, 2, 2, 1, 15, 0, 8]
[Action Encoded] [0, 2, 2, 1, 15, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898), array(11.53314898)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 0, 4, 1, 12, 2, 9]
[Action Encoded] [0, 0, 4, 1, 12, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 31, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 31, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(3.02125879), array(3.02125879), array(3.02125879), array(3.02125879), array(3.02125879), array(3.02125879), array(3.02125879)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 4, 0, 1]
[Action Encoded] [1, 4, 0, 3, 4, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 23, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(2.39653947), array(2.39653947), array(2.39653947), array(2.39653947), array(2.39653947), array(2.39653947), array(2.39653947)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 0, 2, 1, 19, 3, 6]
[Action Encoded] [0, 0, 2, 1, 19, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 0, 3, 1, 3, 1, 3]
[Action Encoded] [0, 0, 3, 1, 3, 1, 3]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 990468.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 22, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618), array(3.07634618)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 1, 0, 8]
[Action Encoded] [0, 4, 2, 3, 1, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 20, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 20, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 3, 2, 1, 4, 1, 0]
[Action Encoded] [1, 3, 2, 1, 4, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(4.18810495), array(4.18810495), array(4.18810495), array(4.18810495), array(4.18810495), array(4.18810495), array(4.18810495)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 2, 4, 1, 3, 0, 4]
[Action Encoded] [1, 2, 4, 1, 3, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194), array(10.13308194)]
Episode 15 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 7, 3, 4]
[Action Encoded] [1, 4, 3, 0, 7, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367), array(2.37837367)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 7, 2, 5]
[Action Encoded] [0, 2, 3, 2, 7, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 26, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377), array(11.55078377)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 0, 4, 0, 13, 0, 3]
[Action Encoded] [1, 0, 4, 0, 13, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 2, 4, 0, 16, 0, 0]
[Action Encoded] [1, 2, 4, 0, 16, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 35, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 35, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(7.20005084), array(7.20005084), array(7.20005084), array(7.20005084), array(7.20005084), array(7.20005084), array(7.20005084)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 1, 4, 2, 19, 2, 1]
[Action Encoded] [0, 1, 4, 2, 19, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 38, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 38, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 0, 1, 20, 2, 8]
[Action Encoded] [1, 0, 0, 1, 20, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 39, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(3.29268412), array(3.29268412), array(3.29268412), array(3.29268412), array(3.29268412), array(3.29268412), array(3.29268412)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 2, 0, 1, 6, 3, 3]
[Action Encoded] [0, 2, 0, 1, 6, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 25, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(11.97181075), array(11.97181075), array(11.97181075), array(11.97181075), array(11.97181075), array(11.97181075), array(11.97181075)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 1, 0, 18, 1, 2]
[Action Encoded] [1, 4, 1, 0, 18, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 37, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 37, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667), array(2.41429667)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 1, 3, 2, 15, 3, 5]
[Action Encoded] [1, 1, 3, 2, 15, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 34, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 14, 'ras': 34, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(11.36643375), array(11.36643375), array(11.36643375), array(11.36643375), array(11.36643375), array(11.36643375), array(11.36643375)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 2, 3, 7]
[Action Encoded] [0, 4, 3, 3, 2, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609), array(2.2235609)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 3, 1, 4, 8, 1, 6]
[Action Encoded] [0, 3, 1, 4, 8, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 285480}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771), array(6.37106771)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 4, 4, 0, 5, 2, 2]
[Action Encoded] [1, 4, 4, 0, 5, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 24, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 24, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133), array(2.32294133)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 0, 1, 2, 10, 1, 7]
[Action Encoded] [1, 0, 1, 2, 10, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 29, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 18, 3, 7]
[Action Encoded] [0, 1, 4, 4, 18, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 15, 0, 9]
[Action Encoded] [0, 2, 1, 2, 15, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 34, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 34, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523), array(11.84974523)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 3, 0, 1, 15, 3, 8]
[Action Encoded] [0, 3, 0, 1, 15, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 34, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(6.50940662), array(6.50940662), array(6.50940662), array(6.50940662), array(6.50940662), array(6.50940662), array(6.50940662)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 1, 4, 2, 7, 0, 5]
[Action Encoded] [0, 1, 4, 2, 7, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 26, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 2, 3, 8]
[Action Encoded] [0, 2, 1, 1, 2, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 21, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 21, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358), array(11.68478358)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 1, 3, 13, 3, 1]
[Action Encoded] [1, 0, 1, 3, 13, 3, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(3.21163676), array(3.21163676), array(3.21163676), array(3.21163676), array(3.21163676), array(3.21163676), array(3.21163676)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 11, 3, 7]
[Action Encoded] [1, 4, 2, 3, 11, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 30, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472), array(2.35000472)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 0, 1, 4, 18, 1, 1]
[Action Encoded] [0, 0, 1, 4, 18, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 37, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(3.04192018), array(3.04192018), array(3.04192018), array(3.04192018), array(3.04192018), array(3.04192018), array(3.04192018)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 4, 2, 0, 20, 2, 9]
[Action Encoded] [1, 4, 2, 0, 20, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 39, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 39, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913), array(2.38977913)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 17, 0, 1]
[Action Encoded] [0, 4, 3, 4, 17, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 12, 3, 2]
[Action Encoded] [1, 0, 0, 0, 12, 3, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435), array(3.34216435)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 0, 2, 0, 18, 1, 5]
[Action Encoded] [0, 0, 2, 0, 18, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 37, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389), array(3.23606389)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 2, 4, 1, 18, 3, 1]
[Action Encoded] [0, 2, 4, 1, 18, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 37, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(11.73014376), array(11.73014376), array(11.73014376), array(11.73014376), array(11.73014376), array(11.73014376), array(11.73014376)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 10, 2, 6]
[Action Encoded] [0, 4, 0, 0, 10, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 29, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006), array(2.36840006)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 0, 1, 4, 1, 1, 7]
[Action Encoded] [1, 0, 1, 4, 1, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658), array(3.20322658)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 4, 0, 4]
[Action Encoded] [0, 0, 0, 2, 4, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 23, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 23, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746), array(3.23927746)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 1, 4, 0, 14, 1, 7]
[Action Encoded] [0, 1, 4, 0, 14, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 12, 'ras': 33, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(11.56254763), array(11.56254763), array(11.56254763), array(11.56254763), array(11.56254763), array(11.56254763), array(11.56254763)]
Episode 45 finished after 1 steps.
[Env][Action] [0, 2, 0, 1, 10, 1, 7]
[Action Encoded] [0, 2, 0, 1, 10, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 13, 'ras': 29, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627), array(11.76668627)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 8, 1, 1]
[Action Encoded] [1, 2, 1, 1, 8, 1, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291), array(11.79424291)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 4, 0, 4, 8, 0, 4]
[Action Encoded] [1, 4, 0, 4, 8, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 27, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 16, 'ras': 27, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(2.36311493), array(2.36311493), array(2.36311493), array(2.36311493), array(2.36311493), array(2.36311493), array(2.36311493)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 6, 1, 5]
[Action Encoded] [1, 4, 4, 1, 6, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 25, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 0, 2, 9]
[Action Encoded] [1, 3, 1, 3, 0, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 19, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 19, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(5.08342295), array(5.08342295), array(5.08342295), array(5.08342295), array(5.08342295), array(5.08342295), array(5.08342295)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 19, 0, 1]
[Action Encoded] [0, 0, 3, 4, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 14, 2, 9]
[Action Encoded] [1, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 8]
[Action Encoded] [0, 3, 3, 0, 4, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 8]
[Action Encoded] [0, 1, 3, 4, 8, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 11, 0, 8]
[Action Encoded] [0, 4, 2, 0, 11, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 0, 2, 0, 3, 2, 8]
[Action Encoded] [0, 0, 2, 0, 3, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(3.23713437), array(3.23713437), array(3.23713437), array(3.23713437), array(3.23713437), array(3.23713437), array(3.23713437)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 15, 0, 8]
[Action Encoded] [0, 1, 4, 1, 15, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 34, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449), array(11.52113449)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 15, 2, 2]
[Action Encoded] [0, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 11, 2, 0]
[Action Encoded] [1, 3, 2, 4, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 2]
[Action Encoded] [1, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 8]
[Action Encoded] [0, 4, 4, 4, 6, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 6, 1, 8]
[Action Encoded] [0, 1, 0, 4, 6, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311), array(11.59589311)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 8]
[Action Encoded] [0, 4, 3, 0, 5, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 4, 0, 3, 13, 2, 7]
[Action Encoded] [0, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 7, 0, 9]
[Action Encoded] [0, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 8]
[Action Encoded] [0, 0, 0, 3, 10, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412), array(3.23499412)]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 2, 0, 8]
[Action Encoded] [0, 0, 3, 0, 2, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 21, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 21, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 8]
[Action Encoded] [0, 0, 4, 4, 20, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 19, 2, 8]
[Action Encoded] [0, 3, 4, 0, 19, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 15, 2, 6]
[Action Encoded] [0, 1, 2, 4, 15, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 7, 0, 1]
[Action Encoded] [0, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 8]
[Action Encoded] [0, 4, 3, 3, 14, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 14, 0, 4]
[Action Encoded] [1, 3, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 17, 2, 6]
[Action Encoded] [0, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 19, 0, 2]
[Action Encoded] [1, 1, 2, 4, 19, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 80 finished after 1 steps.
[Env][Action] [1, 1, 0, 4, 2, 2, 0]
[Action Encoded] [1, 1, 0, 4, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892), array(7.28305892)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [1, 3, 0, 4, 5, 2, 9]
[Action Encoded] [1, 3, 0, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 20, 2, 2]
[Action Encoded] [0, 0, 2, 4, 20, 2, 2]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 1, 2, 9]
[Action Encoded] [1, 3, 3, 4, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929), array(5.2768929)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 16, 1, 4]
[Action Encoded] [0, 0, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 2, 2, 2]
[Action Encoded] [0, 3, 3, 4, 2, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 2, 8]
[Action Encoded] [0, 0, 2, 4, 16, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 4, 1, 8]
[Action Encoded] [0, 3, 4, 4, 4, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 5, 0, 9]
[Action Encoded] [0, 1, 4, 4, 5, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 24, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 24, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 8]
[Action Encoded] [0, 4, 2, 3, 4, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267), array(2.24894267)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 13, 2, 8]
[Action Encoded] [0, 3, 2, 4, 13, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 0, 0, 4, 15, 2, 8]
[Action Encoded] [0, 0, 0, 4, 15, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 0, 2, 3, 15, 2, 8]
[Action Encoded] [0, 0, 2, 3, 15, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 4, 4, 3, 20, 2, 8]
[Action Encoded] [0, 4, 4, 3, 20, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:49:03 UTC 2024
Total Execution Time: 49 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41866191.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [0, 3, 4, 3, 6, 2, 6]
[Action Encoded] [0, 3, 4, 3, 6, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(8.47418839), array(8.47418839), array(8.47418839), array(8.47418839), array(8.47418839), array(8.47418839), array(8.47418839)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 4, 1, 1, 0, 0, 4]
[Action Encoded] [0, 4, 1, 1, 0, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653), array(1.93538653)]
Episode 2 finished after 1 steps.
[Env][Action] [0, 2, 3, 2, 10, 0, 4]
[Action Encoded] [0, 2, 3, 2, 10, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 29, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059), array(15.93622059)]
Episode 3 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 11, 0, 0]
[Action Encoded] [0, 1, 2, 4, 11, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(8.28640854), array(8.28640854), array(8.28640854), array(8.28640854), array(8.28640854), array(8.28640854), array(8.28640854)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 2, 2, 3, 13, 0, 8]
[Action Encoded] [0, 2, 2, 3, 13, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602), array(16.01266602)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 4, 1, 2, 5, 1, 3]
[Action Encoded] [1, 4, 1, 2, 5, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(1.92288321), array(1.92288321), array(1.92288321), array(1.92288321), array(1.92288321), array(1.92288321), array(1.92288321)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 4, 0, 3, 16, 1, 7]
[Action Encoded] [0, 4, 0, 3, 16, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 35, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 35, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(1.91849008), array(1.91849008), array(1.91849008), array(1.91849008), array(1.91849008), array(1.91849008), array(1.91849008)]
Episode 7 finished after 1 steps.
[Env][Action] [0, 0, 0, 1, 0, 0, 3]
[Action Encoded] [0, 0, 0, 1, 0, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(2.49950244), array(2.49950244), array(2.49950244), array(2.49950244), array(2.49950244), array(2.49950244), array(2.49950244)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 0, 1, 3, 19, 1, 3]
[Action Encoded] [0, 0, 1, 3, 19, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 38, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 15, 'ras': 38, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(2.42433129), array(2.42433129), array(2.42433129), array(2.42433129), array(2.42433129), array(2.42433129), array(2.42433129)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 2, 4, 3, 13, 3, 4]
[Action Encoded] [1, 2, 4, 3, 13, 3, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(14.54438741), array(14.54438741), array(14.54438741), array(14.54438741), array(14.54438741), array(14.54438741), array(14.54438741)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 7, 3, 1]
[Action Encoded] [0, 3, 3, 1, 7, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 26, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 26, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(8.19082953), array(8.19082953), array(8.19082953), array(8.19082953), array(8.19082953), array(8.19082953), array(8.19082953)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 4, 3, 4, 4, 0, 4]
[Action Encoded] [1, 4, 3, 4, 4, 0, 4]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 38687326.94 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(1.83399827), array(1.83399827), array(1.83399827), array(1.83399827), array(1.83399827), array(1.83399827), array(1.83399827)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 2, 4, 1, 0, 1, 4]
[Action Encoded] [0, 2, 4, 1, 0, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(15.93156396), array(15.93156396), array(15.93156396), array(15.93156396), array(15.93156396), array(15.93156396), array(15.93156396)]
Episode 13 finished after 1 steps.
[Env][Action] [0, 1, 2, 2, 17, 0, 4]
[Action Encoded] [0, 1, 2, 2, 17, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(15.94137532), array(15.94137532), array(15.94137532), array(15.94137532), array(15.94137532), array(15.94137532), array(15.94137532)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 2, 3, 3, 19, 2, 2]
[Action Encoded] [0, 2, 3, 3, 19, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 38, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 38, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(15.72052543), array(15.72052543), array(15.72052543), array(15.72052543), array(15.72052543), array(15.72052543), array(15.72052543)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 2, 3, 4, 16, 2, 3]
[Action Encoded] [0, 2, 3, 4, 16, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(15.97536515), array(15.97536515), array(15.97536515), array(15.97536515), array(15.97536515), array(15.97536515), array(15.97536515)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 1, 1, 4, 1, 2, 0]
[Action Encoded] [0, 1, 1, 4, 1, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(8.29187128), array(8.29187128), array(8.29187128), array(8.29187128), array(8.29187128), array(8.29187128), array(8.29187128)]
Episode 17 finished after 1 steps.
[Env][Action] [0, 1, 2, 3, 3, 0, 8]
[Action Encoded] [0, 1, 2, 3, 3, 0, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 22, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 15, 'ras': 22, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112), array(16.01391112)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 15, 0, 3]
[Action Encoded] [1, 4, 4, 4, 15, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 34, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 34, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(1.82215568), array(1.82215568), array(1.82215568), array(1.82215568), array(1.82215568), array(1.82215568), array(1.82215568)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 1, 0, 1, 0, 1, 7]
[Action Encoded] [0, 1, 0, 1, 0, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 19, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(16.02674328), array(16.02674328), array(16.02674328), array(16.02674328), array(16.02674328), array(16.02674328), array(16.02674328)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 12, 1, 6]
[Action Encoded] [1, 0, 1, 1, 12, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(2.47898804), array(2.47898804), array(2.47898804), array(2.47898804), array(2.47898804), array(2.47898804), array(2.47898804)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 2, 3, 4, 14, 3, 0]
[Action Encoded] [0, 2, 3, 4, 14, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(8.26373575), array(8.26373575), array(8.26373575), array(8.26373575), array(8.26373575), array(8.26373575), array(8.26373575)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 0, 2, 0, 13, 0, 5]
[Action Encoded] [1, 0, 2, 0, 13, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 32, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 12, 'ras': 32, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.47773432), array(2.47773432), array(2.47773432), array(2.47773432), array(2.47773432), array(2.47773432), array(2.47773432)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 5, 1, 0]
[Action Encoded] [0, 3, 4, 1, 5, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 24, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(4.96544721), array(4.96544721), array(4.96544721), array(4.96544721), array(4.96544721), array(4.96544721), array(4.96544721)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 2, 1, 1, 5, 3, 9]
[Action Encoded] [0, 2, 1, 1, 5, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 24, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671), array(16.02364671)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 1, 2, 1, 14, 2, 2]
[Action Encoded] [0, 1, 2, 1, 14, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 33, 'rrd': 5, 'refi': 98280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34419440.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36837637.44 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34575140.63 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 13, 'ras': 33, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(15.73026719), array(15.73026719), array(15.73026719), array(15.73026719), array(15.73026719), array(15.73026719), array(15.73026719)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 18, 1, 4]
[Action Encoded] [1, 1, 4, 2, 18, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 37, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 37, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(14.79413929), array(14.79413929), array(14.79413929), array(14.79413929), array(14.79413929), array(14.79413929), array(14.79413929)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 17, 3, 0]
[Action Encoded] [0, 1, 4, 4, 17, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(8.2749375), array(8.2749375), array(8.2749375), array(8.2749375), array(8.2749375), array(8.2749375), array(8.2749375)]
Episode 28 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 17, 0, 3]
[Action Encoded] [1, 2, 3, 2, 17, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 36, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(14.79548618), array(14.79548618), array(14.79548618), array(14.79548618), array(14.79548618), array(14.79548618), array(14.79548618)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 1, 0, 0, 12, 2, 3]
[Action Encoded] [0, 1, 0, 0, 12, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 31, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 31, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(15.9587738), array(15.9587738), array(15.9587738), array(15.9587738), array(15.9587738), array(15.9587738), array(15.9587738)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 3, 4, 3, 13, 3, 9]
[Action Encoded] [0, 3, 4, 3, 13, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(8.45688302), array(8.45688302), array(8.45688302), array(8.45688302), array(8.45688302), array(8.45688302), array(8.45688302)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 3, 1, 4, 1, 2, 6]
[Action Encoded] [0, 3, 1, 4, 1, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(8.47920819), array(8.47920819), array(8.47920819), array(8.47920819), array(8.47920819), array(8.47920819), array(8.47920819)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 2, 0, 2, 13, 2, 1]
[Action Encoded] [0, 2, 0, 2, 13, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 32, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 14, 'ras': 32, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(15.19052789), array(15.19052789), array(15.19052789), array(15.19052789), array(15.19052789), array(15.19052789), array(15.19052789)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 2, 0, 7]
[Action Encoded] [1, 1, 4, 2, 2, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 21, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 21, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(14.72744875), array(14.72744875), array(14.72744875), array(14.72744875), array(14.72744875), array(14.72744875), array(14.72744875)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 8, 3, 4]
[Action Encoded] [0, 4, 2, 0, 8, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 27, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(1.93547219), array(1.93547219), array(1.93547219), array(1.93547219), array(1.93547219), array(1.93547219), array(1.93547219)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 4, 1, 1, 15, 2, 3]
[Action Encoded] [0, 4, 1, 1, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(1.94520631), array(1.94520631), array(1.94520631), array(1.94520631), array(1.94520631), array(1.94520631), array(1.94520631)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 1, 2, 0, 12, 3, 3]
[Action Encoded] [0, 1, 2, 0, 12, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 31, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(15.95225723), array(15.95225723), array(15.95225723), array(15.95225723), array(15.95225723), array(15.95225723), array(15.95225723)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 2, 3, 3, 5, 2, 8]
[Action Encoded] [1, 2, 3, 3, 5, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 24, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 15, 'ras': 24, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(15.03227469), array(15.03227469), array(15.03227469), array(15.03227469), array(15.03227469), array(15.03227469), array(15.03227469)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 8, 3, 4]
[Action Encoded] [0, 0, 4, 4, 8, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 27, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(2.33186731), array(2.33186731), array(2.33186731), array(2.33186731), array(2.33186731), array(2.33186731), array(2.33186731)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 10, 1, 2]
[Action Encoded] [0, 4, 3, 3, 10, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43600486.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34557328.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34377147.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43536776.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
{'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(1.84687165), array(1.84687165), array(1.84687165), array(1.84687165), array(1.84687165), array(1.84687165), array(1.84687165)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 1, 1, 1, 16, 1, 1]
[Action Encoded] [0, 1, 1, 1, 16, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 35, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(15.12792694), array(15.12792694), array(15.12792694), array(15.12792694), array(15.12792694), array(15.12792694), array(15.12792694)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 7, 1, 4]
[Action Encoded] [0, 4, 3, 3, 7, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 26, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906), array(1.8523906)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 2, 1, 4, 19, 3, 8]
[Action Encoded] [1, 2, 1, 4, 19, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 38, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 38, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(15.111715), array(15.111715), array(15.111715), array(15.111715), array(15.111715), array(15.111715), array(15.111715)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 2, 2, 0, 17, 3, 0]
[Action Encoded] [0, 2, 2, 0, 17, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 12, 'ras': 36, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(8.29879016), array(8.29879016), array(8.29879016), array(8.29879016), array(8.29879016), array(8.29879016), array(8.29879016)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 2, 2, 3, 10, 1, 3]
[Action Encoded] [1, 2, 2, 3, 10, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(14.8711774), array(14.8711774), array(14.8711774), array(14.8711774), array(14.8711774), array(14.8711774), array(14.8711774)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 4, 1, 7]
[Action Encoded] [1, 2, 3, 1, 4, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(14.96214607), array(14.96214607), array(14.96214607), array(14.96214607), array(14.96214607), array(14.96214607), array(14.96214607)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 0, 3, 3]
[Action Encoded] [1, 4, 0, 3, 0, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 19, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 19, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(1.9252316), array(1.9252316), array(1.9252316), array(1.9252316), array(1.9252316), array(1.9252316), array(1.9252316)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 2, 2, 3, 13, 2, 3]
[Action Encoded] [1, 2, 2, 3, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(14.89306188), array(14.89306188), array(14.89306188), array(14.89306188), array(14.89306188), array(14.89306188), array(14.89306188)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 12, 2, 0]
[Action Encoded] [0, 0, 1, 1, 12, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 31, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(1.73685279), array(1.73685279), array(1.73685279), array(1.73685279), array(1.73685279), array(1.73685279), array(1.73685279)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 1, 1, 0, 14, 0, 3]
[Action Encoded] [0, 1, 1, 0, 14, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(15.95660102), array(15.95660102), array(15.95660102), array(15.95660102), array(15.95660102), array(15.95660102), array(15.95660102)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:50:11 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1106458.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent3', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 8
)
[Env][Action] [0, 0, 2, 3, 18, 0, 0]
[Action Encoded] [0, 0, 2, 3, 18, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 37, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 37, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(2.47832483), array(2.47832483), array(2.47832483), array(2.47832483), array(2.47832483), array(2.47832483), array(2.47832483)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 2, 1, 0, 8, 2, 3]
[Action Encoded] [0, 2, 1, 0, 8, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(11.67575361), array(11.67575361), array(11.67575361), array(11.67575361), array(11.67575361), array(11.67575361), array(11.67575361)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 16, 2, 9]
[Action Encoded] [1, 0, 0, 4, 16, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 0, 4, 0, 4, 0, 4]
[Action Encoded] [1, 0, 4, 0, 4, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(3.22115116), array(3.22115116), array(3.22115116), array(3.22115116), array(3.22115116), array(3.22115116), array(3.22115116)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 0, 0, 3, 5, 0, 8]
[Action Encoded] [1, 0, 0, 3, 5, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 24, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 3, 1, 3, 1, 1, 2]
[Action Encoded] [1, 3, 1, 3, 1, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 20, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 15, 'ras': 20, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(5.46674662), array(5.46674662), array(5.46674662), array(5.46674662), array(5.46674662), array(5.46674662), array(5.46674662)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 4, 0, 0, 4, 2, 8]
[Action Encoded] [0, 4, 0, 0, 4, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 23, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 23, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434), array(2.364434)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 2, 3, 1, 9, 0, 3]
[Action Encoded] [1, 2, 3, 1, 9, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [11.308701473696752, 11.308701473696752, 11.308701473696752, 11.308701473696752, 11.308701473696752, 11.308701473696752, 11.308701473696752]
Episode 8 finished after 1 steps.
[Env][Action] [0, 1, 1, 2, 11, 2, 2]
[Action Encoded] [0, 1, 1, 2, 11, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 14, 'ras': 30, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872), array(11.58753872)]
Episode 9 finished after 1 steps.
[Env][Action] [0, 3, 4, 1, 8, 3, 3]
[Action Encoded] [0, 3, 4, 1, 8, 3, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(6.09117457), array(6.09117457), array(6.09117457), array(6.09117457), array(6.09117457), array(6.09117457), array(6.09117457)]
Episode 10 finished after 1 steps.
[Env][Action] [0, 4, 3, 1, 0, 3, 9]
[Action Encoded] [0, 4, 3, 1, 0, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 19, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029), array(2.27186029)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 6, 0, 7]
[Action Encoded] [1, 4, 2, 4, 6, 0, 7]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(2.3267693), array(2.3267693), array(2.3267693), array(2.3267693), array(2.3267693), array(2.3267693), array(2.3267693)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 0, 3, 2, 5, 1, 8]
[Action Encoded] [0, 0, 3, 2, 5, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 24, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 24, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032), array(3.11354032)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 3, 1, 2, 1, 1, 8]
[Action Encoded] [1, 3, 1, 2, 1, 1, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(5.32247067), array(5.32247067), array(5.32247067), array(5.32247067), array(5.32247067), array(5.32247067), array(5.32247067)]
Episode 14 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 12, 0, 2]
[Action Encoded] [1, 3, 4, 3, 12, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 31, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937), array(5.72048937)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 4, 4, 0, 13, 3, 4]
[Action Encoded] [0, 4, 4, 0, 13, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 1, 0, 3, 19, 0, 0]
[Action Encoded] [0, 1, 0, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997), array(7.90969997)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 2, 1, 3, 7, 0, 1]
[Action Encoded] [1, 2, 1, 3, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(11.50679754), array(11.50679754), array(11.50679754), array(11.50679754), array(11.50679754), array(11.50679754), array(11.50679754)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 4, 0, 0, 19, 0, 3]
[Action Encoded] [1, 4, 0, 0, 19, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 38, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 12, 'ras': 38, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267), array(2.45986267)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 2, 0, 4, 10, 1, 5]
[Action Encoded] [1, 2, 0, 4, 10, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 29, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 29, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(11.65773547), array(11.65773547), array(11.65773547), array(11.65773547), array(11.65773547), array(11.65773547), array(11.65773547)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 13, 1, 5]
[Action Encoded] [1, 0, 0, 2, 13, 1, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 32, 'rrd': 4, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 32, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143), array(3.26958143)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [0, 2, 4, 3, 17, 0, 9]
[Action Encoded] [0, 2, 4, 3, 17, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 15, 'ras': 36, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241), array(11.31717241)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 4, 1, 3, 20, 3, 9]
[Action Encoded] [0, 4, 1, 3, 20, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 39, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047), array(2.25974047)]
Episode 23 finished after 1 steps.
[Env][Action] [0, 2, 4, 1, 16, 0, 9]
[Action Encoded] [0, 2, 4, 1, 16, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 35, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 1, 4, 3, 9, 1, 6]
[Action Encoded] [1, 1, 4, 3, 9, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 28, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 28, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(10.94115901), array(10.94115901), array(10.94115901), array(10.94115901), array(10.94115901), array(10.94115901), array(10.94115901)]
Episode 25 finished after 1 steps.
[Env][Action] [0, 2, 3, 0, 6, 1, 5]
[Action Encoded] [0, 2, 3, 0, 6, 1, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 238680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216), array(11.43711216)]
Episode 26 finished after 1 steps.
[Env][Action] [0, 1, 0, 2, 2, 2, 0]
[Action Encoded] [0, 1, 0, 2, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 14, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 3, 0, 3, 8, 1, 6]
[Action Encoded] [1, 3, 0, 3, 8, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 27, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 27, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [5.85331339624288, 5.85331339624288, 5.85331339624288, 5.85331339624288, 5.85331339624288, 5.85331339624288, 5.85331339624288]
Episode 28 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 3, 1, 2]
[Action Encoded] [1, 1, 2, 2, 3, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 22, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(10.54655984), array(10.54655984), array(10.54655984), array(10.54655984), array(10.54655984), array(10.54655984), array(10.54655984)]
Episode 29 finished after 1 steps.
[Env][Action] [1, 4, 1, 3, 6, 0, 6]
[Action Encoded] [1, 4, 1, 3, 6, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(2.37237945), array(2.37237945), array(2.37237945), array(2.37237945), array(2.37237945), array(2.37237945), array(2.37237945)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 10, 2, 6]
[Action Encoded] [0, 1, 4, 4, 10, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 29, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 29, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 3, 2, 1, 2, 0, 0]
[Action Encoded] [1, 3, 2, 1, 2, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 21, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 13, 'ras': 21, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(4.12424566), array(4.12424566), array(4.12424566), array(4.12424566), array(4.12424566), array(4.12424566), array(4.12424566)]
Episode 32 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 6, 0, 1]
[Action Encoded] [1, 1, 2, 2, 6, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 25, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 25, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(10.90407034), array(10.90407034), array(10.90407034), array(10.90407034), array(10.90407034), array(10.90407034), array(10.90407034)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 0, 3, 1, 14, 1, 4]
[Action Encoded] [1, 0, 3, 1, 14, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 33, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 13, 'ras': 33, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034), array(3.19486034)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 3, 3, 1, 12, 3, 6]
[Action Encoded] [1, 3, 3, 1, 12, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 31, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 31, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(6.10794542), array(6.10794542), array(6.10794542), array(6.10794542), array(6.10794542), array(6.10794542), array(6.10794542)]
Episode 35 finished after 1 steps.
[Env][Action] [0, 3, 1, 1, 14, 1, 3]
[Action Encoded] [0, 3, 1, 1, 14, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 33, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 33, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166), array(6.46012166)]
Episode 36 finished after 1 steps.
[Env][Action] [0, 3, 2, 0, 13, 2, 5]
[Action Encoded] [0, 3, 2, 0, 13, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(6.49416211), array(6.49416211), array(6.49416211), array(6.49416211), array(6.49416211), array(6.49416211), array(6.49416211)]
Episode 37 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 7, 1, 2]
[Action Encoded] [0, 1, 2, 4, 7, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 26, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 26, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337), array(11.52939337)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 3, 1, 2]
[Action Encoded] [0, 4, 4, 4, 3, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 22, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 39 finished after 1 steps.
[Env][Action] [0, 4, 0, 2, 20, 1, 9]
[Action Encoded] [0, 4, 0, 2, 20, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 39, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 39, 'rrd': 4, 'refi': 425880}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 3, 4, 2, 6, 2, 1]
[Action Encoded] [0, 3, 4, 2, 6, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709), array(6.20706709)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 0, 0, 3, 3, 2, 7]
[Action Encoded] [1, 0, 0, 3, 3, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 22, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748), array(3.26630748)]
Episode 42 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 19, 1, 9]
[Action Encoded] [1, 0, 1, 1, 19, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 38, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 38, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545), array(3.26086545)]
Episode 43 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 16, 2, 0]
[Action Encoded] [1, 1, 2, 4, 16, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(7.63853652), array(7.63853652), array(7.63853652), array(7.63853652), array(7.63853652), array(7.63853652), array(7.63853652)]
Episode 44 finished after 1 steps.
[Env][Action] [0, 1, 4, 3, 7, 0, 6]
[Action Encoded] [0, 1, 4, 3, 7, 0, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 15, 'ras': 26, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186), array(11.43919186)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 2, 1, 3, 16, 3, 6]
[Action Encoded] [1, 2, 1, 3, 16, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 35, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 35, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(11.30870147), array(11.30870147), array(11.30870147), array(11.30870147), array(11.30870147), array(11.30870147), array(11.30870147)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 2, 1, 1, 13, 3, 7]
[Action Encoded] [1, 2, 1, 1, 13, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 32, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 13, 'ras': 32, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.52435177), array(11.52435177), array(11.52435177), array(11.52435177), array(11.52435177), array(11.52435177), array(11.52435177)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 4, 2, 3, 6, 0, 0]
[Action Encoded] [1, 4, 2, 3, 6, 0, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 25, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(1.84178472), array(1.84178472), array(1.84178472), array(1.84178472), array(1.84178472), array(1.84178472), array(1.84178472)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 6, 2, 4]
[Action Encoded] [1, 4, 4, 4, 6, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169), array(2.25193169)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 4, 0, 2, 9, 0, 4]
[Action Encoded] [1, 4, 0, 2, 9, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(2.40197534), array(2.40197534), array(2.40197534), array(2.40197534), array(2.40197534), array(2.40197534), array(2.40197534)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 19, 0, 1]
[Action Encoded] [0, 0, 3, 4, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 14, 2, 9]
[Action Encoded] [0, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 9]
[Action Encoded] [0, 3, 3, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 53  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 3]
[Action Encoded] [0, 1, 3, 4, 8, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
Episode 54 finished after 1 steps.
[Env][Action] [1, 4, 3, 0, 11, 0, 2]
[Action Encoded] [1, 4, 3, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409), array(2.36509409)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 0, 0, 0, 3, 2, 4]
[Action Encoded] [0, 0, 0, 0, 3, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 4, 0, 0]
[Action Encoded] [0, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 15, 2, 2]
[Action Encoded] [0, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207)]
Episode 58 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 11, 2, 0]
[Action Encoded] [1, 3, 2, 4, 11, 2, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172), array(4.45441172)]
Episode 59 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 19, 2, 5]
[Action Encoded] [1, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399), array(2.37304399)]
Episode 60 finished after 1 steps.
[Env][Action] [1, 4, 2, 4, 9, 1, 2]
[Action Encoded] [1, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191), array(2.32549191)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 1, 1, 9]
[Action Encoded] [1, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 2]
[Action Encoded] [0, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 6, 1, 9]
[Action Encoded] [0, 1, 0, 4, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [1, 4, 0, 3, 13, 2, 7]
[Action Encoded] [1, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451), array(2.40129451)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 7, 0, 9]
[Action Encoded] [0, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 8, 0, 9]
[Action Encoded] [0, 0, 3, 0, 8, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 69  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 2]
[Action Encoded] [0, 0, 4, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [1, 3, 4, 0, 19, 2, 6]
[Action Encoded] [1, 3, 4, 0, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515), array(6.32745515)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 7, 0, 1]
[Action Encoded] [0, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [1, 3, 3, 4, 4, 0, 9]
[Action Encoded] [1, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606), array(5.80430606)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 8]
[Action Encoded] [0, 4, 3, 3, 14, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [1, 3, 0, 0, 14, 0, 4]
[Action Encoded] [1, 3, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354), array(6.35646354)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 17, 2, 6]
[Action Encoded] [0, 4, 3, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 79 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 10, 0, 6]
[Action Encoded] [1, 1, 2, 4, 10, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736), array(11.19241736)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 1, 0, 0, 2, 2, 0]
[Action Encoded] [0, 1, 0, 0, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 12, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.94795728), array(7.94795728), array(7.94795728), array(7.94795728), array(7.94795728), array(7.94795728), array(7.94795728)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 5, 2, 9]
[Action Encoded] [0, 3, 0, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 14, 1, 2]
[Action Encoded] [0, 0, 2, 4, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [1, 3, 3, 3, 10, 1, 6]
[Action Encoded] [1, 3, 3, 3, 10, 1, 6]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
{'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705), array(5.81038705)]
Episode 84 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 1, 2, 9]
[Action Encoded] [1, 3, 3, 0, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [1, 0, 4, 4, 17, 2, 2]
[Action Encoded] [1, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249), array(3.08410249)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 2, 2, 4]
[Action Encoded] [0, 3, 3, 4, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013)]
Episode 90 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 3, 0, 2]
[Action Encoded] [1, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371), array(5.28695371)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 9]
[Action Encoded] [0, 0, 2, 4, 16, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 4, 1, 9]
[Action Encoded] [0, 3, 4, 0, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 12, 1, 9]
[Action Encoded] [0, 1, 4, 4, 12, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 13, 2, 3]
[Action Encoded] [0, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618)]
Episode 97 finished after 1 steps.
[Env][Action] [1, 0, 0, 4, 15, 2, 2]
[Action Encoded] [1, 0, 0, 4, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
[array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198), array(3.21903198)]
Episode 98 finished after 1 steps.
[Env][Action] [1, 0, 2, 3, 15, 2, 3]
[Action Encoded] [1, 0, 2, 3, 15, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092), array(3.20113092)]
Episode 99 finished after 1 steps.
[Env][Action] [1, 4, 4, 3, 20, 2, 2]
[Action Encoded] [1, 4, 4, 3, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177), array(2.27858177)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:51:01 UTC 2024
Total Execution Time: 50 seconds
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent0', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 12
)
[Env][Action] [1, 1, 0, 4, 14, 1, 2]
[Action Encoded] [1, 1, 0, 4, 14, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 33, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(14.68385075), array(14.68385075), array(14.68385075), array(14.68385075), array(14.68385075), array(14.68385075), array(14.68385075)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 4, 3, 2, 6, 2, 6]
[Action Encoded] [0, 4, 3, 2, 6, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 25, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(1.87732068), array(1.87732068), array(1.87732068), array(1.87732068), array(1.87732068), array(1.87732068), array(1.87732068)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 0, 0, 0, 7, 3, 9]
[Action Encoded] [1, 0, 0, 0, 7, 3, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 3  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 3 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 7, 3, 5]
[Action Encoded] [0, 3, 2, 3, 7, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 26, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 26, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(8.92224707), array(8.92224707), array(8.92224707), array(8.92224707), array(8.92224707), array(8.92224707), array(8.92224707)]
Episode 4 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 9, 3, 0]
[Action Encoded] [0, 4, 2, 0, 9, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 28, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 28, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(1.39439455), array(1.39439455), array(1.39439455), array(1.39439455), array(1.39439455), array(1.39439455), array(1.39439455)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 1, 1, 0, 8, 1, 3]
[Action Encoded] [1, 1, 1, 0, 8, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 12, 'ras': 27, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(14.85115557), array(14.85115557), array(14.85115557), array(14.85115557), array(14.85115557), array(14.85115557), array(14.85115557)]
Episode 6 finished after 1 steps.
[Env][Action] [1, 2, 4, 2, 16, 1, 6]
[Action Encoded] [1, 2, 4, 2, 16, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 14, 'ras': 35, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 7  Rewards: [array(14.90216662), array(14.90216662), array(14.90216662), array(14.90216662), array(14.90216662), array(14.90216662), array(14.90216662)]
Episode 7 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 20, 3, 5]
[Action Encoded] [1, 0, 1, 1, 20, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 39, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(2.47809463), array(2.47809463), array(2.47809463), array(2.47809463), array(2.47809463), array(2.47809463), array(2.47809463)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 4, 1, 0, 1, 2, 5]
[Action Encoded] [0, 4, 1, 0, 1, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(1.96145066), array(1.96145066), array(1.96145066), array(1.96145066), array(1.96145066), array(1.96145066), array(1.96145066)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 10, 3, 5]
[Action Encoded] [1, 4, 2, 1, 10, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 29, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 29, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(1.91707084), array(1.91707084), array(1.91707084), array(1.91707084), array(1.91707084), array(1.91707084), array(1.91707084)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 1, 0, 3, 19, 1, 3]
[Action Encoded] [1, 1, 0, 3, 19, 1, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 38, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 38, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(14.89510666), array(14.89510666), array(14.89510666), array(14.89510666), array(14.89510666), array(14.89510666), array(14.89510666)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [1, 0, 3, 0, 8, 0, 5]
[Action Encoded] [1, 0, 3, 0, 8, 0, 5]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36855937.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43658900.31 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36106777.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 46857707.5 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 27, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(2.45366057), array(2.45366057), array(2.45366057), array(2.45366057), array(2.45366057), array(2.45366057), array(2.45366057)]
Episode 12 finished after 1 steps.
[Env][Action] [0, 2, 0, 0, 7, 2, 0]
[Action Encoded] [0, 2, 0, 0, 7, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 26, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 26, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 13  Rewards: [array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852), array(8.32826852)]
Episode 13 finished after 1 steps.
[Env][Action] [1, 4, 2, 1, 14, 0, 1]
[Action Encoded] [1, 4, 2, 1, 14, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 33, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(1.88908951), array(1.88908951), array(1.88908951), array(1.88908951), array(1.88908951), array(1.88908951), array(1.88908951)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 10, 0, 7]
[Action Encoded] [0, 3, 0, 4, 10, 0, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(8.48740541), array(8.48740541), array(8.48740541), array(8.48740541), array(8.48740541), array(8.48740541), array(8.48740541)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 12, 1, 4]
[Action Encoded] [0, 1, 2, 4, 12, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736), array(15.93765736)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 2, 0, 3, 2, 3, 9]
[Action Encoded] [0, 2, 0, 3, 2, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 21, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 17  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 17 finished after 1 steps.
[Env][Action] [1, 3, 0, 4, 20, 2, 2]
[Action Encoded] [1, 3, 0, 4, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(8.96913685), array(8.96913685), array(8.96913685), array(8.96913685), array(8.96913685), array(8.96913685), array(8.96913685)]
Episode 18 finished after 1 steps.
[Env][Action] [1, 1, 0, 3, 3, 1, 6]
[Action Encoded] [1, 1, 0, 3, 3, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 22, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 22, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(14.98117081), array(14.98117081), array(14.98117081), array(14.98117081), array(14.98117081), array(14.98117081), array(14.98117081)]
Episode 19 finished after 1 steps.
[Env][Action] [0, 2, 3, 0, 18, 3, 4]
[Action Encoded] [0, 2, 3, 0, 18, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 37, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 37, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(15.94212289), array(15.94212289), array(15.94212289), array(15.94212289), array(15.94212289), array(15.94212289), array(15.94212289)]
Episode 20 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 8, 3, 7]
[Action Encoded] [0, 0, 0, 2, 8, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(2.47602816), array(2.47602816), array(2.47602816), array(2.47602816), array(2.47602816), array(2.47602816), array(2.47602816)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 4, 4, 2, 1, 1, 0]
[Action Encoded] [1, 4, 4, 2, 1, 1, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 20, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(1.3248039), array(1.3248039), array(1.3248039), array(1.3248039), array(1.3248039), array(1.3248039), array(1.3248039)]
Episode 22 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 0, 2, 4]
[Action Encoded] [0, 3, 3, 4, 0, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 19, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(8.41322846), array(8.41322846), array(8.41322846), array(8.41322846), array(8.41322846), array(8.41322846), array(8.41322846)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 3, 4, 3, 8, 0, 5]
[Action Encoded] [1, 3, 4, 3, 8, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 15, 'ras': 27, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(8.15603369), array(8.15603369), array(8.15603369), array(8.15603369), array(8.15603369), array(8.15603369), array(8.15603369)]
Episode 24 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 19, 0, 8]
[Action Encoded] [1, 1, 4, 2, 19, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 38, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 38, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(14.90167633), array(14.90167633), array(14.90167633), array(14.90167633), array(14.90167633), array(14.90167633), array(14.90167633)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 3, 0, 9]
[Action Encoded] [1, 0, 1, 1, 3, 0, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 41883655.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 43614309.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 44987087.94 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 42009760.38 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36064981.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
{'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 22, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 26  Rewards: [array(2.48371657), array(2.48371657), array(2.48371657), array(2.48371657), array(2.48371657), array(2.48371657), array(2.48371657)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 4, 3, 1, 9, 3, 8]
[Action Encoded] [1, 4, 3, 1, 9, 3, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 13, 'ras': 28, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203), array(1.89854203)]
Episode 27 finished after 1 steps.
[Env][Action] [0, 0, 4, 3, 0, 0, 1]
[Action Encoded] [0, 0, 4, 3, 0, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 15, 'ras': 19, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(2.30672887), array(2.30672887), array(2.30672887), array(2.30672887), array(2.30672887), array(2.30672887), array(2.30672887)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 10, 3, 2]
[Action Encoded] [0, 2, 1, 2, 10, 3, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 29, 'rrd': 6, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(15.73209091), array(15.73209091), array(15.73209091), array(15.73209091), array(15.73209091), array(15.73209091), array(15.73209091)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 4, 4, 2, 15, 1, 6]
[Action Encoded] [0, 4, 4, 2, 15, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 34, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206), array(1.85633206)]
Episode 30 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 9, 3, 0]
[Action Encoded] [0, 0, 3, 4, 9, 3, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(1.64376804), array(1.64376804), array(1.64376804), array(1.64376804), array(1.64376804), array(1.64376804), array(1.64376804)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [0, 0, 4, 0, 13, 1, 1]
[Action Encoded] [0, 0, 4, 0, 13, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 32, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(2.37436488), array(2.37436488), array(2.37436488), array(2.37436488), array(2.37436488), array(2.37436488), array(2.37436488)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 2, 1, 3, 19, 3, 9]
[Action Encoded] [0, 2, 1, 3, 19, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 38, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 15, 'ras': 38, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(16.02113551), array(16.02113551), array(16.02113551), array(16.02113551), array(16.02113551), array(16.02113551), array(16.02113551)]
Episode 33 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 6, 0, 4]
[Action Encoded] [0, 2, 1, 2, 6, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 25, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 25, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139), array(15.94150139)]
Episode 34 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 15, 2, 6]
[Action Encoded] [0, 3, 3, 0, 15, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 34, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(8.54279372), array(8.54279372), array(8.54279372), array(8.54279372), array(8.54279372), array(8.54279372), array(8.54279372)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 2, 0, 3, 13, 1, 7]
[Action Encoded] [1, 2, 0, 3, 13, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(14.97255509), array(14.97255509), array(14.97255509), array(14.97255509), array(14.97255509), array(14.97255509), array(14.97255509)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 2, 4, 1, 8, 1, 6]
[Action Encoded] [1, 2, 4, 1, 8, 1, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 13, 'ras': 27, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(14.83970358), array(14.83970358), array(14.83970358), array(14.83970358), array(14.83970358), array(14.83970358), array(14.83970358)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 3, 2, 0, 6, 3, 3]
[Action Encoded] [1, 3, 2, 0, 6, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 25, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 25, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(9.04610224), array(9.04610224), array(9.04610224), array(9.04610224), array(9.04610224), array(9.04610224), array(9.04610224)]
Episode 38 finished after 1 steps.
[Env][Action] [1, 2, 3, 0, 17, 1, 4]
[Action Encoded] [1, 2, 3, 0, 17, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 36, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(14.95995654), array(14.95995654), array(14.95995654), array(14.95995654), array(14.95995654), array(14.95995654), array(14.95995654)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 1, 4, 2, 17, 2, 5]
[Action Encoded] [1, 1, 4, 2, 17, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 14, 'ras': 36, 'rrd': 5, 'refi': 238680}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36061736.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34374795.88 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34437659.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 34393234.25 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/freqmine/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/freqmine.trace
Default config, Total Trace Energy: 36240932.0 pJ
Maximum steps per episodes reached!
Episode: 40  Rewards: [array(14.84153237), array(14.84153237), array(14.84153237), array(14.84153237), array(14.84153237), array(14.84153237), array(14.84153237)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 3, 3, 1, 13, 3, 7]
[Action Encoded] [0, 3, 3, 1, 13, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 13, 'ras': 32, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(8.5174878), array(8.5174878), array(8.5174878), array(8.5174878), array(8.5174878), array(8.5174878), array(8.5174878)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [0, 3, 1, 2, 9, 1, 7]
[Action Encoded] [0, 3, 1, 2, 9, 1, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 14, 'ras': 28, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(8.51693694), array(8.51693694), array(8.51693694), array(8.51693694), array(8.51693694), array(8.51693694), array(8.51693694)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 3, 1, 0, 7, 3, 9]
[Action Encoded] [0, 3, 1, 0, 7, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 26, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 43  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 43 finished after 1 steps.
[Env][Action] [1, 2, 2, 2, 2, 0, 5]
[Action Encoded] [1, 2, 2, 2, 2, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 21, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 14, 'ras': 21, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(14.69861438), array(14.69861438), array(14.69861438), array(14.69861438), array(14.69861438), array(14.69861438), array(14.69861438)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 1, 3, 3, 11, 0, 5]
[Action Encoded] [1, 1, 3, 3, 11, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 15, 'ras': 30, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(14.87491559), array(14.87491559), array(14.87491559), array(14.87491559), array(14.87491559), array(14.87491559), array(14.87491559)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 2, 0, 0, 13, 2, 2]
[Action Encoded] [1, 2, 0, 0, 13, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 12, 'ras': 32, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(14.92860743), array(14.92860743), array(14.92860743), array(14.92860743), array(14.92860743), array(14.92860743), array(14.92860743)]
Episode 46 finished after 1 steps.
[Env][Action] [0, 2, 3, 1, 4, 2, 7]
[Action Encoded] [0, 2, 3, 1, 4, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 13, 'ras': 23, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885), array(16.01893885)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 16, 0, 4]
[Action Encoded] [1, 2, 3, 2, 16, 0, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 35, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 35, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(14.78711382), array(14.78711382), array(14.78711382), array(14.78711382), array(14.78711382), array(14.78711382), array(14.78711382)]
Episode 48 finished after 1 steps.
[Env][Action] [0, 0, 0, 2, 17, 3, 6]
[Action Encoded] [0, 0, 0, 2, 17, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 36, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(2.47638798), array(2.47638798), array(2.47638798), array(2.47638798), array(2.47638798), array(2.47638798), array(2.47638798)]
Episode 49 finished after 1 steps.
[Env][Action] [0, 3, 0, 1, 8, 3, 1]
[Action Encoded] [0, 3, 0, 1, 8, 3, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 13, 'ras': 27, 'rrd': 6, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(8.1721482), array(8.1721482), array(8.1721482), array(8.1721482), array(8.1721482), array(8.1721482), array(8.1721482)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 62  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 62 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 64  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 64 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 67  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 67 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 82  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 82 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 83  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 85  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 85 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 86 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 88 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 92  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 92 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 2, 1, 2, 0, 3, 8]
[Action Encoded] [0, 2, 1, 2, 0, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 14, 'ras': 19, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897), array(16.03652897)]
Episode 100 finished after 1 steps.
Start Time: Tue Dec  3 14:52:15 UTC 2024
[0mramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
[0m[DEBUG][Seed] 12234
[DEBUG][RL Form] macme
[DEBUG][Max Steps] 1
[DEBUG][Num Agents] 7
[DEBUG][Reward Formulation] both
[DEBUG][Reward Scaling] false
[DEBUG][Reward Scaling] false
[Env][Action] [0, 2, 0, 3, 15, 0, 5]
[Action Encoded] [0, 2, 0, 3, 15, 0, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 238680}
obs_space:  [Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32), Box(0.0, 1000.0, (3,), float32)]
act_space:  [Discrete(2), Discrete(5), Discrete(5), Discrete(5), Discrete(21), Discrete(4), Discrete(10)]
Replay buffer size = TableInfo(name='priority_table_agent0', sampler_options=uniform: true
, remover_options=fifo: true
is_deterministic: true
, max_size=10, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0
max_diff: 1.7976931348623157e+308
min_size_to_sample: 1
insert_stats {
}
sample_stats {
}
, signature=Step(observation=TensorSpec(shape=(2, 3), dtype=tf.float32, name='0/observations'), action=TensorSpec(shape=(2,), dtype=tf.int32, name='0/actions'), reward=TensorSpec(shape=(2,), dtype=tf.float32, name='0/rewards'), discount=TensorSpec(shape=(2,), dtype=tf.float32, name='0/discounts'), start_of_episode=TensorSpec(shape=(2,), dtype=tf.bool, name='start_of_episode'), extras={'log_prob': TensorSpec(shape=(2,), dtype=tf.float32, name='1/log_prob')}), current_size=0, num_episodes=0, num_deleted_episodes=0, num_unique_samples=0, table_worker_time=sleeping_ms: 11
)
[Env][Action] [0, 0, 1, 2, 5, 2, 1]
[Action Encoded] [0, 0, 1, 2, 5, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 14, 'ras': 24, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 1  Rewards: [array(3.16899521), array(3.16899521), array(3.16899521), array(3.16899521), array(3.16899521), array(3.16899521), array(3.16899521)]
Episode 1 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 9, 3, 5]
[Action Encoded] [0, 4, 2, 4, 9, 3, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 2  Rewards: [array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289)]
Episode 2 finished after 1 steps.
[Env][Action] [1, 3, 3, 0, 3, 0, 7]
[Action Encoded] [1, 3, 3, 0, 3, 0, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 3  Rewards: [array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363), array(5.43194363)]
Episode 3 finished after 1 steps.
[Env][Action] [1, 2, 0, 4, 15, 3, 5]
[Action Encoded] [1, 2, 0, 4, 15, 3, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 6, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 4  Rewards: [array(11.44577664), array(11.44577664), array(11.44577664), array(11.44577664), array(11.44577664), array(11.44577664), array(11.44577664)]
Episode 4 finished after 1 steps.
[Env][Action] [1, 0, 3, 2, 8, 1, 4]
[Action Encoded] [1, 0, 3, 2, 8, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 27, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 14, 'ras': 27, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 5  Rewards: [array(3.18757564), array(3.18757564), array(3.18757564), array(3.18757564), array(3.18757564), array(3.18757564), array(3.18757564)]
Episode 5 finished after 1 steps.
[Env][Action] [1, 2, 4, 0, 4, 0, 1]
[Action Encoded] [1, 2, 4, 0, 4, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 6  Rewards: [array(11.33415241), array(11.33415241), array(11.33415241), array(11.33415241), array(11.33415241), array(11.33415241), array(11.33415241)]
Episode 6 finished after 1 steps.
[Env][Action] [0, 4, 1, 0, 0, 3, 9]
[Action Encoded] [0, 4, 1, 0, 0, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 19, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 12, 'ras': 19, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 7  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 7 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 19, 3, 8]
[Action Encoded] [0, 3, 3, 0, 19, 3, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 38, 'rrd': 6, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 38, 'rrd': 6, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 8  Rewards: [array(6.44510685), array(6.44510685), array(6.44510685), array(6.44510685), array(6.44510685), array(6.44510685), array(6.44510685)]
Episode 8 finished after 1 steps.
[Env][Action] [0, 2, 2, 4, 12, 2, 4]
[Action Encoded] [0, 2, 2, 4, 12, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 14, 'rp': 16, 'ras': 31, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 9  Rewards: [array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504), array(11.46314504)]
Episode 9 finished after 1 steps.
[Env][Action] [1, 0, 0, 2, 8, 3, 0]
[Action Encoded] [1, 0, 0, 2, 8, 3, 0]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 14, 'ras': 27, 'rrd': 6, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 10  Rewards: [array(2.61482084), array(2.61482084), array(2.61482084), array(2.61482084), array(2.61482084), array(2.61482084), array(2.61482084)]
Episode 10 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 7, 2, 5]
[Action Encoded] [1, 2, 4, 4, 7, 2, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 26, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 11  Rewards: [array(10.85375371), array(10.85375371), array(10.85375371), array(10.85375371), array(10.85375371), array(10.85375371), array(10.85375371)]
Replay buffer size = 0
Episode 11 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 4, 3, 7]
[Action Encoded] [0, 3, 3, 4, 4, 3, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 6, 'refi': 332280}
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 12  Rewards: [array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013)]
Episode 12 finished after 1 steps.
[Env][Action] [1, 0, 4, 0, 3, 1, 9]
[Action Encoded] [1, 0, 4, 0, 3, 1, 9]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 13  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 13 finished after 1 steps.
[Env][Action] [0, 2, 0, 4, 18, 2, 3]
[Action Encoded] [0, 2, 0, 4, 18, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'permutation', 'rcd': 12, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 14  Rewards: [array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358), array(11.72104358)]
Episode 14 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 0, 1, 1]
[Action Encoded] [0, 0, 4, 4, 0, 1, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 19, 'rrd': 4, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 19, 'rrd': 4, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 15  Rewards: [array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503), array(3.05712503)]
Episode 15 finished after 1 steps.
[Env][Action] [0, 3, 1, 0, 1, 2, 3]
[Action Encoded] [0, 3, 1, 0, 1, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 20, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 16  Rewards: [array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038), array(6.36741038)]
Episode 16 finished after 1 steps.
[Env][Action] [0, 3, 1, 1, 0, 2, 5]
[Action Encoded] [0, 3, 1, 1, 0, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 13, 'ras': 19, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 17  Rewards: [array(6.34555428), array(6.34555428), array(6.34555428), array(6.34555428), array(6.34555428), array(6.34555428), array(6.34555428)]
Episode 17 finished after 1 steps.
[Env][Action] [1, 1, 2, 2, 10, 2, 4]
[Action Encoded] [1, 1, 2, 2, 10, 2, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 14, 'ras': 29, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 18  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 18 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 6, 2, 3]
[Action Encoded] [0, 4, 3, 3, 6, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 19  Rewards: [array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144), array(2.22181144)]
Episode 19 finished after 1 steps.
[Env][Action] [1, 2, 3, 0, 6, 1, 4]
[Action Encoded] [1, 2, 3, 0, 6, 1, 4]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 12, 'ras': 25, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 20  Rewards: [array(10.92438552), array(10.92438552), array(10.92438552), array(10.92438552), array(10.92438552), array(10.92438552), array(10.92438552)]
Episode 20 finished after 1 steps.
[Env][Action] [1, 3, 1, 0, 3, 1, 2]
[Action Encoded] [1, 3, 1, 0, 3, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 21  Rewards: [array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331)]
Replay buffer size = 0
Episode 21 finished after 1 steps.
[Env][Action] [1, 4, 3, 2, 3, 0, 8]
[Action Encoded] [1, 4, 3, 2, 3, 0, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 14, 'ras': 22, 'rrd': 3, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 22  Rewards: [array(2.34156082), array(2.34156082), array(2.34156082), array(2.34156082), array(2.34156082), array(2.34156082), array(2.34156082)]
Episode 22 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 11, 3, 6]
[Action Encoded] [1, 4, 4, 1, 11, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 30, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 30, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 23  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 23 finished after 1 steps.
[Env][Action] [1, 4, 4, 2, 9, 0, 3]
[Action Encoded] [1, 4, 4, 2, 9, 0, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 24  Rewards: [array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399), array(2.2977399)]
Episode 24 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 3, 1, 3]
[Action Encoded] [0, 0, 3, 0, 3, 1, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 22, 'rrd': 4, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 25  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 25 finished after 1 steps.
[Env][Action] [1, 1, 0, 1, 17, 2, 6]
[Action Encoded] [1, 1, 0, 1, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 13, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 26  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 936292.0 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[array(11.80007612), array(11.80007612), array(11.80007612), array(11.80007612), array(11.80007612), array(11.80007612), array(11.80007612)]
Episode 26 finished after 1 steps.
[Env][Action] [1, 4, 1, 1, 15, 1, 7]
[Action Encoded] [1, 4, 1, 1, 15, 1, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 13, 'rp': 13, 'ras': 34, 'rrd': 4, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 27  Rewards: [array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761), array(2.39721761)]
Episode 27 finished after 1 steps.
[Env][Action] [1, 2, 1, 4, 16, 3, 3]
[Action Encoded] [1, 2, 1, 4, 16, 3, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 35, 'rrd': 6, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 13, 'rp': 16, 'ras': 35, 'rrd': 6, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 28  Rewards: [array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286), array(11.63977286)]
Episode 28 finished after 1 steps.
[Env][Action] [0, 3, 1, 4, 1, 3, 9]
[Action Encoded] [0, 3, 1, 4, 1, 3, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 6, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 16, 'ras': 20, 'rrd': 6, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 29  Rewards: [array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036), array(6.24903036)]
Episode 29 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 13, 3, 6]
[Action Encoded] [0, 0, 3, 4, 13, 3, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 32, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 32, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 30  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Episode 30 finished after 1 steps.
[Env][Action] [1, 4, 4, 4, 18, 2, 1]
[Action Encoded] [1, 4, 4, 4, 18, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 37, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 31  Rewards: [array(2.23824756), array(2.23824756), array(2.23824756), array(2.23824756), array(2.23824756), array(2.23824756), array(2.23824756)]
Replay buffer size = 0
Episode 31 finished after 1 steps.
[Env][Action] [1, 0, 1, 1, 5, 2, 8]
[Action Encoded] [1, 0, 1, 1, 5, 2, 8]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 24, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 32  Rewards: [array(3.28274311), array(3.28274311), array(3.28274311), array(3.28274311), array(3.28274311), array(3.28274311), array(3.28274311)]
Episode 32 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 16, 2, 6]
[Action Encoded] [0, 3, 3, 3, 16, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 35, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 33  Rewards: [array(6.40787342), array(6.40787342), array(6.40787342), array(6.40787342), array(6.40787342), array(6.40787342), array(6.40787342)]
Episode 33 finished after 1 steps.
[Env][Action] [1, 3, 0, 2, 9, 0, 5]
[Action Encoded] [1, 3, 0, 2, 9, 0, 5]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 14, 'ras': 28, 'rrd': 3, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 34  Rewards: [array(6.02500211), array(6.02500211), array(6.02500211), array(6.02500211), array(6.02500211), array(6.02500211), array(6.02500211)]
Episode 34 finished after 1 steps.
[Env][Action] [1, 1, 2, 4, 2, 2, 1]
[Action Encoded] [1, 1, 2, 4, 2, 2, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 35  Rewards: [array(10.69381898), array(10.69381898), array(10.69381898), array(10.69381898), array(10.69381898), array(10.69381898), array(10.69381898)]
Episode 35 finished after 1 steps.
[Env][Action] [1, 3, 1, 0, 4, 0, 1]
[Action Encoded] [1, 3, 1, 0, 4, 0, 1]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 13, 'rp': 12, 'ras': 23, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 36  Rewards: [array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331), array(5.46136331)]
Episode 36 finished after 1 steps.
[Env][Action] [1, 0, 4, 1, 7, 0, 6]
[Action Encoded] [1, 0, 4, 1, 7, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 26, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 26, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 37  Rewards: [array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425)]
Episode 37 finished after 1 steps.
[Env][Action] [1, 4, 4, 1, 4, 3, 7]
[Action Encoded] [1, 4, 4, 1, 4, 3, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 38  Rewards: [array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014), array(2.30086014)]
Episode 38 finished after 1 steps.
[Env][Action] [0, 0, 1, 1, 13, 2, 9]
[Action Encoded] [0, 0, 1, 1, 13, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 13, 'ras': 32, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 39  Rewards: [array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585), array(3.22965585)]
Episode 39 finished after 1 steps.
[Env][Action] [1, 0, 2, 4, 13, 2, 3]
[Action Encoded] [1, 0, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 40  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1194347.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
[array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997), array(3.14758997)]
Episode 40 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 16, 2, 7]
[Action Encoded] [0, 4, 2, 4, 16, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 41  Rewards: [array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984), array(2.20848984)]
Replay buffer size = 0
Episode 41 finished after 1 steps.
[Env][Action] [1, 2, 3, 2, 19, 2, 7]
[Action Encoded] [1, 2, 3, 2, 19, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 38, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 15, 'rp': 14, 'ras': 38, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 42  Rewards: [array(11.15012928), array(11.15012928), array(11.15012928), array(11.15012928), array(11.15012928), array(11.15012928), array(11.15012928)]
Episode 42 finished after 1 steps.
[Env][Action] [0, 1, 0, 3, 13, 3, 4]
[Action Encoded] [0, 1, 0, 3, 13, 3, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 6, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 43  Rewards: [array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636), array(11.57919636)]
Episode 43 finished after 1 steps.
[Env][Action] [0, 4, 0, 1, 9, 0, 0]
[Action Encoded] [0, 4, 0, 1, 9, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 28, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 13, 'ras': 28, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 44  Rewards: [array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793), array(1.83243793)]
Episode 44 finished after 1 steps.
[Env][Action] [1, 0, 4, 1, 4, 3, 6]
[Action Encoded] [1, 0, 4, 1, 4, 3, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 6, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 45  Rewards: [array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425), array(3.19173425)]
Episode 45 finished after 1 steps.
[Env][Action] [1, 4, 3, 3, 9, 2, 3]
[Action Encoded] [1, 4, 3, 3, 9, 2, 3]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 28, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 28, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 46  Rewards: [array(2.32230456), array(2.32230456), array(2.32230456), array(2.32230456), array(2.32230456), array(2.32230456), array(2.32230456)]
Episode 46 finished after 1 steps.
[Env][Action] [1, 1, 1, 1, 18, 1, 2]
[Action Encoded] [1, 1, 1, 1, 18, 1, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 37, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 13, 'rp': 13, 'ras': 37, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 47  Rewards: [array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695)]
Episode 47 finished after 1 steps.
[Env][Action] [1, 0, 1, 4, 16, 0, 6]
[Action Encoded] [1, 0, 1, 4, 16, 0, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 35, 'rrd': 3, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'bank_row_col', 'rcd': 13, 'rp': 16, 'ras': 35, 'rrd': 3, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 48  Rewards: [array(3.181358), array(3.181358), array(3.181358), array(3.181358), array(3.181358), array(3.181358), array(3.181358)]
Episode 48 finished after 1 steps.
[Env][Action] [1, 2, 4, 4, 4, 2, 2]
[Action Encoded] [1, 2, 4, 4, 4, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'permutation', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 49  Rewards: [array(10.39093891), array(10.39093891), array(10.39093891), array(10.39093891), array(10.39093891), array(10.39093891), array(10.39093891)]
Episode 49 finished after 1 steps.
[Env][Action] [1, 1, 2, 0, 0, 2, 7]
[Action Encoded] [1, 1, 2, 0, 0, 2, 7]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 19, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 19, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 50  Rewards: [array(9.93422097), array(9.93422097), array(9.93422097), array(9.93422097), array(9.93422097), array(9.93422097), array(9.93422097)]
Episode 50 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 19, 0, 1]
[Action Encoded] [0, 0, 3, 4, 19, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 38, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 51  Rewards: [array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132), array(3.0744132)]
Replay buffer size = 0
Episode 51 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 14, 2, 9]
[Action Encoded] [0, 1, 3, 4, 14, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 33, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 52  Rewards: [array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695), array(11.48001695)]
Episode 52 finished after 1 steps.
[Env][Action] [0, 3, 3, 0, 4, 1, 8]
[Action Encoded] [0, 3, 3, 0, 4, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 12, 'ras': 23, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 53  Rewards: [array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831), array(6.2244831)]
Episode 53 finished after 1 steps.
[Env][Action] [0, 1, 3, 4, 8, 1, 8]
[Action Encoded] [0, 1, 3, 4, 8, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 27, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 54  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1066629.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864), array(11.47182864)]
Episode 54 finished after 1 steps.
[Env][Action] [0, 4, 2, 0, 11, 0, 2]
[Action Encoded] [0, 4, 2, 0, 11, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 12, 'ras': 30, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 55  Rewards: [array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327), array(2.29836327)]
Episode 55 finished after 1 steps.
[Env][Action] [0, 0, 0, 0, 3, 2, 1]
[Action Encoded] [0, 0, 0, 0, 3, 2, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 12, 'ras': 22, 'rrd': 5, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 56  Rewards: [array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681), array(3.31162681)]
Episode 56 finished after 1 steps.
[Env][Action] [0, 1, 4, 1, 4, 0, 0]
[Action Encoded] [0, 1, 4, 1, 4, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 13, 'ras': 23, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 57  Rewards: [array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198), array(7.91446198)]
Episode 57 finished after 1 steps.
[Env][Action] [0, 3, 3, 3, 15, 2, 2]
[Action Encoded] [0, 3, 3, 3, 15, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 15, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 58  Rewards: [array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207), array(6.57890207)]
Episode 58 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 11, 1, 0]
[Action Encoded] [0, 3, 2, 4, 11, 1, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 4, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 30, 'rrd': 4, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 59  Rewards: [array(4.6478969), array(4.6478969), array(4.6478969), array(4.6478969), array(4.6478969), array(4.6478969), array(4.6478969)]
Episode 59 finished after 1 steps.
[Env][Action] [0, 4, 2, 1, 19, 2, 5]
[Action Encoded] [0, 4, 2, 1, 19, 2, 5]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 13, 'ras': 38, 'rrd': 5, 'refi': 238680}
Maximum steps per episodes reached!
Episode: 60  Rewards: [array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133), array(2.276133)]
Episode 60 finished after 1 steps.
[Env][Action] [0, 4, 2, 4, 9, 1, 2]
[Action Encoded] [0, 4, 2, 4, 9, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 16, 'ras': 28, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 61  Rewards: [array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289), array(2.2212289)]
Replay buffer size = 0
Episode 61 finished after 1 steps.
[Env][Action] [0, 1, 2, 0, 1, 1, 9]
[Action Encoded] [0, 1, 2, 0, 1, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 12, 'ras': 20, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 62  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 62 finished after 1 steps.
[Env][Action] [0, 4, 4, 4, 6, 0, 2]
[Action Encoded] [0, 4, 4, 4, 6, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 16, 'ras': 25, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 63  Rewards: [array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397), array(2.1420397)]
Episode 63 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 6, 1, 9]
[Action Encoded] [0, 1, 0, 4, 6, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 25, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 64  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 64 finished after 1 steps.
[Env][Action] [0, 4, 3, 0, 5, 1, 4]
[Action Encoded] [0, 4, 3, 0, 5, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 12, 'ras': 24, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 65  Rewards: [array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978), array(2.28842978)]
Episode 65 finished after 1 steps.
[Env][Action] [0, 4, 0, 3, 13, 2, 7]
[Action Encoded] [0, 4, 0, 3, 13, 2, 7]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 32, 'rrd': 5, 'refi': 332280}
Maximum steps per episodes reached!
Episode: 66  Rewards: [array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678)]
Episode 66 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 7, 0, 9]
[Action Encoded] [0, 0, 3, 0, 7, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 26, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 67  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 67 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 10, 0, 0]
[Action Encoded] [0, 0, 0, 3, 10, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 68  Rewards: [array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184), array(2.58938184)]
Episode 68 finished after 1 steps.
[Env][Action] [0, 0, 3, 0, 20, 0, 9]
[Action Encoded] [0, 0, 3, 0, 20, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 971567.12 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 12, 'ras': 39, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 69  Rewards: [array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545), array(3.20427545)]
Episode 69 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 20, 1, 8]
[Action Encoded] [0, 0, 4, 4, 20, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 70  Rewards: [array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305), array(2.98349305)]
Episode 70 finished after 1 steps.
[Env][Action] [0, 3, 4, 0, 19, 2, 8]
[Action Encoded] [0, 3, 4, 0, 19, 2, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 12, 'ras': 38, 'rrd': 5, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 71  Rewards: [array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167), array(6.43016167)]
Replay buffer size = 0
Episode 71 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 17, 2, 6]
[Action Encoded] [0, 1, 2, 4, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 72  Rewards: [array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641), array(11.5376641)]
Episode 72 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 7, 0, 1]
[Action Encoded] [0, 0, 3, 4, 7, 0, 1]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 26, 'rrd': 3, 'refi': 51480}
Maximum steps per episodes reached!
Episode: 73  Rewards: [array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026), array(3.09679026)]
Episode 73 finished after 1 steps.
[Env][Action] [0, 3, 2, 3, 19, 0, 0]
[Action Encoded] [0, 3, 2, 3, 19, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 15, 'ras': 38, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 74  Rewards: [array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919), array(4.77086919)]
Episode 74 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 4, 0, 9]
[Action Encoded] [0, 3, 3, 4, 4, 0, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 23, 'rrd': 3, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 75  Rewards: [array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013)]
Episode 75 finished after 1 steps.
[Env][Action] [0, 4, 3, 3, 14, 1, 8]
[Action Encoded] [0, 4, 3, 3, 14, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 15, 'ras': 33, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 76  Rewards: [array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467), array(2.22414467)]
Episode 76 finished after 1 steps.
[Env][Action] [0, 0, 3, 4, 20, 0, 0]
[Action Encoded] [0, 0, 3, 4, 20, 0, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 15, 'rp': 16, 'ras': 39, 'rrd': 3, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 77  Rewards: [array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457), array(2.48463457)]
Episode 77 finished after 1 steps.
[Env][Action] [0, 3, 0, 0, 14, 0, 4]
[Action Encoded] [0, 3, 0, 0, 14, 0, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 12, 'ras': 33, 'rrd': 3, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 78  Rewards: [array(6.62606266), array(6.62606266), array(6.62606266), array(6.62606266), array(6.62606266), array(6.62606266), array(6.62606266)]
Episode 78 finished after 1 steps.
[Env][Action] [0, 4, 0, 3, 17, 2, 6]
[Action Encoded] [0, 4, 0, 3, 17, 2, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 12, 'rp': 15, 'ras': 36, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 79  Rewards: [array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678), array(2.29400678)]
Episode 79 finished after 1 steps.
[Env][Action] [0, 1, 2, 4, 10, 0, 2]
[Action Encoded] [0, 1, 2, 4, 10, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 14, 'rp': 16, 'ras': 29, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 80  Rewards: [array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744), array(11.51288744)]
Episode 80 finished after 1 steps.
[Env][Action] [0, 1, 0, 4, 2, 2, 0]
[Action Encoded] [0, 1, 0, 4, 2, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 12, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 81  Rewards: [array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675), array(7.9335675)]
Replay buffer size = 0
Episode 81 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 5, 2, 9]
[Action Encoded] [0, 3, 0, 4, 5, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 24, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 82  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 82 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 20, 1, 2]
[Action Encoded] [0, 0, 2, 4, 20, 1, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 39, 'rrd': 4, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 83  Rewards: ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1021852.75 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 921966.56 pJ
[array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 83 finished after 1 steps.
[Env][Action] [0, 3, 0, 3, 10, 1, 6]
[Action Encoded] [0, 3, 0, 3, 10, 1, 6]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 15, 'ras': 29, 'rrd': 4, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 84  Rewards: [array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222), array(6.33830222)]
Episode 84 finished after 1 steps.
[Env][Action] [0, 3, 0, 4, 1, 2, 9]
[Action Encoded] [0, 3, 0, 4, 1, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 12, 'rp': 16, 'ras': 20, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 85  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 85 finished after 1 steps.
[Env][Action] [0, 4, 3, 4, 16, 1, 4]
[Action Encoded] [0, 4, 3, 4, 16, 1, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 15, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 86  Rewards: [array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008), array(2.184008)]
Episode 86 finished after 1 steps.
[Env][Action] [1, 1, 3, 4, 17, 2, 2]
[Action Encoded] [1, 1, 3, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col', 'rcd': 15, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 87  Rewards: [array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559), array(10.91887559)]
Episode 87 finished after 1 steps.
[Env][Action] [0, 0, 4, 4, 17, 2, 2]
[Action Encoded] [0, 0, 4, 4, 17, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 16, 'rp': 16, 'ras': 36, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 88  Rewards: [array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551), array(3.03531551)]
Episode 88 finished after 1 steps.
[Env][Action] [1, 3, 2, 4, 19, 2, 6]
[Action Encoded] [1, 3, 2, 4, 19, 2, 6]
[Action Decoder] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
[envHelpers][Action] {'pagepolicy': 'closed', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 38, 'rrd': 5, 'refi': 285480}
Maximum steps per episodes reached!
Episode: 89  Rewards: [array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712), array(6.24199712)]
Episode 89 finished after 1 steps.
[Env][Action] [0, 3, 3, 4, 2, 2, 4]
[Action Encoded] [0, 3, 3, 4, 2, 2, 4]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 15, 'rp': 16, 'ras': 21, 'rrd': 5, 'refi': 191880}
Maximum steps per episodes reached!
Episode: 90  Rewards: [array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013), array(6.00218013)]
Episode 90 finished after 1 steps.
[Env][Action] [0, 3, 2, 0, 3, 0, 2]
[Action Encoded] [0, 3, 2, 0, 3, 0, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 12, 'ras': 22, 'rrd': 3, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 91  Rewards: [array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515), array(6.31664515)]
Replay buffer size = 0
Episode 91 finished after 1 steps.
[Env][Action] [0, 0, 0, 3, 6, 2, 9]
[Action Encoded] [0, 0, 0, 3, 6, 2, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 15, 'ras': 25, 'rrd': 5, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 92  Rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Episode 92 finished after 1 steps.
[Env][Action] [0, 0, 2, 4, 16, 1, 8]
[Action Encoded] [0, 0, 2, 4, 16, 1, 8]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 379080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 16, 'ras': 35, 'rrd': 4, 'refi': 379080}
Maximum steps per episodes reached!
Episode: 93  Rewards: [array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284), array(3.10958284)]
Episode 93 finished after 1 steps.
[Env][Action] [0, 3, 4, 4, 4, 1, 9]
[Action Encoded] [0, 3, 4, 4, 4, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 16, 'rp': 16, 'ras': 23, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 94  Rewards: [array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234), array(6.11805234)]
Episode 94 finished after 1 steps.
[Env][Action] [0, 1, 4, 4, 5, 1, 9]
[Action Encoded] [0, 1, 4, 4, 5, 1, 9]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 24, 'rrd': 4, 'refi': 425880}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col', 'rcd': 16, 'rp': 16, 'ras': 24, 'rrd': 4, 'refi': 425880}
Maximum steps per episodes reached!
Episode: 95  Rewards: [array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363), array(11.44733363)]
Episode 95 finished after 1 steps.
[Env][Action] [0, 4, 2, 3, 4, 2, 0]
[Action Encoded] [0, 4, 2, 3, 4, 2, 0]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 14, 'rp': 15, 'ras': 23, 'rrd': 5, 'refi': 4680}
Maximum steps per episodes reached!
Episode: 96  Rewards: [array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789), array(1.75580789)]
Episode 96 finished after 1 steps.
[Env][Action] [0, 3, 2, 4, 13, 2, 3]
[Action Encoded] [0, 3, 2, 4, 13, 2, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col2', 'rcd': 14, 'rp': 16, 'ras': 32, 'rrd': 5, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 97  Rewards: [array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618), array(6.34192618)]
Episode 97 finished after 1 steps.
[Env][Action] [0, 0, 0, 4, 15, 2, 2]
[Action Encoded] [0, 0, 0, 4, 15, 2, 2]
[Action Decoder] ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1064812.19 pJ
ramulator::Config::add options[mapping] already set.
Simulation done. Statistics written to /home/user/ramulator/stats/swaptions/1461/sim.stat
/mnt/nvme3n1/benchmark/parsec/swaptions.trace
Default config, Total Trace Energy: 1121399.69 pJ
{'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 12, 'rp': 16, 'ras': 34, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 98  Rewards: [array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762), array(3.07344762)]
Episode 98 finished after 1 steps.
[Env][Action] [0, 0, 2, 3, 15, 0, 3]
[Action Encoded] [0, 0, 2, 3, 15, 0, 3]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 145080}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'bank_row_col', 'rcd': 14, 'rp': 15, 'ras': 34, 'rrd': 3, 'refi': 145080}
Maximum steps per episodes reached!
Episode: 99  Rewards: [array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459), array(3.06478459)]
Episode 99 finished after 1 steps.
[Env][Action] [0, 4, 4, 3, 20, 2, 2]
[Action Encoded] [0, 4, 4, 3, 20, 2, 2]
[Action Decoder] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
[envHelpers][Action] {'pagepolicy': 'open', 'addressmapping': 'row_bank_col3', 'rcd': 16, 'rp': 15, 'ras': 39, 'rrd': 5, 'refi': 98280}
Maximum steps per episodes reached!
Episode: 100  Rewards: [array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828), array(2.17057828)]
Episode 100 finished after 1 steps.
End Time: Tue Dec  3 14:53:06 UTC 2024
Total Execution Time: 51 seconds
